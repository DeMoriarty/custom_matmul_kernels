{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_minbmm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU4BcFUE5E0J"
      },
      "source": [
        "#!pip install --upgrade cupy-cuda112==8.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75DR78cKpM3m"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import cupy as cp\n",
        "import math\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12phuKJIFY9A",
        "cellView": "form"
      },
      "source": [
        "#@title CustomKernel\n",
        "import cupy as cp\n",
        "import torch\n",
        "\n",
        "@cp.util.memoize(for_each_device=True)\n",
        "def cunnex(func_name, func_body):\n",
        "  return cp.cuda.compile_with_cache(func_body).get_function(func_name)\n",
        "\n",
        "class Stream:\n",
        "  def __init__(self, ptr):\n",
        "    self.ptr = ptr\n",
        "  \n",
        "class CustomKernel:\n",
        "  def __init__(self):\n",
        "    self._use_torch_in_cupy_malloc()\n",
        "    self.stream = Stream(torch.cuda.current_stream().cuda_stream)\n",
        "\n",
        "  @staticmethod\n",
        "  def _torch_alloc(size):\n",
        "    device = cp.cuda.Device().id\n",
        "    tensor = torch.empty(size, dtype=torch.uint8, device=device)\n",
        "    return cp.cuda.MemoryPointer(\n",
        "        cp.cuda.UnownedMemory(tensor.data_ptr(), size, tensor), 0)\n",
        "\n",
        "  def _use_torch_in_cupy_malloc(self):\n",
        "    cp.cuda.set_allocator(self._torch_alloc)\n",
        "\n",
        "  def _compile_kernel_str(\n",
        "      self,\n",
        "      kernel,\n",
        "      name,\n",
        "      options=(),\n",
        "      backend=\"nvrtc\",\n",
        "      max_dynamic_smem=None\n",
        "    ):\n",
        "    fn = cp.RawKernel(\n",
        "      kernel,\n",
        "      name,\n",
        "      options=options,\n",
        "      backend=backend,\n",
        "    )\n",
        "    if max_dynamic_smem:\n",
        "      fn.max_dynamic_shared_size_bytes = max_dynamic_smem\n",
        "    return fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Img5TGyjqX2",
        "cellView": "form"
      },
      "source": [
        "#@title bmm_helpers.cu\n",
        "kernel = \"\"\"\n",
        "#define _VOLATILE_  \n",
        "\n",
        "#define likely(x)      __builtin_expect(!!(x), 1)\n",
        "#define unlikely(x)    __builtin_expect(!!(x), 0)\n",
        "#define load(x)        __ldcg(x)\n",
        "#define store(x, value) __stcs(x, value)\n",
        "\n",
        "typedef long long ll_t;\n",
        "typedef unsigned long long ull_t;\n",
        "\n",
        "typedef struct __builtin_align__(32) {\n",
        "  float s0, s1, s2, s3, s4, s5, s6, s7;\n",
        "} _float8;\n",
        "\n",
        "typedef union {\n",
        "  _float8 f8;\n",
        "  float val[8];\n",
        "} float8;\n",
        "\n",
        "__device__ void madd(\n",
        "  float a,\n",
        "  float b,\n",
        "  float &c\n",
        ") {\n",
        "  c = fmaf(a, b, c);\n",
        "}\n",
        "\n",
        "__device__ void squared_l2(\n",
        "  float a,\n",
        "  float b,\n",
        "  float &c\n",
        "){\n",
        "  float dif = a - b;\n",
        "  c = fmaf(dif, dif, c);\n",
        "}\n",
        "\n",
        "__device__ void negative_squared_l2(\n",
        "  float a,\n",
        "  float b,\n",
        "  float &c\n",
        "){\n",
        "  float dif = a - b;\n",
        "  c = fmaf(-dif, dif, c);\n",
        "}\n",
        "\n",
        "__device__ void l1(\n",
        "  float a,\n",
        "  float b,\n",
        "  float &c\n",
        "){\n",
        "  c += fabsf(a - b);\n",
        "}\n",
        "\n",
        "__device__ void negative_l1(\n",
        "  float a,\n",
        "  float b,\n",
        "  float &c\n",
        "){\n",
        "  c -= fabsf(a - b);\n",
        "}\n",
        "\n",
        "__device__ void thread_matmul_v4(\n",
        "  _VOLATILE_ float aSM[8][128+4],\n",
        "  _VOLATILE_ float bSM[8][128+4],\n",
        "  float8 cCache[8],\n",
        "  int vx, int vy\n",
        ") {\n",
        "  float aCache1[8];\n",
        "  float aCache2[8];\n",
        "  #pragma unroll\n",
        "  for (int mi=0; mi<8; mi++){\n",
        "    aCache1[mi] = aSM[0][8*vy + mi];\n",
        "  }\n",
        "\n",
        "  #pragma unroll\n",
        "  for (int ki=0; ki<8; ki++){\n",
        "    int is_odd = ki & 1;\n",
        "    if (is_odd == 0){\n",
        "      if (likely(ki < 7)){\n",
        "        #pragma unroll\n",
        "        for (int mi=0; mi<8; mi++){\n",
        "          aCache2[mi] = aSM[ki+1][8*vy + mi];\n",
        "        }\n",
        "      }\n",
        "      #pragma unroll\n",
        "      for (int ni=0; ni<8; ni++){\n",
        "        float b = bSM[ki][vx/4 + 8*vx + ni];\n",
        "        #pragma unroll\n",
        "        for (int mi=0; mi<8; mi++){\n",
        "          float a = aCache1[mi];\n",
        "          cCache[mi].val[ni] = fmaf(a, b, cCache[mi].val[ni]);\n",
        "        }\n",
        "      }\n",
        "    } else {\n",
        "      if (likely(ki < 7)){\n",
        "        #pragma unroll\n",
        "        for (int mi=0; mi<8; mi++){\n",
        "          aCache1[mi] = aSM[ki+1][8*vy + mi];\n",
        "        }\n",
        "      }\n",
        "      #pragma unroll\n",
        "      for (int ni=0; ni<8; ni++){\n",
        "        float b = bSM[ki][vx/4 + 8*vx + ni];\n",
        "        #pragma unroll\n",
        "        for (int mi=0; mi<8; mi++){\n",
        "          float a = aCache2[mi];\n",
        "          cCache[mi].val[ni] = fmaf(a, b, cCache[mi].val[ni]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void thread_matmul_16_v3(\n",
        "  _VOLATILE_ float aSM[16][128+4],\n",
        "  _VOLATILE_ float bSM[16][128+4],\n",
        "  float8 cCache[8],\n",
        "  int vx, int vy\n",
        ") {\n",
        "  float aCache[8];\n",
        "\n",
        "  #pragma unroll\n",
        "  for (int ki=0; ki<16; ki++){\n",
        "    #pragma unroll\n",
        "    for (int mi=0; mi<8; mi++){\n",
        "      aCache[mi] = aSM[ki][8*vy + mi];\n",
        "    }\n",
        "    #pragma unroll\n",
        "    for (int ni=0; ni<8; ni++){\n",
        "      float b = bSM[ki][vx/4 + 8*vx + ni];\n",
        "      #pragma unroll\n",
        "      for (int mi=0; mi<8; mi++){\n",
        "        float a = aCache[mi];\n",
        "        __DISTANCE_FN__(a, b, cCache[mi].val[ni]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void thread_matmul_v3(\n",
        "  _VOLATILE_ float aSM[8][128+4],\n",
        "  _VOLATILE_ float bSM[8][128+4],\n",
        "  float8 cCache[8],\n",
        "  int vx, int vy\n",
        ") {\n",
        "  float aCache[8];\n",
        "\n",
        "  #pragma unroll\n",
        "  for (int ki=0; ki<8; ki++){\n",
        "    #pragma unroll\n",
        "    for (int mi=0; mi<8; mi++){\n",
        "      aCache[mi] = aSM[ki][8*vy + mi];\n",
        "    }\n",
        "    #pragma unroll\n",
        "    for (int ni=0; ni<8; ni++){\n",
        "      float b = bSM[ki][vx/4 + 8*vx + ni];\n",
        "      #pragma unroll\n",
        "      for (int mi=0; mi<8; mi++){\n",
        "        float a = aCache[mi];\n",
        "        __DISTANCE_FN__(a, b, cCache[mi].val[ni]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void init_cCache(\n",
        "  float8 cCache[8]\n",
        ") {\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<8; i++){\n",
        "    #pragma unroll\n",
        "    for (int j=0; j<8; j++){\n",
        "      cCache[i].val[j] = 0.f;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// Unsafe\n",
        "__device__ void write_c(\n",
        "  float8 cCache[8],\n",
        "  float* C,\n",
        "  int gStartx, int gStarty,\n",
        "  int vx, int vy, int bid,\n",
        "  int M, int N\n",
        ") {\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<8; i++){\n",
        "    int iM = gStarty + vy*8 + i;\n",
        "    if (likely(iM < M)){\n",
        "      int iN_start = gStartx + vx*8;\n",
        "      reinterpret_cast<float8*>(C + (bid)*M*N + (iM)*N + (iN_start))[0] = cCache[i];\n",
        "      /*\n",
        "      if (likely(iN_start + 7 < N)){\n",
        "        reinterpret_cast<float8*>(C + (bid)*M*N + (iM)*N + (iN_start))[0] = cCache[i];\n",
        "      } else {\n",
        "        #pragma unroll\n",
        "        for (int j=0; j<8; j++){\n",
        "          int iN = iN_start + j;\n",
        "          if (iN < N){\n",
        "            C[(bid)*M*N + (iM)*N + (iN)] = cCache[i].val[j];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      */\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void write_c_v3(\n",
        "  float8 cCache[8],\n",
        "  float* C,\n",
        "  int gStartx, int gStarty,\n",
        "  int vx, int vy, int bid,\n",
        "  int M, int N\n",
        ") {\n",
        "  __shared__ volatile float cSM[16][128];\n",
        "  #pragma unroll\n",
        "  for (int mi=0; mi<8; mi++){\n",
        "    int iM = gStarty + vy*8 + mi;\n",
        "    // Store 1 row from cCache to cSM\n",
        "    if (iM < M){\n",
        "      #pragma unroll\n",
        "      for (int ni=0; ni<8; ni++){\n",
        "        cSM[vy][vx*8 + ni] = cCache[mi].val[ni];\n",
        "      }\n",
        "      // Store to C\n",
        "      #pragma unroll\n",
        "      for (int ni=0; ni<8; ni++){\n",
        "        int iN = gStartx + 16*ni + vx;\n",
        "        if (iN < N){\n",
        "          float cVal = cSM[vy][16*ni + vx];\n",
        "          store(C+(bid)*M*N + (iM)*N + (iN), cVal);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  } \n",
        "}\n",
        "\n",
        "__device__ void load_ab_nn(\n",
        "  const float* A,\n",
        "  const float* B,\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4],\n",
        "  int bid, int gStartx, int gStarty, int gStartk,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  int iKA = gStartk + dx;\n",
        "  int iKB = gStartk + wy;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    int iM = gStarty + dy + i*32;\n",
        "    int iN = gStartx + wx + i*32;\n",
        "    if (likely(iM < M)){\n",
        "      if (likely(iKA < K)){\n",
        "        aBuffer1[i] = load(A + (bid)*M*K + (iM)*K + (iKA));\n",
        "      } else {\n",
        "        aBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKA+8 < K)){\n",
        "        aBuffer2[i] = load(A + (bid)*M*K + (iM)*K + (iKA+8));\n",
        "      } else {\n",
        "        aBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "    if (likely(iN < N)){\n",
        "      if (likely(iKB < K)){\n",
        "        bBuffer1[i] = load(B + (bid)*N*K + (iKB)*N + (iN));\n",
        "      } else {\n",
        "        bBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKB+8 < K)){\n",
        "        bBuffer2[i] = load(B + (bid)*N*K + (iKB+8)*N + (iN));\n",
        "      } else {\n",
        "        bBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void load_ab_tt(\n",
        "  const float* A,\n",
        "  const float* B,\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4],\n",
        "  int bid, int gStartx, int gStarty, int gStartk,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  int iKA = gStartk + wy;\n",
        "  int iKB = gStartk + dx;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    int iM = gStarty + wx + i*32;\n",
        "    int iN = gStartx + dy + i*32;\n",
        "    if (likely(iM < M)){\n",
        "      if (likely(iKA < K)){\n",
        "        aBuffer1[i] = load(A + (bid)*M*K + (iKA)*M + (iM));\n",
        "      } else {\n",
        "        aBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKA+8 < K)){\n",
        "        aBuffer2[i] = load(A + (bid)*M*K + (iKA+8)*M + (iM));\n",
        "      } else {\n",
        "        aBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "    if (likely(iN < N)){\n",
        "      if (likely(iKB < K)){\n",
        "        bBuffer1[i] = load(B + (bid)*N*K + (iN)*K + (iKB));\n",
        "      } else {\n",
        "        bBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKB+8 < K)){\n",
        "        bBuffer2[i] = load(B + (bid)*N*K + (iN)*K + (iKB+8));\n",
        "      } else {\n",
        "        bBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void load_ab_nt(\n",
        "  const float* A,\n",
        "  const float* B,\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4],\n",
        "  int bid, int gStartx, int gStarty, int gStartk,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  int iKA = gStartk + dx;\n",
        "  int iKB = gStartk + dx;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    int iM = gStarty + dy + i*32;\n",
        "    int iN = gStartx + dy + i*32;\n",
        "    if (likely(iM < M)){\n",
        "      if (likely(iKA < K)){\n",
        "        aBuffer1[i] = load(A + (bid)*M*K + (iM)*K + (iKA));\n",
        "      } else {\n",
        "        aBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKA+8 < K)){\n",
        "        aBuffer2[i] = load(A + (bid)*M*K + (iM)*K + (iKA+8));\n",
        "      } else {\n",
        "        aBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "    if (likely(iN < N)){\n",
        "      if (likely(iKB < K)){\n",
        "        bBuffer1[i] = load(B + (bid)*N*K + (iN)*K + (iKB));\n",
        "      } else {\n",
        "        bBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKB+8 < K)){\n",
        "        bBuffer2[i] = load(B + (bid)*N*K + (iN)*K + (iKB+8));\n",
        "      } else {\n",
        "        bBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void load_ab_tn(\n",
        "  const float* A,\n",
        "  const float* B,\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4],\n",
        "  int bid, int gStartx, int gStarty, int gStartk,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  int iKA = gStartk + wy;\n",
        "  int iKB = gStartk + wy;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    int iM = gStarty + wx + i*32;\n",
        "    int iN = gStartx + wx + i*32;\n",
        "    if (likely(iM < M)){\n",
        "      if (likely(iKA < K)){\n",
        "        aBuffer1[i] = load(A + (bid)*M*K + (iKA)*M + (iM));\n",
        "      } else {\n",
        "        aBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKA+8 < K)){\n",
        "        aBuffer2[i] = load(A + (bid)*M*K + (iKA+8)*M + (iM));\n",
        "      } else {\n",
        "        aBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "    if (likely(iN < N)){\n",
        "      if (likely(iKB < K)){\n",
        "        bBuffer1[i] = load(B + (bid)*N*K + (iKB)*N + (iN));\n",
        "      } else {\n",
        "        bBuffer1[i] = 0.f;\n",
        "      }\n",
        "      if (likely(iKB+8 < K)){\n",
        "        bBuffer2[i] = load(B + (bid)*N*K + (iKB+8)*N + (iN));\n",
        "      } else {\n",
        "        bBuffer2[i] = 0.f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_nn(\n",
        "  _VOLATILE_ float aSM1[8][128+4],\n",
        "  _VOLATILE_ float aSM2[8][128+4],\n",
        "  _VOLATILE_ float bSM1[8][128+4],\n",
        "  _VOLATILE_ float bSM2[8][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM1[dx][dy+i*32] = aBuffer1[i];\n",
        "    bSM1[wy][wx+i*32+i] = bBuffer1[i];\n",
        "    aSM2[dx][dy+i*32] = aBuffer2[i];\n",
        "    bSM2[wy][wx+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_tt(\n",
        "  _VOLATILE_ float aSM1[8][128+4],\n",
        "  _VOLATILE_ float aSM2[8][128+4],\n",
        "  _VOLATILE_ float bSM1[8][128+4],\n",
        "  _VOLATILE_ float bSM2[8][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM1[wy][wx+i*32] = aBuffer1[i];\n",
        "    aSM2[wy][wx+i*32] = aBuffer2[i];\n",
        "    bSM1[dx][dy+i*32+i] = bBuffer1[i];\n",
        "    bSM2[dx][dy+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_nt(\n",
        "  _VOLATILE_ float aSM1[8][128+4],\n",
        "  _VOLATILE_ float aSM2[8][128+4],\n",
        "  _VOLATILE_ float bSM1[8][128+4],\n",
        "  _VOLATILE_ float bSM2[8][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM1[dx][dy+i*32] = aBuffer1[i];\n",
        "    aSM2[dx][dy+i*32] = aBuffer2[i];\n",
        "    bSM1[dx][dy+i*32+i] = bBuffer1[i];\n",
        "    bSM2[dx][dy+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_tn(\n",
        "  _VOLATILE_ float aSM1[8][128+4],\n",
        "  _VOLATILE_ float aSM2[8][128+4],\n",
        "  _VOLATILE_ float bSM1[8][128+4],\n",
        "  _VOLATILE_ float bSM2[8][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM1[wy][wx+i*32] = aBuffer1[i];\n",
        "    aSM2[wy][wx+i*32] = aBuffer2[i];\n",
        "    bSM1[wy][wx+i*32+i] = bBuffer1[i];\n",
        "    bSM2[wy][wx+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_16_nn(\n",
        "  _VOLATILE_ float aSM[16][128+4],\n",
        "  _VOLATILE_ float bSM[16][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM[dx][dy+i*32] = aBuffer1[i];\n",
        "    aSM[dx+8][dy+i*32] = aBuffer2[i];\n",
        "    bSM[wy][wx+i*32+i] = bBuffer1[i];\n",
        "    bSM[wy+8][wx+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_16_tt(\n",
        "  _VOLATILE_ float aSM[16][128+4],\n",
        "  _VOLATILE_ float bSM[16][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM[wy][wx+i*32] = aBuffer1[i];\n",
        "    aSM[wy+8][wx+i*32] = aBuffer2[i];\n",
        "    bSM[dx][dy+i*32+i] = bBuffer1[i];\n",
        "    bSM[dx+8][dy+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_16_nt(\n",
        "  _VOLATILE_ float aSM[16][128+4],\n",
        "  _VOLATILE_ float bSM[16][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM[dx][dy+i*32] = aBuffer1[i];\n",
        "    aSM[dx+8][dy+i*32] = aBuffer2[i];\n",
        "    bSM[dx][dy+i*32+i] = bBuffer1[i];\n",
        "    bSM[dx+8][dy+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void buffer2smem_16_tn(\n",
        "  _VOLATILE_ float aSM[16][128+4],\n",
        "  _VOLATILE_ float bSM[16][128+4],\n",
        "  float aBuffer1[4],\n",
        "  float aBuffer2[4],\n",
        "  float bBuffer1[4],\n",
        "  float bBuffer2[4]\n",
        "){\n",
        "  int tid = threadIdx.x;\n",
        "  int wx = tid % 32;\n",
        "  int wy = tid / 32;\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "  #pragma unroll\n",
        "  for (int i=0; i<4; i++){\n",
        "    // Store buffered tiles into shared memory\n",
        "    aSM[wy][wx+i*32] = aBuffer1[i];\n",
        "    aSM[wy+8][wx+i*32] = aBuffer2[i];\n",
        "    bSM[wy][wx+i*32+i] = bBuffer1[i];\n",
        "    bSM[wy+8][wx+i*32+i] = bBuffer2[i];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"bmm_helpers.cu\", \"w\") as f:\n",
        "  f.write(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bgnl7RysBlD",
        "cellView": "form"
      },
      "source": [
        "#@title MinBMM Kernel\n",
        "kernel = \"\"\"\n",
        "__device__ __forceinline__ float atomicMin(float *address, float val)\n",
        "{\n",
        "  int ret = __float_as_int(*address);\n",
        "  while(val < __int_as_float(ret))\n",
        "  {\n",
        "    int old = ret;\n",
        "    if((ret = atomicCAS((int *)address, old, __float_as_int(val))) == old)\n",
        "      break;\n",
        "  }\n",
        "  return __int_as_float(ret);\n",
        "}\n",
        "\n",
        "__device__ void min_dim_1(\n",
        "  float8 cCache[8],\n",
        "  _VOLATILE_ float valSM[16][128+4],\n",
        "  _VOLATILE_ float idxSM[16][128+4],\n",
        "  float* values,\n",
        "  ll_t* indices,\n",
        "  int gStartx, int gStarty, int tid, int bid,\n",
        "  int M, int N\n",
        "){\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "\n",
        "  #pragma unroll\n",
        "  for (int ni = 0; ni < 8; ni++){\n",
        "    // initialize with first value\n",
        "\n",
        "    float value;\n",
        "    if (likely(gStarty + vy*8 < M)){\n",
        "      value = cCache[0].val[ni];\n",
        "    } else {\n",
        "      value = INFINITY;\n",
        "    }\n",
        "    float index = vy*8;\n",
        "\n",
        "    // Reduce within thread\n",
        "    #pragma unroll\n",
        "    for (int mi = 1; mi < 8; mi++){\n",
        "      int iM = gStarty + vy*8 + mi;\n",
        "      float temp;\n",
        "      if (likely(iM < M)){\n",
        "        temp = cCache[mi].val[ni];\n",
        "      } else {\n",
        "        temp = INFINITY;\n",
        "      }\n",
        "      if (temp < value){\n",
        "        value = temp;\n",
        "        index = vy*8 + mi;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // Store reduced values and indices in shared memory\n",
        "    valSM[vy][vx * 8 + ni] = value;\n",
        "    idxSM[vy][vx * 8 + ni] = index;\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // first 128 threads do block wise reduction\n",
        "  if (tid < 128){\n",
        "    float value = valSM[0][tid];\n",
        "    float index = idxSM[0][tid];\n",
        "    \n",
        "    #pragma unroll\n",
        "    for (int i=1; i<16; i++){\n",
        "      float temp = valSM[i][tid];\n",
        "      if (temp < value){\n",
        "        value = temp;\n",
        "        index = idxSM[i][tid];\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    // global reduction\n",
        "    int iN = gStartx + tid;\n",
        "    if (iN < N){\n",
        "      atomicMin(values + (bid) * N + iN, value);\n",
        "      if (value <= values[(bid) * N + iN]){\n",
        "        indices[(bid) * N + iN] = ll_t(index) + gStarty;\n",
        "      }\n",
        "    }\n",
        "    /*\n",
        "    */\n",
        "  }\n",
        "}\n",
        "\n",
        "__device__ void min_dim_2(\n",
        "  float8 cCache[8],\n",
        "  _VOLATILE_ float valSM[16][128+4],\n",
        "  _VOLATILE_ float idxSM[16][128+4],\n",
        "  float* values,\n",
        "  ll_t* indices,\n",
        "  int gStartx, int gStarty, int tid, int bid,\n",
        "  int M, int N\n",
        "){\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "\n",
        "  #pragma unroll\n",
        "  for (int mi = 0; mi < 8; mi++){\n",
        "    // initialize with first value\n",
        "    float value;\n",
        "    if (likely(gStartx + vx*8 < N)){\n",
        "      value = cCache[mi].val[0];\n",
        "    } else {\n",
        "      value = INFINITY;\n",
        "    }\n",
        "    float index = vx*8;\n",
        "\n",
        "    // Reduce within thread\n",
        "    #pragma unroll\n",
        "    for (int ni = 1; ni < 8; ni++){\n",
        "      int iN = gStartx + vx*8 + ni;\n",
        "      float temp;\n",
        "      if (likely(iN < N)){\n",
        "        temp = cCache[mi].val[ni];\n",
        "      } else {\n",
        "        temp = INFINITY;\n",
        "      }\n",
        "      if (temp < value){\n",
        "        value = temp;\n",
        "        index = vx*8 + ni;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // Store reduced values and indices in shared memory\n",
        "    valSM[vx][vy * 8 + mi] = value;\n",
        "    idxSM[vx][vy * 8 + mi] = index;\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  // first 128 threads do block-wise reduction\n",
        "  if (tid < 128){\n",
        "    float value = valSM[0][tid];\n",
        "    float index = idxSM[0][tid];\n",
        "    #pragma unroll\n",
        "    for (int i = 1; i < 16; i++){\n",
        "      float temp = valSM[i][tid];\n",
        "      if (temp < value){\n",
        "        value = temp;\n",
        "        index = idxSM[i][tid];\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // global reduction\n",
        "    int iM = gStarty + tid;\n",
        "    if (iM < M){\n",
        "      atomicMin(values + (bid) * M + iM, value);\n",
        "      if (value <= values[(bid) * M + iM]){\n",
        "        indices[(bid) * M + iM] = ll_t(index) + gStartx;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void min_bmm_tn(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ values,\n",
        "  ll_t* __restrict__ indices,\n",
        "  int M, int N, int K, int DIM\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM[16][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM[16][128+4];\n",
        "\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  #pragma unroll\n",
        "  load_ab_tn(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    buffer2smem_16_tn(\n",
        "      aSM, bSM,\n",
        "      aBuffer1, aBuffer2, \n",
        "      bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_tn(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    thread_matmul_16_v3(aSM, bSM, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // Reduce along DIM\n",
        "  if (DIM == 1){\n",
        "    min_dim_1(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  } else if (DIM == 2){\n",
        "    min_dim_2(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void min_bmm_nt(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ values,\n",
        "  ll_t* __restrict__ indices,\n",
        "  int M, int N, int K, int DIM\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM[16][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM[16][128+4];\n",
        "\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  #pragma unroll\n",
        "  load_ab_nt(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    buffer2smem_16_nt(\n",
        "      aSM, bSM,\n",
        "      aBuffer1, aBuffer2,\n",
        "      bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_nt(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    thread_matmul_16_v3(aSM, bSM, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // Reduce along DIM\n",
        "  if (DIM == 1){\n",
        "    min_dim_1(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  } else if (DIM == 2){\n",
        "    min_dim_2(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void min_bmm_nn(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ values,\n",
        "  ll_t* __restrict__ indices,\n",
        "  int M, int N, int K, int DIM\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM[16][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM[16][128+4];\n",
        "\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  load_ab_nn(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    buffer2smem_16_nn(\n",
        "      aSM, bSM,\n",
        "      aBuffer1, aBuffer2,\n",
        "      bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_nn(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    thread_matmul_16_v3(aSM, bSM, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // Reduce along DIM\n",
        "  if (DIM == 1){\n",
        "    min_dim_1(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  } else if (DIM == 2){\n",
        "    min_dim_2(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void min_bmm_tt(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ values,\n",
        "  ll_t* __restrict__ indices,\n",
        "  int M, int N, int K, int DIM\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM[16][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM[16][128+4];\n",
        "\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  #pragma unroll\n",
        "  load_ab_tt(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    buffer2smem_16_tt(\n",
        "      aSM, bSM,\n",
        "      aBuffer1, aBuffer2,\n",
        "      bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_tt(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    thread_matmul_16_v3(aSM, bSM, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // Reduce along DIM\n",
        "  if (DIM == 1){\n",
        "    min_dim_1(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  } else if (DIM == 2){\n",
        "    min_dim_2(\n",
        "      cCache, aSM, bSM, values, indices,\n",
        "      gStartx, gStarty, tid, bid, M, N);\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"MinBMMCUDA.cu\", \"w\") as f:\n",
        "  f.write(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uaCGxMKsP1H",
        "cellView": "form"
      },
      "source": [
        "#@title MinBMM\n",
        "import torch\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class MinBMMCUDA(CustomKernel): \n",
        "  def __init__(self, m=None, n=None, k=None, patch_m=4, patch_n=4, distance=\"inner\"):\n",
        "    super(MinBMMCUDA, self).__init__()\n",
        "    self.m = m\n",
        "    self.n = n\n",
        "    self.k = k\n",
        "    self.patch_m = patch_m\n",
        "    self.patch_n = patch_n\n",
        "    if distance == \"inner\":\n",
        "      dist_fn = \"madd\"\n",
        "    elif distance in [\"l2\", \"euclidean\"]:\n",
        "      dist_fn = \"squared_l2\"\n",
        "    elif distance in [\"l1\", \"manhattan\"]:\n",
        "      dist_fn = \"l1\"\n",
        "    else:\n",
        "      ValueError(\"Unrecognized distance type\")\n",
        "\n",
        "    self.distance = distance\n",
        "    \n",
        "    with open(\"bmm_helpers.cu\", \"r\") as f:\n",
        "      helpers = f.read()\n",
        "    \n",
        "    with open(\"MinBMMCUDA.cu\",'r') as f: ###\n",
        "      self.kernel = helpers + f.read()\n",
        "      \n",
        "    self.kernel = (self.kernel\n",
        "      .replace(\"_M_\", str(m) if m else \"M\")\n",
        "      .replace(\"_N_\", str(n) if n else \"N\")\n",
        "      .replace(\"_K_\", str(k) if k else \"K\")\n",
        "      .replace(\"_PM_\", str(self.patch_m))\n",
        "      .replace(\"_PN_\", str(self.patch_n))\n",
        "      .replace(\"__DISTANCE_FN__\", dist_fn)\n",
        "    )\n",
        "    \n",
        "    self._fn_tt = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"min_bmm_tt\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "    self._fn_nn = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"min_bmm_nn\",\n",
        "      backend='nvcc',\n",
        "      options=(\n",
        "        '--maxrregcount=128',\n",
        "        '--use_fast_math',\n",
        "        #'-Xptxas',\n",
        "        #'-dlcm=cg',\n",
        "      )\n",
        "    )\n",
        "    # print(self._fn_nn.attributes)\n",
        "    self._fn_tn = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"min_bmm_tn\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "    self._fn_nt = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"min_bmm_nt\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "\n",
        "  def get_mode(self, A, B):\n",
        "    mode = [None, None]\n",
        "    if A.stride()[-1] == 1:\n",
        "      mode[0] = \"n\"\n",
        "    elif A.stride()[-2] == 1:\n",
        "      mode[0] = \"t\"\n",
        "    if B.stride()[-1] == 1:\n",
        "      mode[1] = \"n\"\n",
        "    elif B.stride()[-2] == 1:\n",
        "      mode[1] = \"t\"\n",
        "    return \"\".join(mode)\n",
        "\n",
        "  def __call__(self, A, B, dim=1):\n",
        "    \"\"\"\n",
        "      Performs C = min(f(A) @ g(B)), argmin(f(A) @ g(B))\n",
        "      A: torch.Tensor, shape : [l, m, k] or [l, k, m]\n",
        "      B: torch.Tensor, shape : [l, n, k] or [l, k, n]\n",
        "      returns C: torch.Tensor, shape : [l, m, n]\n",
        "      Notes:\n",
        "        f() and g() are determined by mode\n",
        "        \"nn\" --> A @ B\n",
        "        \"tt\" --> A.T @ B.T\n",
        "        \"nt\" --> A @ B.T\n",
        "        \"tn\" --> A.T @ B\n",
        "    \"\"\"\n",
        "    assert len(A.shape) == len(B.shape)\n",
        "    if len(A.shape) == 2 and len(B.shape) == 2:\n",
        "      A = A[None]\n",
        "      B = B[None]\n",
        "      dim += 1\n",
        "      two_dimentional = True\n",
        "    elif len(A.shape) == 3 and len(B.shape) == 3:\n",
        "      two_dimentional = False\n",
        "    else:\n",
        "      raise ValueError(\"A and B need to be 2d or 3d\")\n",
        "    assert A.shape[0] == B.shape[0]\n",
        "    assert A.shape[2] == B.shape[1]\n",
        "    assert A.dtype == B.dtype\n",
        "    assert A.dtype in [torch.float, torch.half]\n",
        "    assert A.device.type == B.device.type == \"cuda\"\n",
        "    assert dim in [1, 2]\n",
        "\n",
        "    mode = self.get_mode(A, B)\n",
        "    \n",
        "    if mode == \"nn\":\n",
        "      kernel_fn = self._fn_nn\n",
        "    elif mode == \"nt\":\n",
        "      kernel_fn = self._fn_nt\n",
        "    elif mode == \"tn\":\n",
        "      kernel_fn = self._fn_tn\n",
        "    elif mode == \"tt\":\n",
        "      kernel_fn = self._fn_tt\n",
        "\n",
        "    l, m, k = A.shape\n",
        "    l, k, n = B.shape\n",
        "\n",
        "    if dim == 1:\n",
        "      values = torch.empty([l, n], device=\"cuda:0\", dtype=A.dtype)\n",
        "      indices = torch.empty([l, n], device=\"cuda:0\", dtype=torch.int64)\n",
        "    elif dim == 2:\n",
        "      values = torch.empty([l, m], device=\"cuda:0\", dtype=A.dtype)\n",
        "      indices = torch.empty([l, m], device=\"cuda:0\", dtype=torch.int64)\n",
        "    values.fill_(float(\"inf\"))\n",
        "\n",
        "    threads_per_block = (256,)\n",
        "    #blocks_per_grid = (math.ceil(n/128), math.ceil(m/128), l)\n",
        "    \n",
        "    n_ = math.ceil(n/(128*self.patch_n))\n",
        "    m_ = math.ceil(m/(128*self.patch_m))\n",
        "    blocks_per_grid = (self.patch_n*self.patch_m, n_ * m_, l)\n",
        "    # print(blocks_per_grid, m_, n_)\n",
        "\n",
        "    kernel_fn(\n",
        "      grid=blocks_per_grid,\n",
        "      block=threads_per_block,\n",
        "      args=[\n",
        "        A.data_ptr(),\n",
        "        B.data_ptr(),\n",
        "        values.data_ptr(),\n",
        "        indices.data_ptr(),\n",
        "        m, n, k, dim,\n",
        "      ],\n",
        "      stream=self.stream\n",
        "    )\n",
        "\n",
        "    if two_dimentional:\n",
        "      indices = indices[0]\n",
        "      values = values[0]\n",
        "\n",
        "    return values, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDuqX_JrO-50",
        "cellView": "form"
      },
      "source": [
        "#@title BMMv2.5 Kernel\n",
        "kernel = \"\"\"\n",
        "extern \"C\"\n",
        "__global__ void bmm_tn(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ C,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float aSM2[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM2[8][128+4];\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  load_ab_tn(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    #pragma unroll\n",
        "    buffer2smem_tn(\n",
        "      aSM1, aSM2, bSM1, bSM2,\n",
        "      aBuffer1, aBuffer2, bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_tn(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    // Each thread computes 8 x 8 matrix multiplication\n",
        "    // Accumulate intermediate results in cCache\n",
        "    // aSM1, bSM1, aSM2, bSM2 are consumed\n",
        "    thread_matmul_v3(aSM1, bSM1, cCache, vx, vy);\n",
        "    thread_matmul_v3(aSM2, bSM2, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "  \n",
        "  // At the end of main loop, store cCache to C\n",
        "  //write_c(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "  write_c_v3(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void bmm_nt(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ C,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float aSM2[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM2[8][128+4];\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  load_ab_nt(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    buffer2smem_nt(\n",
        "      aSM1, aSM2, bSM1, bSM2,\n",
        "      aBuffer1, aBuffer2, bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_nt(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    // Each thread computes 8 x 8 matrix multiplication\n",
        "    // Accumulate intermediate results in cCache\n",
        "    // aSM1, bSM1, aSM2, bSM2 are consumed\n",
        "    thread_matmul_v3(aSM1, bSM1, cCache, vx, vy);\n",
        "    thread_matmul_v3(aSM2, bSM2, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "  \n",
        "  // At the end of main loop, store cCache to C\n",
        "  //write_c(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "  write_c_v3(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void bmm_nn(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ C,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float aSM2[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM2[8][128+4];\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  load_ab_nn(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    #pragma unroll\n",
        "    buffer2smem_nn(\n",
        "      aSM1, aSM2, bSM1, bSM2,\n",
        "      aBuffer1, aBuffer2, bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_nn(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    // Each thread computes 8 x 8 matrix multiplication\n",
        "    // Accumulate intermediate results in cCache\n",
        "    // aSM1, bSM1, aSM2, bSM2 are consumed\n",
        "    thread_matmul_v3(aSM1, bSM1, cCache, vx, vy);\n",
        "    thread_matmul_v3(aSM2, bSM2, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "  \n",
        "  // At the end of main loop, store cCache to C\n",
        "  //write_c(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "  write_c_v3(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "}\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void bmm_tt(\n",
        "  const float* __restrict__ A,\n",
        "  const float* __restrict__ B,\n",
        "  float* __restrict__ C,\n",
        "  int M, int N, int K\n",
        "){\n",
        "  int tid = threadIdx.x;     // thread idx\n",
        "  int bid = blockIdx.z;      // batch idx\n",
        "\n",
        "  // Neighboring blocks are grouped into PN x PM block groups in order to increase\n",
        "  // L1 cache hit rate\n",
        "  // There are ceil(M/PM) x ceil(N/PN) block groups in total.\n",
        "  // Blocks within block groups are indexed with blockIdx.x % PN and blockIdx.x / PN\n",
        "  int px = blockIdx.x % _PN_;\n",
        "  int py = blockIdx.x / _PN_;\n",
        "  int bDimX = (N + (128*_PN_) - 1) / (128*_PN_); \n",
        "  int bDimY = (M + (128*_PM_) - 1) / (128*_PM_); \n",
        "  int bIdxX = (blockIdx.y % bDimX) * _PN_ + px;\n",
        "  int bIdxY = (blockIdx.y / bDimX) * _PM_ + py;\n",
        "  int gStartx = bIdxX * 128;   // starting index of block on N axis\n",
        "  int gStarty = bIdxY * 128;   // starting index of block on M axis\n",
        "  if (gStartx > N || gStarty > M){\n",
        "    return;\n",
        "  }\n",
        "  // These are used to re-arrange threads into different shapes\n",
        "  // for example: (256) -> (16, 16) -> (8, 32) -> (32, 8)\n",
        "  int vx = tid % 16;\n",
        "  int vy = tid / 16;\n",
        "  int wx = tid % 32; // thread idx in warp\n",
        "  int wy = tid / 32; // warp id\n",
        "  int dx = tid % 8;\n",
        "  int dy = tid / 8;\n",
        "\n",
        "  __shared__ _VOLATILE_ float aSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM1[8][128+4];\n",
        "  __shared__ _VOLATILE_ float aSM2[8][128+4];\n",
        "  __shared__ _VOLATILE_ float bSM2[8][128+4];\n",
        "  float aBuffer1[4];\n",
        "  float bBuffer1[4];\n",
        "  float aBuffer2[4];\n",
        "  float bBuffer2[4];\n",
        "\n",
        "  float8 cCache[8];\n",
        "  init_cCache(cCache);\n",
        "\n",
        "  // Load initial 16 x 128 tile of A and B to buffer1 and buffer2\n",
        "  load_ab_tt(\n",
        "    A, B, \n",
        "    aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "    bid, gStartx, gStarty, 0,\n",
        "    M, N, K\n",
        "  );\n",
        "\n",
        "  // Number of main loop iterations is ceil(k/16)\n",
        "  int nIt = (_K_ + 16 - 1) / 16;\n",
        "  #pragma unroll\n",
        "  for (int itr=0; itr<nIt; itr++){\n",
        "    int gStartk = itr * 16;\n",
        "\n",
        "    #pragma unroll\n",
        "    buffer2smem_tt(\n",
        "      aSM1, aSM2, bSM1, bSM2,\n",
        "      aBuffer1, aBuffer2, bBuffer1, bBuffer2\n",
        "    );\n",
        "    if (likely(itr < nIt - 1)){\n",
        "      load_ab_tt(\n",
        "        A, B, \n",
        "        aBuffer1, aBuffer2, bBuffer1, bBuffer2,\n",
        "        bid, gStartx, gStarty, gStartk + 16,\n",
        "        M, N, K\n",
        "      );\n",
        "    }\n",
        "    // synchroznie threads in order make sure tiles of A and B are fully\n",
        "    // loaded to shared memory.\n",
        "    __syncthreads();\n",
        "\n",
        "    // Each thread computes 8 x 8 matrix multiplication\n",
        "    // Accumulate intermediate results in cCache\n",
        "    // aSM1, bSM1, aSM2, bSM2 are consumed\n",
        "    thread_matmul_v3(aSM1, bSM1, cCache, vx, vy);\n",
        "    thread_matmul_v3(aSM2, bSM2, cCache, vx, vy);\n",
        "\n",
        "    // synchronize threads to signal that shared memory is consumed.\n",
        "    __syncthreads();\n",
        "  }\n",
        "  \n",
        "  // At the end of main loop, store cCache to C\n",
        "  //write_c(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "  write_c_v3(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"BMMCUDAv2_5.cu\", \"w\") as f:\n",
        "  f.write(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZvX6kh9Pt4_",
        "cellView": "form"
      },
      "source": [
        "#@title BMMv2.5\n",
        "import torch\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class BMMCUDAv2_5(CustomKernel): \n",
        "  def __init__(self, m=None, n=None, k=None, patch_m=4, patch_n=4):\n",
        "    super(BMMCUDAv2_5, self).__init__()\n",
        "    self.m = m\n",
        "    self.n = n\n",
        "    self.k = k\n",
        "    self.patch_m = patch_m\n",
        "    self.patch_n = patch_n\n",
        "    \n",
        "    with open(\"bmm_helpers.cu\", \"r\") as f:\n",
        "      helpers = f.read()\n",
        "\n",
        "    with open(\"BMMCUDAv2_5.cu\",'r') as f: ###\n",
        "      self.kernel = helpers + f.read()\n",
        "      \n",
        "    self.kernel = (self.kernel\n",
        "      .replace(\"_M_\", str(m) if m else \"M\")\n",
        "      .replace(\"_N_\", str(n) if n else \"N\")\n",
        "      .replace(\"_K_\", str(k) if k else \"K\")\n",
        "      .replace(\"_PM_\", str(self.patch_m))\n",
        "      .replace(\"_PN_\", str(self.patch_n))\n",
        "      .replace(\"__DISTANCE_FN__\", \"madd\")\n",
        "    )\n",
        "    \n",
        "    self._fn_tt = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"bmm_tt\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "    self._fn_nn = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"bmm_nn\",\n",
        "      backend='nvcc',\n",
        "      options=(\n",
        "        '--maxrregcount=128',\n",
        "        '--use_fast_math',\n",
        "        #'-Xptxas',\n",
        "        #'-dlcm=cg',\n",
        "      )\n",
        "    )\n",
        "    # print(self._fn_nn.attributes)\n",
        "    self._fn_tn = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"bmm_tn\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "    self._fn_nt = cp.RawKernel(\n",
        "      code=self.kernel,\n",
        "      name=\"bmm_nt\",\n",
        "      backend='nvcc',\n",
        "      options=('--maxrregcount=128', '--use_fast_math')\n",
        "    )\n",
        "\n",
        "  def _call_nn(self, A, B):\n",
        "    \"\"\"\n",
        "      Performs C = A @ B\n",
        "      A: shape = [l, m, k]\n",
        "      B: shape = [l, k, n]\n",
        "      returns C: shape = [l, m, n]\n",
        "    \"\"\"\n",
        "    l, m, k = A.shape\n",
        "    l, k, n = B.shape\n",
        "\n",
        "    C = torch.zeros([l, m, n], device=\"cuda:0\", dtype=A.dtype)\n",
        "\n",
        "    threads_per_block = (256,)\n",
        "    #blocks_per_grid = (math.ceil(n/128), math.ceil(m/128), l)\n",
        "    \n",
        "    n_ = math.ceil(n/(128*self.patch_n))\n",
        "    m_ = math.ceil(m/(128*self.patch_m))\n",
        "    blocks_per_grid = (self.patch_n*self.patch_m, n_ * m_, l)\n",
        "    # print(blocks_per_grid, m_, n_)\n",
        "\n",
        "    self._fn_nn(\n",
        "      grid=blocks_per_grid,\n",
        "      block=threads_per_block,\n",
        "      args=[\n",
        "        A.data_ptr(),\n",
        "        B.data_ptr(),\n",
        "        C.data_ptr(),\n",
        "        m, n, k,\n",
        "      ],\n",
        "      stream=self.stream\n",
        "    )\n",
        "    return C\n",
        "\n",
        "  def _call_tt(self, A, B):\n",
        "    l, m, k = A.shape\n",
        "    l, k, n = B.shape\n",
        "\n",
        "    C = torch.zeros([l, m, n], device=\"cuda:0\", dtype=A.dtype)\n",
        "\n",
        "    threads_per_block = (256,)\n",
        "    #blocks_per_grid = (math.ceil(n/128), math.ceil(m/128), l)\n",
        "    \n",
        "    n_ = math.ceil(n/(128*self.patch_n))\n",
        "    m_ = math.ceil(m/(128*self.patch_m))\n",
        "    blocks_per_grid = (self.patch_n*self.patch_m, n_ * m_, l)\n",
        "    # print(blocks_per_grid, m_, n_)\n",
        "\n",
        "    self._fn_tt(\n",
        "      grid=blocks_per_grid,\n",
        "      block=threads_per_block,\n",
        "      args=[\n",
        "        A.data_ptr(),\n",
        "        B.data_ptr(),\n",
        "        C.data_ptr(),\n",
        "        m, n, k,\n",
        "      ],\n",
        "      stream=self.stream\n",
        "    )\n",
        "    return C\n",
        "\n",
        "  def _call_tn(self, A, B):\n",
        "    l, m, k = A.shape\n",
        "    l, k, n = B.shape\n",
        "\n",
        "    C = torch.zeros([l, m, n], device=\"cuda:0\", dtype=A.dtype)\n",
        "\n",
        "    threads_per_block = (256,)\n",
        "    #blocks_per_grid = (math.ceil(n/128), math.ceil(m/128), l)\n",
        "    \n",
        "    n_ = math.ceil(n/(128*self.patch_n))\n",
        "    m_ = math.ceil(m/(128*self.patch_m))\n",
        "    blocks_per_grid = (self.patch_n*self.patch_m, n_ * m_, l)\n",
        "    # print(blocks_per_grid, m_, n_)\n",
        "\n",
        "    self._fn_tn(\n",
        "      grid=blocks_per_grid,\n",
        "      block=threads_per_block,\n",
        "      args=[\n",
        "        A.data_ptr(),\n",
        "        B.data_ptr(),\n",
        "        C.data_ptr(),\n",
        "        m, n, k,\n",
        "      ],\n",
        "      stream=self.stream\n",
        "    )\n",
        "    return C\n",
        "\n",
        "  def _call_nt(self, A, B):\n",
        "    l, m, k = A.shape\n",
        "    l, k, n = B.shape\n",
        "\n",
        "    C = torch.zeros([l, m, n], device=\"cuda:0\", dtype=A.dtype)\n",
        "\n",
        "    threads_per_block = (256,)\n",
        "    #blocks_per_grid = (math.ceil(n/128), math.ceil(m/128), l)\n",
        "    \n",
        "    n_ = math.ceil(n/(128*self.patch_n))\n",
        "    m_ = math.ceil(m/(128*self.patch_m))\n",
        "    blocks_per_grid = (self.patch_n*self.patch_m, n_ * m_, l)\n",
        "    # print(blocks_per_grid, m_, n_)\n",
        "\n",
        "    self._fn_nt(\n",
        "      grid=blocks_per_grid,\n",
        "      block=threads_per_block,\n",
        "      args=[\n",
        "        A.data_ptr(),\n",
        "        B.data_ptr(),\n",
        "        C.data_ptr(),\n",
        "        m, n, k,\n",
        "      ],\n",
        "      stream=self.stream\n",
        "    )\n",
        "    return C\n",
        "\n",
        "  def __call__(self, A, B):\n",
        "    \"\"\"\n",
        "      Performs C = f(A) @ f(B)\n",
        "      A: torch.Tensor, shape : [l, m, k] or [l, k, m]\n",
        "      B: torch.Tensor, shape : [l, n, k] or [l, k, n]\n",
        "      returns C: torch.Tensor, shape : [l, m, n]\n",
        "      mode: str, default: \"nn\"\n",
        "      Notes:\n",
        "        f() and g() are determined by mode\n",
        "        \"nn\" --> A @ B\n",
        "        \"tt\" --> A.T @ B.T\n",
        "        \"nt\" --> A @ B.T\n",
        "        \"tn\" --> A.T @ B\n",
        "    \"\"\"\n",
        "    assert len(A.shape) == len(B.shape)\n",
        "    # A = A.contiguous()\n",
        "    # B = B.contiguous()\n",
        "    if len(A.shape) == 2 and len(B.shape) == 2:\n",
        "      A = A[None]\n",
        "      B = B[None]\n",
        "    elif len(A.shape) == 3 and len(B.shape) == 3:\n",
        "      pass\n",
        "    else:\n",
        "      raise ValueError(\"A and B need to be 2d or 3d\")\n",
        "    assert A.shape[0] == B.shape[0]\n",
        "    assert A.shape[2] == B.shape[1]\n",
        "    assert A.dtype == B.dtype\n",
        "    assert A.dtype in [torch.float, torch.half]\n",
        "    assert A.device.type == B.device.type == \"cuda\"\n",
        "\n",
        "    mode = [None, None]\n",
        "    if A.stride()[-1] == 1:\n",
        "      mode[0] = \"n\"\n",
        "    elif A.stride()[-2] == 1:\n",
        "      mode[0] = \"t\"\n",
        "    if B.stride()[-1] == 1:\n",
        "      mode[1] = \"n\"\n",
        "    elif B.stride()[-2] == 1:\n",
        "      mode[1] = \"t\"\n",
        "\n",
        "    if mode == [\"n\", \"n\"]:\n",
        "      C = self._call_nn(A, B)\n",
        "    elif mode == [\"t\",\"t\"]:\n",
        "      C = self._call_tt(A, B)\n",
        "    elif mode == [\"t\", \"n\"]:\n",
        "      C = self._call_tn(A, B)\n",
        "    elif mode == [\"n\", \"t\"]:\n",
        "      C = self._call_nt(A, B)\n",
        "\n",
        "    if len(A.shape) == 2 and len(B.shape) == 2:\n",
        "      C = C[0]\n",
        "    return C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0hHKYk-sAN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "bd358fe1-2da3-4cad-bba4-290ba33415f0"
      },
      "source": [
        "#@title test MinBMM\n",
        "def test_min_bmm(l, m, n, k, mode=\"nn\", n_iter=1, dim=1, verbose=0):\n",
        "  print(f\"l={l}  m={m}  n={n}  k={k}\")\n",
        "  if mode[0] == \"n\":\n",
        "    A = torch.randn(l, m, k, device=\"cuda:0\")\n",
        "  elif mode[0] == \"t\":\n",
        "    A = torch.randn(l, k, m, device=\"cuda:0\")\n",
        "  \n",
        "  if mode[1] == \"n\":\n",
        "    B = torch.randn(l, k, n, device=\"cuda:0\")\n",
        "  elif mode[1] == \"t\":\n",
        "    B = torch.randn(l, n, k, device=\"cuda:0\")\n",
        "  custom_bmm_v2_5 = BMMCUDAv2_5(patch_m=4, patch_n=4)\n",
        "  custom_min_bmm = MinBMMCUDA(\n",
        "    patch_m=4, patch_n=4,\n",
        "    distance=\"inner\")\n",
        "  flop = l * m * n * k * 2 + l * m * n\n",
        "\n",
        "  if mode[0] == \"t\":\n",
        "    At = A.transpose(1, 2)\n",
        "  else: \n",
        "    At = A\n",
        "  if mode[1] == \"t\":\n",
        "    Bt = B.transpose(1, 2)\n",
        "  else:\n",
        "    Bt = B\n",
        "  #warmup\n",
        "  for i in range(n_iter):\n",
        "    C = torch.bmm(At, Bt)\n",
        "    C.min(dim = dim)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "  tm = time()\n",
        "  for i in range(n_iter):\n",
        "    C = torch.bmm(At, Bt)\n",
        "    C_v, C_i = C.min(dim = dim)\n",
        "    torch.cuda.synchronize()\n",
        "  time_cost_0 = (time() - tm) / n_iter\n",
        "  flops0 = (flop / time_cost_0) / 1000**4\n",
        "  mem_0 = C.numel() * 4 + C_v.numel()*4 + C_i.numel() * 8\n",
        "\n",
        "  if verbose > 0:\n",
        "    print(\"time spent for torch.bmm + min:\", time_cost_0)\n",
        "    print(\"tflops:\", flops0)\n",
        "  else:\n",
        "    del C_v, C_i \n",
        "  del C\n",
        "\n",
        "  # warmup\n",
        "  for i in range(n_iter):\n",
        "    C2 = custom_bmm_v2_5(At, Bt)\n",
        "    C2.min(dim = dim)\n",
        "    torch.cuda.synchronize()\n",
        "  tm = time()\n",
        "  for i in range(n_iter):\n",
        "    C2 = custom_bmm_v2_5(At, Bt)\n",
        "    C2_v, C2_i = C2.min(dim = dim)\n",
        "    torch.cuda.synchronize()\n",
        "  time_cost_2 = (time() - tm) / n_iter\n",
        "  flops2 = (flop / time_cost_2) / 1000**4\n",
        "  mem_2 = C2.numel() * 4 + C2_v.numel()*4 + C2_i.numel() * 8\n",
        "  if verbose > 0:\n",
        "    print(\"time spent for custom_bmm_v2_5 + min:\", time_cost_2)\n",
        "    print(\"tflops:\", flops2)\n",
        "  del C2, C2_v, C2_i\n",
        "\n",
        "  # warmup\n",
        "  for i in range(n_iter):\n",
        "    custom_min_bmm(At, Bt, dim=dim)\n",
        "    torch.cuda.synchronize()\n",
        "  tm = time()\n",
        "  for i in range(n_iter):\n",
        "    C1_v, C1_i = custom_min_bmm(At, Bt, dim=dim)\n",
        "    torch.cuda.synchronize()\n",
        "  time_cost_1 = (time() - tm) / n_iter\n",
        "  flops1 = (flop / time_cost_1) / 1000**4\n",
        "  mem_1 = C1_v.numel()*4 + C1_i.numel() * 8\n",
        "  if verbose > 0:\n",
        "    print(\"time spent for custom_min_bmm:\", time_cost_1)\n",
        "    print(\"tflops:\", flops1)\n",
        "  else:\n",
        "    del C1_v, C1_i\n",
        "\n",
        "  if verbose > 0:\n",
        "    val_dif = (C1_v - C_v).abs()\n",
        "    idx_dif = (C1_i != C_i)\n",
        "    print(\"Max Val Error\", val_dif.max())\n",
        "    print(\"Val Error:\", val_dif.sum())\n",
        "    print(\"Idx Error:\", idx_dif.sum())\n",
        "    print(\"ratio:\", time_cost_1 / time_cost_0)\n",
        "\n",
        "\n",
        "  return time_cost_0, time_cost_1, time_cost_2\n",
        "  # return mem_0, mem_1, mem_2\n",
        "  \n",
        "_ = test_min_bmm(1, 1024, 1024*128, 64,\n",
        "    mode=\"nn\", dim=2, n_iter=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l=1  m=1024  n=131072  k=64\n",
            "time spent for torch.bmm + min: 0.009221601486206054\n",
            "tflops: 1.877557486939652\n",
            "time spent for custom_bmm_v2_5 + min: 0.011105585098266601\n",
            "tflops: 1.5590431984265687\n",
            "time spent for custom_min_bmm: 0.004831290245056153\n",
            "tflops: 3.5837397535197684\n",
            "Max Val Error tensor(0., device='cuda:0')\n",
            "Val Error: tensor(0., device='cuda:0')\n",
            "Idx Error: tensor(0, device='cuda:0')\n",
            "ratio: 0.523910109570766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXkMqJGQyPtj"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"imgs\"):\n",
        "  os.mkdir(\"imgs\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "hVrWrpvnCM_i"
      },
      "source": [
        "#@title Grid test MinBMM (Memory Footprint)\n",
        "ls = [64]\n",
        "ms = [256*i for i in range(1, 12 + 1)]\n",
        "ns = ms\n",
        "ks = [64]\n",
        "mode=\"nn\"\n",
        "\n",
        "custom_res = dict()\n",
        "cublass_res = dict()\n",
        "custommin_res = dict()\n",
        "for l in ls:\n",
        "  for m in ms:\n",
        "    for k in ks:     \n",
        "      res = test_min_bmm(l, m, m, k, mode=mode, n_iter=25)\n",
        "      cublass_res[m] = res[0] / 1024**2\n",
        "      custom_res[m] = res[1] / 1024**2\n",
        "      custommin_res[m] = res[2] / 1024**2\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 10) )\n",
        "plt.tight_layout()\n",
        "plt.xlabel(\"N\", fontsize=17)\n",
        "plt.ylabel(\"MB\", fontsize=17)\n",
        "title = f\"A[{l},N,{k}] B[{l},{k},N]\"\n",
        "plt.title(title)\n",
        "plt.rcParams[\"font.size\"] = \"17\"\n",
        "plt.grid()\n",
        "colors = [\"red\", \"blue\", \"green\"]\n",
        "labels = [\"custom_min_bmm\", \"torch.bmm + min\", \"custom_bmm + min\"]\n",
        "for i, res in enumerate([custom_res, cublass_res]):\n",
        "  res_x = list(res.keys())\n",
        "  res_y = list(res.values())\n",
        "  plt.plot(\n",
        "    res_x,\n",
        "    res_y,\n",
        "    color=colors[i],\n",
        "    label=labels[i],\n",
        "  )\n",
        "\n",
        "plt.legend()\n",
        "plt.savefig(\"imgs/min_bmm_\" + title + \"_memory\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qAefcFH-8xN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "4a1b48b3-b46d-42c1-c4d7-02ef2c40df8c"
      },
      "source": [
        "#@title Grid test MinBMM (Runtime)\n",
        "ls = [1]\n",
        "ms = [256*i for i in range(1, 65)]\n",
        "ns = ms\n",
        "ks = [64]\n",
        "mode=\"nn\"\n",
        "\n",
        "custom_res = dict()\n",
        "cublass_res = dict()\n",
        "custommin_res = dict()\n",
        "for l in ls:\n",
        "  for m in ms:\n",
        "    for k in ks:     \n",
        "      res = test_min_bmm(l, m, m, k, mode=mode, n_iter=25)\n",
        "      cublass_res[m] = res[0]# *1e3\n",
        "      custom_res[m] = res[1]# * 1e3\n",
        "      custommin_res[m] = res[2]#*1e3\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 10) )\n",
        "plt.tight_layout()\n",
        "plt.xlabel(\"N\", fontsize=17)\n",
        "plt.ylabel(\"milliseconds\", fontsize=17)\n",
        "title = f\"A[{l},N,{k}] B[{l},{k},N]\"\n",
        "plt.title(title)\n",
        "plt.rcParams[\"font.size\"] = \"17\"\n",
        "plt.grid()\n",
        "colors = [\"red\", \"blue\", \"green\"]\n",
        "labels = [\"custom_min_bmm\", \"torch.bmm + min\", \"custom_bmm + min\"]\n",
        "for i, res in enumerate([custom_res, cublass_res, custommin_res]):\n",
        "  res_x = list(res.keys())\n",
        "  res_y = list(res.values())\n",
        "  plt.plot(\n",
        "    res_x,\n",
        "    res_y,\n",
        "    color=colors[i],\n",
        "    label=labels[i],\n",
        "  )\n",
        "\n",
        "plt.legend()\n",
        "plt.savefig(\"imgs/min_bmm_\" + title)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l=1  m=256  n=256  k=64\n",
            "l=1  m=512  n=512  k=64\n",
            "l=1  m=768  n=768  k=64\n",
            "l=1  m=1024  n=1024  k=64\n",
            "l=1  m=1280  n=1280  k=64\n",
            "l=1  m=1536  n=1536  k=64\n",
            "l=1  m=1792  n=1792  k=64\n",
            "l=1  m=2048  n=2048  k=64\n",
            "l=1  m=2304  n=2304  k=64\n",
            "l=1  m=2560  n=2560  k=64\n",
            "l=1  m=2816  n=2816  k=64\n",
            "l=1  m=3072  n=3072  k=64\n",
            "l=1  m=3328  n=3328  k=64\n",
            "l=1  m=3584  n=3584  k=64\n",
            "l=1  m=3840  n=3840  k=64\n",
            "l=1  m=4096  n=4096  k=64\n",
            "l=1  m=4352  n=4352  k=64\n",
            "l=1  m=4608  n=4608  k=64\n",
            "l=1  m=4864  n=4864  k=64\n",
            "l=1  m=5120  n=5120  k=64\n",
            "l=1  m=5376  n=5376  k=64\n",
            "l=1  m=5632  n=5632  k=64\n",
            "l=1  m=5888  n=5888  k=64\n",
            "l=1  m=6144  n=6144  k=64\n",
            "l=1  m=6400  n=6400  k=64\n",
            "l=1  m=6656  n=6656  k=64\n",
            "l=1  m=6912  n=6912  k=64\n",
            "l=1  m=7168  n=7168  k=64\n",
            "l=1  m=7424  n=7424  k=64\n",
            "l=1  m=7680  n=7680  k=64\n",
            "l=1  m=7936  n=7936  k=64\n",
            "l=1  m=8192  n=8192  k=64\n",
            "l=1  m=8448  n=8448  k=64\n",
            "l=1  m=8704  n=8704  k=64\n",
            "l=1  m=8960  n=8960  k=64\n",
            "l=1  m=9216  n=9216  k=64\n",
            "l=1  m=9472  n=9472  k=64\n",
            "l=1  m=9728  n=9728  k=64\n",
            "l=1  m=9984  n=9984  k=64\n",
            "l=1  m=10240  n=10240  k=64\n",
            "l=1  m=10496  n=10496  k=64\n",
            "l=1  m=10752  n=10752  k=64\n",
            "l=1  m=11008  n=11008  k=64\n",
            "l=1  m=11264  n=11264  k=64\n",
            "l=1  m=11520  n=11520  k=64\n",
            "l=1  m=11776  n=11776  k=64\n",
            "l=1  m=12032  n=12032  k=64\n",
            "l=1  m=12288  n=12288  k=64\n",
            "l=1  m=12544  n=12544  k=64\n",
            "l=1  m=12800  n=12800  k=64\n",
            "l=1  m=13056  n=13056  k=64\n",
            "l=1  m=13312  n=13312  k=64\n",
            "l=1  m=13568  n=13568  k=64\n",
            "l=1  m=13824  n=13824  k=64\n",
            "l=1  m=14080  n=14080  k=64\n",
            "l=1  m=14336  n=14336  k=64\n",
            "l=1  m=14592  n=14592  k=64\n",
            "l=1  m=14848  n=14848  k=64\n",
            "l=1  m=15104  n=15104  k=64\n",
            "l=1  m=15360  n=15360  k=64\n",
            "l=1  m=15616  n=15616  k=64\n",
            "l=1  m=15872  n=15872  k=64\n",
            "l=1  m=16128  n=16128  k=64\n",
            "l=1  m=16384  n=16384  k=64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6EAAAJyCAYAAAA1hsYfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3zP5f/H8cdlZjPMhiGnzSGiRPh2pEkOlXIYUaLNua9vOjkrX8uXmKIo1bcMJR0lfpSKsqKSEt8O5JuQrAhzmONO1++Pz7bvzrb57PPe4Xm/3T637XO939d1vd7XZyuvXe/3dRlrLSIiIiIiIiKeUM7pAERERERERKTsUBIqIiIiIiIiHqMkVERERERERDxGSaiIiIiIiIh4jJJQERERERER8RgloSIiIiIiIuIxSkJFRERERETEY5SEioiIo4wxHY0xNsurvNNxFUfGmJAcxiqkiPvcl6W/YUXZX0lmjInJMlaRTsckIlIcKQkVEZEiYYyJyPCP8Z75qPIf4PHUV0qWtvoYY+YbYz43xhxPbTOmkHEtyRDXXbmcc3vq8SWFaL+lMeYVY8x+Y8x5Y8xhY8xXxpgx+ajb2RiTktr3Mzmccpz/jdFvBYwr43WnvVKMMceMMZuMMX83xnjl0URav99labe5MSbSGLPSGLPXHcmxMaacMeZeY8ynxpijxphzqeO5yhhzbT7qv5ohjtYF7Dut3iFjjH8u5yxPPadjlkNLcI3RqoL0KSJS1ugvzSIiUlTuAyxggJFc+B/m2621kbkcmwK0Ak4D+4Cq7gmRWcaYldbac+5ozBgzHHgBOAusAfbiirUZEAbMyaNuNVxJzGmgck7nWGuPA5Gp53cEggsR5ipge+r33kB9oCfwPHA9MCiXviNzaa8bMBXXHw52A/FAlULEBYAxxg94F7gF+AV4EzgB1AauA9oCm/Oo3w/XNZwil3HMp5rAo8CE/Faw1i5JjSEC15iKiEgOlISKiIjbpc4+XQOsAwKBbsaYEGvtvkI2+TAQiyvJaQH84IYwfwEuBR4BnrjYxowxnYB/40rwbrPWHsxy3PsCTbwI+KbGctHx5GFlWrKUJnXW8kdgoDFmSgE/p7W4ksLvrbVnjDHf4koUC+t5XAnoDOCf1tqss+K5jqMxph6ucXwDqAOEFjKGM7hmnR80xrxord1byHZERCQHuh1XRESKwsjUr4tSX+WA4YVtzFq7wVr736wJyUWaBRwDJhljaruhvadSv96TNQEFsNYm5lbRGBMO3AmMAv50QywFkpp07kp9G1TAurustZuttWcuNg5jTCsgHNhsrX0sp887t3E0xhjgFVwJ5D8uMpREXLOgPsDsi2xLRESyUBIqIiJuZYypDNwDxAHvAa/juj11SD5mAz0pDtfze5WB6RfTkDGmBXAV8B9r7U5jzNXGmEeMMeNSny+tkEfdEGA+8Ia19u2LiaOwjDHBuG4ZPgn87EQMqe5J/fqmMaaiMaavMWaiMeYfqQlqXh4BOgFDrLXH3BDLq7ief+1rjGnvhvZERCSVbscVERF3uwfXM4HPWWvPA+eNMStSy3sCy50MLovncc0+DjbGPGut/U8h27km9es+Y8zbuGY1M9pvjOlrrf0mY6ExphywFNfzixc7e5dfvTIsGlQe1zOhPYBzwFBrbbyH4shJ2jj64UqGG2Q8aIx5F7g366yrMeZKXLfvvmCt/dgdgVhrU4wxjwAxwNPGmKuttdYdbYuIlHWaCRUREXfLeCsuWb6/z8Ox5Cn11s5xuP5/+PRFNFUz9esdwM3AAKAaEAI8iSuZ+sAYUyNLvUlAe1zJnztm7/KjJ66FhKbiuuX0XlyzwW8B3+RRzxPSxvFfuBagaoMrtmuBb4E+uP5wkM4Y4wMsA37H9Vm6jbX2M1yz+e3IZcEmEREpOCWhIiLiNsaYq3HdlrrdWrstw6ENuFaK7WSMaeJIcLmw1v4f8ClwUz63kslJ2v9PvYB/WGvfsNYes9b+Zq0dD6wAapDhuVhjTFtcieCL1toPC38FBTbYWmustSY13vrAGGAY8E3q4j5OSRvHOOAOa+02a+1pa+3XuGZrTwGDjDF1M9SZBTQHwq21p4sgpvFAAvBE6sq9IiJykZSEioiIO6XNdGacBSX1NsbFuLZrGeHpoPLhEVxbjDxZyOdWj6d+teS8Fc17qV+vBjDGlMc1e7cfGFuI/tzCWptirT1grZ2Pa/uYOrhmR52SNo6fWGtPZjxgrf0T+BrXv13aARhjbgQeBJ601n5ZFAFZa3cDzwJ1cSWkIiJykZSEioiIWxhjAoD+qW/nG2NsxhcwLfVYRF4L9Tgh9VnQRbi2bLm/EE2kLeZzzlp7NofjabfaVkz9WhnXQkCNgVNZxmlx6jkPppbFFCKewvgq9eu1HuovJ2njeDyX41nHsQ2uP2xMzOHnLW17lm2pZREXEdd04AgwLsssrIiIFIIWJhIREXcZhGtBmR+ALbmccwNwGa5n+97wUFz59RhwF/BP4KEC1t2M61bRysaYxtbaX7McvyL1a9p+k+eB6FzauhS4Efgptd1duZznbtVSvzr5B+p1uJ5RvSKX45enfk0bxx/JfRy7A7VxzULHAf8tbFDW2uPGmEjgOWBmYdsREREXJaEiIuIuaQsSjbHWrsvpBGNMb1zPR95HESehqTOIobiegVxyofOttYeMMTNxrbKa6y2pqbNsAA1T99fEWnvWGPMy8DAQZYy5y1qblHp+vdRycG1XQ+ps6bBc2o/AlYSut9YWNBkuFGOML/+bAY7xQH8RuGZ8P7PWdsxwaAWuZzzbG2N6W2vfy1BnOK5nP3/BtUgR1tr1wPpc+ojBlYROs9Zuz3IshNRENvXZ2Pz4N64VjAcCWf/IICIiBaAkVERELpoxpgOuWao95JIUpFoN/AncaIy5zFqbrz0pjTG9gF6pbwNSv15mjFmSdo61NiJLtbQZvcT89JFqLq5k+tJc4sg4S5i13am4ksc+wHZjzCe4tqrpBQTiem5xYwFiKSoZt2gpB1wC3IbredDdFHDP1NQVf5/KUJTW9lPGmFOp3y+01m7KcE6On4219owxZhCwFnjXGLMa1wzm5cCtQDwwyFqbXJAYc5DWf1J+K1hrk4wxY4APgGK1uJaISEmjJFRERNwhbRY0Oq+9FFP/IR+N69bX+8j/ba+tgfAsZbWylEWkfZOaLF6B6xnCNfnsA2vtOWPMBHKfpb0y9eun1trYLHXjjTGhuBav6Y9rTBKAbbj2TH0nv3EUsZ6przSncc0uLgTmZF0QKB8qk/2zAVcyniYGyJiEpo3jq1krWWs3GGPaAVOAjrgS5L+AV4AZ1tpfChhfTnLtPy/W2rXGmI+Abm6IQUSkzDLad1lERJxkjOmIawuXV3KYzSxsm61xJX+PWWtnuKPN1HYfwrWfaHtr7RfuareQscTgut04/bbgIupnHxBcgNtW89PmdsAXuNwNs5qF6f8ZYBTQtCjGLsPtxo9bayPd3b6ISEmn1XFFRKS4CM+wuunF3qnTETgKzL/4sLK1+7FTCagxJiSH1V891XfaZ5Pjs6wFaKcarpnIx51IQFN1BBa7OwE1xsRkWeFYRERyoJlQERFxVOrziRFZiqdZa1M8Hkwxl7oNTtZbmJ+x1ua2pYk7+nyI/z2HC/B/1trviqq/kix1BjQkQ1GMtTbGkWBERIoxJaEiIiIiIiLiMbodV0RERERERDxGq+MWgRo1atiQkJAi7+f06dNUqlSpyPuRzDTuztHYO0Pj7gyNu3M09s7QuDtD4+6c0j72W7duPWKtDcrpmJLQIhASEsK3335b5P3ExMTQsWPHIu9HMtO4O0dj7wyNuzM07s7R2DtD4+4MjbtzSvvYG2N+y+2YbscVERERERERj1ESKiIiIiIiIh6jJFREREREREQ8RkmoiIiIiIiIeIySUBEREREREfEYJaEiIiIiIiLiMUpCRURERERExGO0T6hDzp07x+HDhzl37hxJSUmFaqNq1ars3LnTzZHJhWjcnVPUY+/t7U3NmjXx9/cvsj5EREREyjoloQ44ceIEhw4dIigoiNq1a1O+fHmMMQVuJz4+nipVqhRBhJIXjbtzinLsrbWcPXuW2NhYACWiIiIiIkVEt+M64MiRI9SrV4/AwEC8vb0LlYCKiHsZY/Dz86Nu3br89ddfTocjIiIiUmopCXVAQkICFStWdDoMEclBxYoVSUxMdDoMERERkVJLSahDNPspUjzpd1NERESkaCkJFREREREREY9REioiIiIiIiIeoyRUpIQJCQkhIiKiSNvv3LlzkbUvIiIiImWbklApFbZv305kZCT79+93OhQREREREcmD9gmVUmH79u08/vjjdO7cmQYNGjgdTpHatWsX5crp70ciIiIiUjIpCRUpYXx8fJwOQURERESk0DSdIkXm0KFD/OMf/6BBgwb4+PhQr149BgwYQGxsLDExMRhjiImJyVbPGENkZGT6+9OnTzNhwgQaN26Mr68v1atX59prr2X58uUAREZGMnjwYAA6dOiAMSZb24sWLaJVq1b4+voSFBTEoEGDOHDgQKZ+IyIiKF++PAcPHuTOO+/E39+fmjVrMmXKFKy1HDp0iP79+1O/fn0CAwMZM2YMKSkpBRqTyMhIjDHs2LGD4cOHU716dQICAhg5ciQJCQmcOnWKkSNHEhQUROXKlQkPD+fs2bOZ2sj6TGjaWC5dupQ5c+YQHByMr68v1157Ld99912B4svo888/5+qrr6ZixYqEhIQwd+7cTMf37duHMYbp06ezePFimjVrRsWKFbn++uv5/vvvAVi6dCnNmzfH19eXNm3a8M0332RqI79jHhAQQGBgIJMnTy7wmIuIiIhI8aKZUCkShw4d4pprruGPP/5g2LBhtGrVisOHD/P++++ze/fuArU1atQo3njjDUaNGsUVV1zByZMn2b59O19//TV9+/YlLCyMP//8k5deeokpU6bQtGlTAJo3bw7ArFmzmDRpEu3bt2f27NnExsYyf/58Pv/8c7Zt20a1atXS+7LWcsstt9CmTRuioqJYvXo106dPx9/fn6VLl9KuXTumTp3KunXrmDt3Ls2aNWPEiBEFHp+BAwcSEhLC9OnT2bRpEy+99BKVKlXixx9/pHLlykybNo0vvviCV199lbp16/LEE09csM158+Zx/vx5HnjgAZKSknjyySfp3bs3u3fvxtvbu0Dx/fbbb/To0YOIiAgGDRrEihUrGDNmDImJiUyYMCHTuStWrODkyZOMHDmSpKQkZs2axa233sq0adOYOXMmI0aMIDk5mVmzZtG3b19+/fVXypf/33968jPmM2fOZPXq1Tz33HO0bNmyUGMuIiIiIsWEtVYvN7/atm1r87Jjx448j+fXyZMn3dJOURg8eLAF7KeffprtWEpKit2wYYMF7IYNG7IdB+zUqVPT3wcEBNhRo0bl2d/ixYstYDdu3Jip/PDhw9bHx8d26NDBJiYmppevWbPGAnbcuHHpZeHh4Rawjz76aHpZYmKirVu3rjXG2ClTplhrXeOeVn7NNdfkGVdWU6dOtYC95557MpVfffXV1hhjBw0alK28Vq1amcqCg4NteHh4+vu0sWzYsKE9c+ZMevl7771nAbtmzZoCxRgcHGwBu2jRovSypKQk26FDB1uxYkV77Ngxa621e/futYCtWrWqPXz4cPq5zz//vAVstWrV7JEjR7KVr127Nr0sv2OeVl6nTp0Cj3lhuOt3tLTI6fdUip7G3Tkae2do3J2hcXdOaR974FubS76kmdDi5KGHYPv2fJ9eMTkZvLyKJpbWreGZZwpVNSUlhRUrVtClSxduuummbMeNMQVqLyAggK+//prff/+d+vXrF6ju+vXrOX/+PA899FCm2bfu3bvTokUL1qxZw+zZszPVGTlyZPr35cuXp127dqxatYrhw4dnK//yyy8LFE9OfQBcd911bNmyJVMfGcvPnDmDn59fnm1GRERQsWLF9PehoaEA7Nmzp8DxVa9enUGDBqW/9/LyYvTo0fTr149PPvmEPn36pB/r06cPNWrUyBQzQK9evahevXq28pziye+YX3XVVWzZsqXA1yMiIiJSGiUkJ1DBq4LTYRSYngkVtzt8+DAnTpygZcuWbmlvzpw57Ny5k+DgYFq3bs24cePYunVrvuru27cPgMsuuyzbsRYtWrB3795MZeXKlaNevXqZygICAnItP3bsWAGu5H+yruAbEBCQZ3l++gkODs70PjAwEIC4uLgCx9eoUaNMSTtAs2bNALKN2cVeS0HGvGrVqoUecxEREZHSJPZkLNdFX8eCLQucDqXANBNanBRw5vFsfDxVqlQpomCKVm6zocnJydnKwsLCaN++PatXr2b9+vUsWrSIOXPmMGPGDCZNmuT2uHKKLbdy150GBeeVywx2buX56edi6l6Mi70WT425iIiISGmx/eB2bn/9dk6cP0FIQIjT4RSYZkLF7YKCgvD39+eHH37I9Zy0Wbrjx49nKk+bucyqZs2aDB06lDfeeIMDBw4QGhpKZGQkiYmJQO5JbUhICAA///xztmM7d+6kYcOGF7qcMmnPnj0kJSVlKtu1axeAxkxERETEQat3rab9ovYYY9g0eBPdm3Z3OqQCUxIqbleuXDn69OnDunXr2LBhQ7bj1lpCQkLw8vLKdvy5557L9D45OZkTJ05kKqtYsSLNmjUjISGB06dPA1CpUiUge1LbpUsXfHx8mDdvXqakau3atfz000/ccccdhb/QUuzo0aMsXbo0/X1ycjLPPvssvr6+dOrUycHIRERERMomay3PbH6Gnm/2pHlQc7YM20Kr2q2cDqtQdDuuFIknnniCdevW0a1bt/QtWuLi4vjggw+YPn06oaGh3H333SxYsABjDM2aNWPDhg3ZnjeMj4+nbt269O7dm1atWlGtWjW2bdvGwoULufXWW9OfM2zTpg3GGGbOnMnRo0fx8fGhU6dO1KxZk8jISCZNmsTNN99M375907doadCgQbbtRsSlSZMmPPzww3z//fc0btyYFStWsHHjRp544on0WWwRERER8YyklCQeWPsAL3z7AmHNw1jaeyl+3nkvWlmcKQmVIlG7dm22bNnC1KlTWblyJQsXLqRWrVqEhoZy6aWXAq59LRMTE4mOjqZcuXLcfvvtrF27lqCgoPR2/Pz8uP/++1m/fj3vv/8+58+fp0GDBkyePJnx48enn9eoUSPmz5/PnDlzGDp0KMnJyWzYsIGaNWsyceJEgoKCmDdvHmPHjqVKlSqEhYUxa9asTHuEyv8EBwcTHR3N2LFjeeGFF6hVqxZPPvkkY8eOdTo0ERERkTLlxLkT9F/en49+/Yjx149nZueZlDMl+4ZWo0U+3K9du3b222+/zfX4zp07ad68+UX3E1+CFyYqyTTuzvHU2Lvrd7S0iImJoWPHjk6HUeZo3J2jsXeGxt0ZGnfn5Gfs9x3fx+2v386uo7t4sfuLDG0z1DPBuYExZqu1tl1OxzQTKiIiIiIiUsx8feBrerzZg4TkBD4a+BGdGpaedTmUhIq4QVxcHAkJCXmeExQUlOu2JUUtOTmZw4cP53lOhQoVdHuyiIiISDHw9k9vE74ynDpV6vD+gPe5rEb2Pe9LMiWhIm4QFhbGZ599luc5e/fuTd8yxtN+//33C26tEhoaSkxMjGcCEhEREZFsrLXM3DSTRz99lBvq38DKu1ZSw6+G02G5nZJQETeYM2cOx44dy/Oc2rVreyianPtet25dnudo1VsRERER51hrGfZ/w1i0fRH3tLyH6B7R+JT3cTqsIqEkVMQN2rZt63QIefL19aVz585OhyEiIiIiuVi3Zx2Lti9i/PXjmdV5FsYYp0MqMiV7bV8REREREZFSYOammdStUpdpN00r1QkoKAkVERERERFx1OYDm4nZF8Mj1z1Sam/BzUhJqIiIiIiIiIOivogi0DeQEW1HOB2KRygJFRERERERcciOwztY+fNKRl89msoVKjsdjkcoCRUREREREXHI7C9m4+ftx+hrRjsdiscoCRUREREREXHA/hP7WfbDMoa3GV4q9wPNjZJQKZU6duxIkyZNCl0/MjISYwwHDhxwY1RlW0xMDMYYYmJinA5FREREpFiY+9VcAB657hGHI/EsJaHidtu3bycyMpL9+/c7HYqIiIiISLF0IvEEL3/3Mve0vIcGVRs4HY5HKQkVt9u+fTuPP/64klDJ5MYbb+Ts2bPceOONTociIiIi4rgVsSs4k3iGCTdMcDoUj1MSKiXG6dOnnQ6hxIuMjCQkJMSRvsuVK4evry/lyuk/OyIiIlK2nUo4xXux79Hrsl40D2rudDgep38NiltFRkYyePBgADp06IAxJttzgIsWLaJVq1b4+voSFBTEoEGDsj17GRERQfny5fn9998JCwsjICCA9u3bpx9/9913ad++PVWqVMHf35927doRHR2dLZ7du3fTrVs3KlWqRM2aNZk4cSIpKSn5vp7jx48THh5OYGAg/v7+3H333Rw+fDjTOWnPn+7atYuuXbtSuXJl6tWrx3PPPQfAL7/8wq233kqVKlWoXbs2UVFRmeqnPSu5dOlSZs+eTXBwMH5+fnTt2jV9Nnnu3Lk0bNgQX19fQkND+fXXX/N9De4SEhJC586d2bx5M9dffz1+fn40adKEd955B4AtW7bQoUMH/Pz8CA4O5pVXXsnxOjP+LKR9zocOHaJfv374+/sTGBjIsGHDOHv2rCcvT0RERMRjXtr6EvFJ8WVyFhSUhIqbhYWFMWKEa5PdKVOmsHTpUpYuXUrz5q6/8MyaNYuhQ4fi7+/P7NmzGTJkCMuXL+eGG24gLi4uU1vWWrp160aFChWYNWsWw4cPT2+jb9++nDlzhsmTJzNr1izatm3L6tWrM9WPj4+nc+fONGrUiDlz5nDDDTcQFRXFyy+/nO/rGThwIAcOHOBf//oXgwcPZvny5fTq1YuEhIRsfXXr1o3mzZsze/Zs6tevz+jRo1m8eDE333wzTZs2JSoqioYNGzJx4kQ+/vjjbH09/fTTvPnmmzzyyCM8/PDDxMTE0Lt3b2bMmMGyZct48MEHGTNmDF999RWDBg3K9zW402+//Ubv3r256aabiIqKwtvbm7vuuou3336bHj16cOONNzJ79mz8/PwYPHgwu3btumCb1lpuueUWvL29iYqKonfv3kRHRzNt2jQPXJGIiIiIZ51POs+cr+bQumprrq13rdPhOMNaq5ebX23btrV52bFjR57H8+vkyZNuacfdFi9ebAG7cePGTOWHDx+2Pj4+tkOHDjYxMTG9fM2aNRaw48aNSy8LDw+3gB09enSmNvbs2WO9vLxsly5dbEJCQqZjKSkp6d+HhoZawL7wwguZzmnVqpVt167dBa9h6tSpFrA33XSTTUpKSi9/6aWXLGBffPHFbH29/PLL6WVxcXHW19fXGmNsdHR0tvL+/funl23YsMECtnHjxvbs2bPp5ePHj7eAbdq0qT137ly28p07d17wOnK6ruDg4ALXs9ba4OBgC9h169all+3YscMC1hhjP/nkk2zlEyZMSC9Lu84NGzakl6V9zhnPs9banj172ho1amSLwVM/8+76HS0tMn5m4jkad+do7J2hcXeGxt3zor+LtkRiZ7872+lQihTwrc0lXyrv+bRXcvPQQ7B9e/7PT06uiJdX0cTSujU884x721y/fj3nz5/noYceonz5//3ode/enRYtWrBmzRpmz56dqc6oUaMyvV+xYgXJyclERkbi7e2d6ZgxJtN7b29vhg0blqksNDSU1157Ld8xjx49Gq8MgxwREcG4ceNYs2YNI0eOTC+vUKECERER6e8DAwNp1qwZO3fuJDw8PFv5nj17svUVHh6Or69v+vvrrrsOcM3G+vj4ZCvfs2cPl112Wa6xp6SkZJtdPnPmDCkpKRw5ciRTuZ+fH35+frm2laZRo0Z07tw5/X3z5s2pWrUq1atXp1OnTtnKc7rOnGT9nENDQ1m1ahXx8fFUqVIlX22IiIiIFHfJKclEfRHFVbWvol1gO6fDcYySUPGYffv2AeSYOKUloVk1atQo0/vdu3cD0LJlywv2V7du3UzJLriSwKyJWV6aNWuW6b23tzchISHs3bs3U3mdOnWy9RUQEECdOnUyJbFp5bGxsdn6atCgQbbz8io/duxYnrHv37+fhg0b5ngsKCgo0/upU6cSGRmZZ3s5xZIWT27lF4oRXAsW1atXL1NZYGAgAHFxcUpCRUREpNRY+fNK/nv0v7zV9y3MYXPhCqWUktBipKAzj/HxZ0v1P9C9vLyoUKHCRdX3lNz6yq3cdYeC+9vIqHbt2qxbty5T2auvvsrHH3+cbTY4a7KfG3fHCK4Z7NxWzM1PfREREZGSwFrLrC9m0aRaE/o078PGwxudDskxSkLF7bLeFpsmbWuQn3/+mRYtWmQ6tnPnzlxn7TJq0qQJAD/88APXX3/9xQWaD7t27coUa2JiIr/99lumlXqLK19f30y3zgJs2rQpx3IRERERKVqf7P2Eb//4lpdufwmvcp6bLCmOtDquuF2lSpUA1/YmGXXp0gUfHx/mzZtHUlJSevnatWv56aefuOOOOy7YdlhYGF5eXkydOpXExMRMxwo7a/bnn3/y888/Z2sP4NlnnyU5OTn9/ZIlSzh+/Djdu3cvVF8iIiIiUjbN2jSLSypfwr2t7nU6FMdpJlTcrk2bNhhjmDlzJkePHsXHx4dOnTpRs2ZNIiMjmTRpEjfffDN9+/YlNjaW+fPn06BBAyZMuPA+SQ0bNuTxxx/nscce45prrqFfv35UrVqVH3/8kT/++IP33nuvwPFOmjSJV155hb1796bP1qaJi4uja9eu9O7dm927d7NgwQIuv/xyhgwZUuB+RERERKRs+ib2Gz7Z+wlPdnkSn/I+F65QymkmVNyuUaNGzJ8/nz/++IOhQ4dy9913s2PHDgAmTpzIwoULOXbsGGPHjmXhwoWEhYXxxRdfUK1atXy1/+ijj/LGG29QoUIFpk2bxoQJE9iyZQs9evRw+7W89tpr1K1blylTphAdHU1YWBgrV668qGdVRURERKRsifoiigDfAEa0HeF0KMWC0cIf7teuXePmPBgAACAASURBVDv77bff5np8586dNG/e/KL70fYVztC4O8dTY++u39HSIiYmho4dOzodRpmjcXeOxt4ZGndnaNyL3s9HfqbFghZM7jCZ6Z2mp5eX9rE3xmy11ua4D41mQkVERERERIrIk188iW95Xx685kGnQyk2lISKiIiIiIjkw8nzJzmXdC7f5x84eYCl3y9l6FVDCaoUdOEKZYQWJhIREREREbmAD375gN5v9SYhOYFqFatRt0pd6vrXpW6VutSpUifb+6BKQcz9ai4pNoUx149xOvxiRUmoiIiIiIhIHg6eOkjEygiaVm/KXZffRWx8LLHxsfwR/wf/OfgfDp46iCXzWjve5bxJtsnc0/IeQgJCnAm8mFISKiIiIiIikosUm8LgVYOJT4gnpm8MLYJaZDsnKSWJg6cOEnvSlZjGxscSezKWo2ePMrnDZAeiLt6UhIqIiIiIiORi/tfz+XD3hzx/2/M5JqAA5cuVp55/Per51/NwdCWTFiYSERERERHJwfaD25mwfgI9mvXgvnb3OR1OqaEkVEREREREJIsziWcY8O4AqlesTnSPaIwxTodUajiahBpjKhhj/mWM2W+MOWeM+d4Yc3cB6g9KrXPOGPObMeZxY4x3lnP+ZoyZb4z5wRhzyhjzhzFmjTEmx41TjTH+xpjnjDEHjTFnjTGbjTFdLvZaRURERESk5Bjz0Rh2HtnJq71fpYZfDafDKVWcngmNBiYDq4DRQCzwujHmngtVNMYMBV4Ffk+tuxqYAjyf5dQJQH/gc+Bh4BmgOfC1Mea2LG2a1HaGpsb2UOqhD4wxoYW4PhERERERKWFW/byKF7e+yNjrxtK5UWenwyl1HFuYyBjTFhgIPG6tjUwtW4grWXzKGPO2tTYxl7q+wCwgBrjdWmtTy48Dk40x8621P6SePhcYYK1NyFA/GtgBTAc+yNB0GHAjMNhauyT13FeAH4E5QI6zpyIiIiIiUjr8Ef8HQ/9vKG0uacOMm2c4HU6p5ORMaD/AAgvSClKTyeeB2riSwdzcBNQAFqQloKmeB0xq22ltfpkxAU0tO4orgc26vFU/4DjwWoZzz+GaFW1rjGmcz2sTEREREZESJsWmcO9793I26Syvh71OBa8KTodUKjmZhLYB9llrD2cp35LheF51M54LgLX2D+DABeqmqQMczaHdbdbapELEJHJBkZGRGGM4cOCA06GUGjExMRhjiImJcToUERERKeHmfDmHT/Z+wrxb5tGsRjOnwym1nExCLwH+zKE8razOBepmPDdr/bzqYozpANwAvOnGmMRB27dvJzIykv379zsdioiIiIiUQFv/2Mqjnz5KWPMwhl411OlwSjXHngkFKgJ/5VB+LsPxvOraXJ4ZPQf451bRGHMJ8AawH5iWQ7vnCxOTMWYEMAKgVq1aec7KVK1alfj4+FyP51dycrJb2ikNNm/ezOOPP871119PYGBgkfZ1MeN+/rzrx+vUqVP67Aohp7G/6qqr+Ouvv6hQoYLbxvTcuXOaWc3g1KlTGg8HaNydo7F3hsbdGRp3l7PJZxmxdQRVy1clPDCczz77rMj7LMtj72QSehbwyaHcN8PxvOoaY4x3Domob251jTFVcS1EVBnoYK094a6YrLUvAS8BtGvXznbs2DHX4Hfu3EmVKlVyPZ5f8fHxbmmnNPD1dX1Efn5+RT4mFzPuPj6uH6/KlSuXqs8uMjKSJUuWsG/fviLtx1M/876+vlx11VVF3k9JERMTQ17/TZOioXF3jsbeGRp3Z2jcXYb93zBiz8byafindAzp6JE+y/LYO3k7bm63zabdavvHBeqSR/1sdY0xfsAaoBmuFXV/yHrORcYkGRw6dIh//OMfNGjQAB8fH+rVq8eAAQOIjY0F8n6OzxhDZGRk+vvTp08zYcIEGjdujK+vL9WrV+faa69l+fLlgCsBGjx4MAAdOnTAGJOt7UWLFtGqVSt8fX0JCgpi0KBB2Z7LjIiIoHz58hw8eJA777wTf39/atasyZQpU7DWcujQIfr370/9+vUJDAxkzJgxpKSkFGp8jh8/Tnh4OIGBgfj7+3P33Xfz11+Zbwzo2LEjTZo0YdeuXXTt2pXKlStTr149nnvuOQB++eUXbr31VqpUqULt2rWJiorKVD9tjJcuXcrs2bMJDg7Gz8+Prl27pt+2PHfuXBo2bIivry+hoaH8+uuvhbqeixESEkLnzp3ZvHkz119/PX5+fjRp0oR33nkHgC1bttChQwf8/Py4/PLLeeWVV3K8zoyfd9pneejQIfr164e/vz+BgYEMGzaMs2fz+vuWiIiIlDXLdywnels0E9tP9FgCWtY5mYR+BwQbY4KylF+T4XhedQH+lrHQGFMHqJe1rjGmArACuBa401q7KY92Wxtjss4Qp8W0LY+YJNWhQ4e45pprePnll7n99tuZP38+9913H3v37mX37t0Fbm/UqFE8/fTT3HHHHTz33HM8+uijNG3alK+//hqAsLAwRowYAcCUKVNYunQpS5cupXnz5gDMmjWLoUOH4u/vz+zZsxkyZAjLly/nhhtuIC4uLlNf1lpuueUWqlSpQlRUFO3atWP69Ok89dRTdOnShUqVKjF16lSuu+465s6dy8KFCws1RgMHDuTAgQP861//YvDgwSxfvpyuXbuSkJBpIWfi4+Pp1q0bzZs3Z/bs2dSvX5/Ro0ezePFibr75Zpo2bUpUVBQNGzZk4sSJfPzxx9n6evrpp3nzzTd55JFHePjhh4mJiaF3797MmDGDZcuW8eCDDzJmzBi++uorBg0aVKjruVi//fYbvXv35qabbiIqKgpvb2/uuusu3n77bXr06MGNN97I7NmzqVixIoMHD2bXrl0XbDPts/T29iYqKorevXsTHR3NtGlZ78IXERGRsur3E78zfPVw/lbnbzze8XGnwyk7rLWOvHAlkBaIzFBmcO0TehDwTi2rClwGVM1wni9wBNgAmAzl01PbvDJDmRewHEgG7r5ATHem1o/I0tdu4Lv8Xlvbtm1tXnbs2JHn8fw6efKkW9pxt8GDB1vAfvrpp9mOpaSkWGut3bBhgwXshg0bsp0D2KlTp6a/DwgIsKNGjcqzz8WLF1vAbty4MVP54cOHrY+Pj+3QoYNNTExML1+zZo0F7Lhx49LLwsPDLWAfffTR9LLExERbt25da4yxU6ZMsda6xj2t/JprrskzrqymTp1qAXvTTTfZpKSk9PKXXnrJAvbFF19MLwsNDbWAffnll9PL4uLirK+vrzXG2Ojo6Gzl/fv3Ty9LG+PGjRvbs2fPppePHz/eArZp06b23Llz2cp37txZoGtKu67g4OAC17PW2uDgYAvYdevWpZft2LHDAtYYYz/55JP08m+++cYCdsKECellOf0spX2WGc+z1tqePXvaGjVqXDAmd/2OlhY5/Z5K0dO4O0dj7wyNuzPK8rgnJifa0MWhttKMSvaXo794vP/SPvbAtzaXfMmxZ0Kttd8YY14HphhjqgHfA2FAByDc/u9Zz97AYmAwsCS17jljzCRcz2CuNsasBFoDo4BF1trvM3T1FNAHWAd4GWMGZgnlPWvt6dTv3wU2AS8YY5oAvwMRQAjQxU2XnquHPnyI7Qe35/v85ORkvLy8iiSW1rVb88wtzxS4XkpKCitWrKBLly7cdNNN2Y4bYwrcZkBAAF9//TW///479evXL1Dd9evXc/78eR566CHKl//fj3v37t1p0aIFa9asYfbs2ZnqjBw5Mv378uXL065dO1atWsXw4cOzlX/55ZcFvh6A0aNHZ/rsIiIiGDduHGvWrMnUf4UKFYiIiEh/HxgYSLNmzdi5cyfh4eHZyvfs2ZOtr/Dw8PRnZgGuu+46wDUbm/aMasbyPXv2cNlll+Uae0pKSrYZ5DNnzpCSksKRI0cylfv5+eHn55drW2kaNWpE586d0983b96cqlWrUr16dTp16pRe3qxZM6pWrZrjdeZk1KhRmd6HhoayatUqPU8tIiJSxn20+yPGfDyGnw7/xOKei2lSrYnTIZUpTi5MBDAE2AfcC4wE/gsMtNYuu1BFa+3LxpgEYBywANdKu9OBf2U5NW11kS7knEg2BE6ntplijLkdmAkMx7XK7g9Ad2vthgJdWRl1+PBhTpw4QcuWLd3W5pw5cxg0aBDBwcFceeWVdOnShbvuuou2bdtesG7aQjk5JVVpSWhG5cqVo169epnKAgICci0/duxYAa/GpVmzzPtOeXt706hRI/bu3ZupvE6dOpmS57R+69Spk+0PEAEBAenP3GbUoEGDbOflVX6ha9q/fz8NGzbM8VhQUOa766dOnZrp+d7cZI0lLZ7cyvMz7jl9ZmkrJ8fFxSkJFRERKYN2HN7BmI/H8OHuD2kU2Ih3+71LWPMwp8MqcxxNQq2154FHU1+5nbOE1BnQHI69AryS07EM53QsYEwncM2ojrrQue5W0JnHkjybk9uMaHJycraysLAw2rdvz+rVq1m/fj2LFi1izpw5zJgxg0mTJrk9rpxiy63cdadB0cltpju38pzicUcbGdWuXZt169ZlKnv11Vf5+OOPee211zKVN2rUKM+2iipGcH1m5crl/Nh7UX9uIiIiUrwcPn2YqTFTeWnrS1SuUJmnujzF/Vffj0/5nDbGkKLm9EyolDJBQUH4+/vzww85LT78P2kzUsePH89UntsWHzVr1mTo0KEMHTqUs2fPcttttxEZGcnYsWPx9vbONakNCQkB4Oeff6ZFixaZju3cuTPXGb2itmvXrkzxJCYmsnfvXtq3b+9IPAXh6+ub6dZZgE2bNuVYLiIiIuKk80nnmf/1fKZvnM7phNPc1+4+IjtGUsOvhtOhlWlOro4rpVC5cuXo06cP69atY8OG7Hcwp81AhYSE4OXlle2ctO1H0iQnJ3PiRObtXCtWrEizZs1ISEjg9GnX47yVKlUCsie1Xbp0wcfHh3nz5pGUlJRevnbtWn766SfuuOOOQl7pxXn22WczzfouWbKE48eP0717d0fiERERESlNrLUs37Gc5guaM379eNo3aM8Pf/+B5257TgloMaCZUHG7J554gnXr1tGtWzeGDRtGq1atiIuL44MPPmD69OmEhoam7425YMECjDE0a9aMDRs2ZHsmMj4+nrp169K7d29atWpFtWrV2LZtGwsXLuTWW29Nf46xTZs2GGOYOXMmR48excfHh06dOlGzZk0iIyOZNGkSN998M3379iU2Npb58+fToEEDJkyY4MQQERcXR9euXenduze7d+9mwYIFtGzZkiFDhjgSj4iIiEhp8U3sNzzy8SNs2r+JK2pewUcDP6Jr465OhyUZKAkVt6tduzZbtmxh6tSprFy5koULF1KrVi1CQ0O59NJL08+bN28eiYmJREdHU65cOW6//XbWrl2baXEbPz8/7r//ftavX8/777/P+fPnadCgAZMnT2b8+PHp5zVq1Ij58+czZ84chg4dSnJyMhs2bKBmzZpMnDiRoKAg5s2bx9ixY6lSpQphYWHMmjWLatWqeXRs0rz22mvMnj2bKVOmkJSURFhYGPPmzaNChQqOxCMiIiJS0p08f5L7P7ifpd8vpWalmvz79n8z5KohlC+nlKe4MVqgw/3atWtnv/3221yP79y5k+bNm190PyV5YaKSTOPuHE+Nvbt+R0uLmJgYOnbs6HQYZY7G3Tkae2do3J1Rmsb94Q8fZv6W+Yy/fjyTOkzC38ff6ZDyVJrGPifGmK3W2nY5HdOfBUREREREpET7M/5PXtz6Ive2upeZnWc6HY5cgJJQETeIi4sjISEhz3OCgoJy3XJERERERAov6osoEpMTeazDY06HIvmgJFTEDcLCwvjss8/yPGfv3r3pW8aIiIiIiHv8Ef8HL37rmgVtXK2x0+FIPigJFXGDOXPmcOzYsTzPqV27toeiERERESk7ojZFkZSSxGM3aha0pFASKuIGbdu2dToEERERkTIn9mQs/976b8JbhdMosJHT4Ug+lXM6ABERERERkcKI+iKKZJusWdASRkmoQ7Q1jkjxpN9NERGRkiH2ZCwvbX2JiFYRNAxs6HQ4UgBKQh3g5eVFYmKi02GISA6SkpIoX15PKoiIiBR3MzfNJNkm8+iNjzodihSQklAHVKlShZMnTzodhojkID4+Hl9fX6fDEBERkTwcOHmAl797mcGtBxMSEOJ0OI74/XeYORM+/dTpSApOSagDqlWrxrFjxzhy5AgJCQm6/U+kGLDWcubMGY4cOUJQUJDT4YiIiEgeZm6cSYpNYXKHyU6H4lGnTsGrr0LnzhAcDJMnl8wkVPecOcDHx4cGDRoQFxfHvn37SE5OLlQ7586d04yNAzTuzinqsffx8aFWrVr6fEVERIqx30/8zsJtCxnSekiZmAVNSYGYGFfyuXw5nD4NjRrB1KkwaJDr+5JGSahDfHx8uOSSS7jkkksK3UZMTAxXXXWVG6OS/NC4O0djLyIiIjM3zcRaW+pnQf/7X1fiuXQp7N8P/v5w990QHg433ADGOB1h4SkJFRERERGREmH/if0s/G4hQ64aQnBAsNPhuN2xY/DWW/DKK7B5M5QrB127QlQU9OwJFSs6HaF7KAkVEREREZESYebGmQClchZ0/Xro0wdOnoQrroAnn4R77oGLuHGy2FISKiIiIiIixd5vx38jels0w9oMo0HVBk6H41bLlkFEBLRoAYsWQZs2Jft22wvR6rgiIiIiIlLsPbHxCYwxTGo/yelQ3MZa14znwIHQoQN8/jm0bVu6E1BQEioiIiIiIsXcb8d/Y9H2RQy7ahj1q9Z3Ohy3SEmBhx+G8eOhf39YuxaqVnU6Ks/Q7bgiIiIiIlKszdg4g3KmHJM6lI5Z0HPnYNq0Fnz2mSsRfeop1yJEZUUZulQRERERESlp9h7by+LtixneZjj1/Os5Hc5FO34cbrkFPvusJk89BXPnlq0EFJSEioiIiIhIMfbExifwMl6l4lnQAwdcz35++SU89tgOxoxxOiJn6HZcEREREREplvYe28uS/yzh7+3+Tl3/uk6Hc1F++sk1A3rihOv5Ty+vv4AWToflCM2EioiIiIhIsTRj4wy8jBcT2090OpSLsnEjtG8PSUmuFXBvvtnpiJylJFRERERERIqdX+N+Zcn2JYxsO5I6Veo4HU6hrVgBXbpArVrw1VfQurXTETlPSaiIiIiIiBQre47todtr3ajoXbHEzoImJcH8+dC3L7RpA198ASEhTkdVPOiZUBERERERKTb+c/A/3LLsFhKSE1g/aD2XVLnE6ZDyzVr47jt47TV48004eBB69IA33gA/P6ejKz6UhIqIiIiISLHw2b7P6PFmD/x9/Pn03k9pHtTc6ZDyZe9eWLbM9fr5Z6hQAW6/HQYOdCWhXl5OR1i8KAkVERERERHHrfx5JXctv4tGgY34aOBH1K9a3+mQ8nT0KLz9tivx/OILV1loKIwZA336QGCgs/EVZ0pCRURERETEUdHfRTNizQj+VudvvD/gfar7VXc6pBydPQurV7sSz7VrITERLr8cZs6EAQOgQQOnIywZlISKiIiIiIgjrLXM2jSLyZ9Oplvjbrzb710qVajkdFjZHDsGTz/tWmjoxAmoUwcefNB1u+2VV4IxTkdYsigJFRERERERj0uxKYz5aAzPfP0MA1oOYHHPxVTwquB0WJmkJZ/z5sHJk67bbP/+d+jYUc95XgwloSIiIiIi4lEJyQkMWTWEZT8s48FrHmRut7mUM8Vn98hjx+CZZ1yvkydd26z885/QsqXTkZUOSkJFRERERMRjTiecpu87fflw94c80ekJJrafiCkm97MeP+6a+UxLPvv0cSWfV17pdGSli5JQERERERHxiKNnjtL99e5888c3vHzHywxrM8zpkABX8pk283nihJLPoqYkVEREREREityBkwfourQre47t4d1+79Lrsl5Oh8Tx467nPZ9+2pV8hoW5ks9WrZyOrHRTEioiIiIiIkXqTOIZ7njjDg6cPMBHAz8iNCTU6ZDYsMGVdB4/ruTT05SEioiIiIhIkbHWMmL1CP5z8D+sGbCmWCSgW7dCjx6ufT03bIDWrZ2OqGxREioiIiIiIkXmmc3PsOyHZUy/aTq3XXqb0+GwaxfccgtUrw4ffwx16zodUdlTfNZBFhERERGRUuXTvZ8ybt04el/Wm0kdJjkdDgcOQNeuYAysW6cE1CmaCRUREREREbf77fhv9F/en6bVm/JKr1cc3wf06FHo1s21B2hMDFx6qaPhlGlKQkVERERExK3OJp4l7O0wEpMTWXnXSqr4VHE0nlOnoHt3+PVX+PBDaNPG0XDKPCWhIiIiIiLiNtZaRqwZwbY/t7H67tU0rd7U0XgSElz7fn7zDbz7LnTs6Gg4gpJQERERERFxo/lfz+e1719jWsdpdG/a3dFYkpPh3ntdCxBFR0Mv57cmFbQwkYiIiIiIuEnMvhjGfDyGXpf14tEbH3U0FmvhgQfgrbdg9mwYMsTRcCQDJaEiIiIiInLR9p/YT793+nFp9UuLxUJEjz8Ozz8P48a5XlJ8KAkVEREREZGLcjbxLGFvhXEu6Rwr+6/E38ff0Xiee86VhA4eDFFRjoYiOdAzoSIiIiIiUmjWWu57/z62/rmVVXetolmNZo7G88YbMHo09OwJL73k2hNUihfNhIqIiIiISKEt+GYBr/7nVSJDI+nRrIejsXz4oWshotBQePNNKK8pt2JJSaiIiIiIiBTK5799zsMfPUyPZj2YEjrF0VhWrnRtxdKyJaxaBb6+joYjeVASKiIiIiIiBfb7id/p+3ZfGgc25tVerzq2ENHx4xAeDr17Q7NmsHYtVK3qSCiST0pCRURERESkQOLOxnHb67e5FiK6ayVVfZ3J+j7+GK64ApYtg3/+EzZvhlq1HAlFCkBJqIiIiIiI5Fv8+XhuXXYr/z36X97r/x6X1bjM4zGcOgV//zt06wb+/q7k8/HHoUIFj4cihaAkVERERERE8uVs4ll6vNmDrX9s5Z073+HmRjd7PIaNG6FVK/j3v2HsWPjuO2jXzuNhyEVQEioiIiIiIheUmJxIv+X9+GzfZ7za+1WPr4R79qwr6QwNdb3//HN48kktQFQSadFiERERERHJU3JKMveuvJc1/13Di91fZEDLAR7t/5tvXIsP7dwJo0ZBVBRUruzREMSNNBMqIiIiIiK5stZy35r7ePPHN4nqHMXIdiM91ndCgmvBoeuug/h4+OgjWLBACWhJp5lQERERERHJkbWWcevGsXDbQia3n8z4G8Z7rO+9eyEsDLZvd82CPvMMBAR4rHspQkpCRUREREQkR9M/n86cr+Zw/9/uZ3qn6R7r9/x56NMH9u2DlSuhZ0+PdS0eoCRURERERESymbd5Hv+M+Sf3trqXebfOwxjjsb4ffRS2bVMCWlrpmVAREREREclk0bZFPPTRQ4Q1DyO6RzTljOfSho8/hjlzXPuAKgEtnZSEioiIiIhIund+eofhq4fTtXFXXg97nfLlPHfz5F9/wb33QosWrkRUSifdjisiIiIiIgB8uPtD7llxD9fVu44V/VbgU97HY31bC0OGwPHjrtnQihU91rV4mJJQERERERFh428bCXsrjMtrXs6aAWuoVKGSR/t/7jl4/32YPx+uvNKjXYuH6XZcEREREZEybu+xvfR6qxcNqjbgo4EfEeDr2b1Qvv8exo2D7t3h/vs92rU4QEmoiIiIiEgZdjrhNL3e6kWKTWHNgDXUrFTTo/2fOQN33w2BgbB4MXhwEV5xiG7HFREREREpo6y1DF41mB//+pH3B7xPk2pNPB7D2LGwYwd89BEEBXm8e3GAklARERERkTJq2f5lvLPvHaI6R3FLk1s83v+qVfDCC65EtGtXj3cvDtHtuCIiIiIiZdD7/32fRfsWcfcVdzPu+nEe7z821rUabps2MGOGx7sXBykJFREREREpY3Yd2cWAFQNoUrkJC3ssxHj4QczkZBg0CM6dg9dfhwoVPNq9OEy344qIiIiIlCEnzp2g55s9qeBVgWmXT8PP28/jMTz1FGzYANHR0KyZx7sXhykJFREREREpI1JsCgPfG8ivx35l/aD12H3W4zFs2QKPPQZ33gmDB3u8eykGdDuuiIiIiEgZ8c8N/2TNf9fwTLdnCA0J9Xj/8fEwYADUqQP//re2YymrNBMqIiIiIlIGLN+xnBkbZzD0qqGM+tsoR2IYPRr27oWYGNe+oFI2aSZURERERKSU+/7Q94SvDOe6etex4LYFHl+ICGDZMnjlFdetuB06eLx7KUaUhIqIiIiIlGJHzxyl15u9CPAN4N1+7+JT3sfjMWzfDsOHu5LPKVM83r0UM7odV0RERESklEpKSaL/8v7ExsfyecTnXFLlEo/HcOQI9OoF1avDO+9AeWUgZZ5+BERERERESqnx68bzyd5PWNxzMdfUu8bj/SclQf/+cPAgbNwItWp5PAQphpSEioiIiIiUQku2L+HpzU/zwNUPENE6wpEYxo+HTz+FJUvgb39zJAQphvRMqIiIiIhIKfPs188yZNUQbm54M091fcqRGJYuhaefhgcegPBwR0KQYkpJqIiIiIhIKZFiU5iwbgIPfPgAPS/ryeq7V+Pt5e3xOLZuhREjIDQUnnImB5ZiTLfjioiIiIiUAgnJCQxZNYRlPyxjVLtRzL91Pl7lvDwex19/Qe/eULOmayEib8/nwFLMKQkVERERESnhTp4/SdhbYXyy9xOe6PQEE9tPdGQv0MRE6NcPDh+GL76AoCCPhyAlgJJQEREREZES7I/4P7ht2W38dPgnlvRcQnhr5x7AHDMGPvvM9TxomzaOhSHFnJJQEREREZESaufhndyy7BaOnjnKmrvX0K1JN8diWbIEnn0WHn4YBg50LAwpAZSEioiIiIiUQF/s/4I73riDCl4V+CziM9rWaetYLN98A/fdB506wezZtsLwCgAAIABJREFUjoUhJYRWxxURERERKWHe2/kenZd2poZfDb4c+qWjCeihQ66FiGrXhrfegvKa5pILUBIqIiIiIlKCLNiygD5v96FVrVZ8OfRLGgU2ciyWhATo2xfi4mDlSqhRw7FQpARREioiIiIiUgJYa5m0fhL3r72f25vezqfhn/4/e3ceZ2P5/3H8dZF9yRaSooWIUAmVslXKTvZt7EQohb4VJZIkO6GIsS+Z7LsZ+1IoVCT7luxLhjHm+v1xT/0GY5YzZ+Y+M/N+Ph7zGOde306jx3zOdd2fixzp3a363nkH1q+H8eOhRAlXo0giosFyEREREZFEoMPCDozbPo52T7djVNVR3JPC3V/l/f1h9Gh47z1o1MjVKJLIaCRURERERMTHTds1jXHbx9H9+e6MqTbG9QL03DlnFLRsWfj8c1ejSCKkIlRERERExIcduXiEjos68lze5+hfqT/GGLcj0bs3XLgAo0apEZHEnopQEREREREfFWbDaPFDC27am0yuPdn1EVCAXbvg66+dJVmKFXM7jSRG7v8Ui4iIiIhIpIZsGkLgoUC+rf4tj2Z71O04WAtdukCWLPDpp26nkcRKRaiIiIiIiA/aeWonH6z+gFqFatHqqVZuxwHg++8hKMiZhps9u9tpJLFydTquMSa1MaavMeaIMeaaMWanMSbGvbWMMc3Cz7lmjDlsjOljjEl12zEZw7cvNsacNsZYY8wnd7lei/D9kX2VjeNfV0REREQkRq6FXqPJ3CZkTZuVcdXG+cRzoFevwrvvOlNw27VzO40kZm6PhI4HGgOjgZ1AHWCaMSaFtXZqVCcaY1oD3wKLgRFAcaAXkAdoG+HQHEBv4DiwHXg1Brn6An/ctm1vDM4TEREREYmzD1d9yO6/d7O48WLuy3Cf23EA+PJLOHLEWZpFzYgkLlz78THGPAM0BfpYaz8J3/YtsBYYZIyZZa29cZdz0wIDgCCgmrXWhm+/AHxgjBlurd0VfvhJ4AFr7QljTF7gaAziLbfWrvf8byciIiIi4plVB1YxePNgOpbsyOsFXnc7DgCHD8OAAVC/PpQr53YaSezcnI5bH7DAqH83hBeTo4HcwEtRnFsBZ4Rz1L8FaLjRgAm/9r/XvG6tPRHbcMaYTMYYfcYjIiIiIgnmfPB5/H7w4/Hsj/Plq1+6Hec/3buDMc5oqEhcuVmEPg0cstaevm371gj7ozo34rEAhBebx6I5NyYWA5eAYGPMqvBRWxERERGReGOt5c1Fb3Lqn1NMqTOF9KnSux0JgMBAmD0b3n8fHnrI7TSSFLg50nc/zlTZ2/27LU8050Y89vbzozo3KlcBfyAQOA8UBd4F1hljXrTWbvPwuiIiIiIiUZq2axozf51Jvwr9KJmnpNtxAAgNha5dIV8+ZzRUxBvMrbNZE/DGxuwHDltrK962PQVwExhrre1wl3PHAy2ttXeM5Bpj1gI5rbWFItn37zOh/z2HGoOcBYFfgE23Z73tuHZAO4BcuXI9M2PGjJhcPk6uXLlCxowZ4/0+ciu97+7Re+8Ove/u0PvuHr337kju7/tf1/6izU9teDjDwwwtMZSUJmWC3De69z0gIA/Dhxfkk092U67cmQTJlFwk9Z/5ChUqbLPWRvppipsjocFAmki2p42wP6pzjTEmVSTNi9JGc26sWGv/MMbMA94wxqSx1l6/y3HjgHEAJUuWtOXLl/dWhLsKCgoiIe4jt9L77h699+7Q++4Ove/u0XvvjuT8vt8Mu0kl/0qYlIb5LebzcNaHE+zeUb3vZ89CnTpQoQL07l0UH1glJklJzj/zbj4Terdps/9OtY2qmVBUU3bvj+ZcTxzBKdjv9fJ1RURERCSZG7xpMGsOr2H4a8MTtACNTu/ecOkSDBuGClDxKjeL0O1APmPM7QsflY6wP6pzAZ6NuNEYkwfIG825nngUuAFc8PJ1RURERCQZ++WvX/hw9YfUKVyHFiVauB3nP7/8AmPGwJtvwpNPup1Gkho3i9A5OMupdPp3gzHGAB2AUzjrhWKMudcYU8gYE3EUMhA4C3QKP+dfHcO/z/YkkDEmZyTbngZqAKustSGeXFdERERE5HbXQq/RZG4TsqfPzthqYzE+MtxordOMKGtW6NPH7TSSFLn2TKi19kdjzDSglzEmG7ATqAO8CPhFeNazNvAd0BKYGH7uNWPM/3CewVxgjPkBKIFThE6w1u6MeC9jzFtAFiBz+KaXjDEfhf95srX2cPifNxpjfgZ+As4BRYC2wD84XXJFREREROLMWst7y9/j19O/srTJUnKkz+F2pP/Mng1r1sDXX0O2bG6nkaTIzcZEAK2AQ0BzoD3wB9DUWjs1uhOttd8YY0KA7sAo4G+gH9A3ksPfA/JFeF0h/AtgPfBvETodqApUAjKGX3MW0Ndauz82fzERERERkcjcuHmDNxe9yfgd43m79NtUfqyy25H+c/UqvPceFC8Obdu6nUaSKleL0PBOsx+Gf93tmImEj4BGsm8SMCkG98kfwzy9gF4xOVZEREREJLbOB5+n7uy6rD64mo9e/Ig+FXxrvusXX8DRozB1KqRMmFViJBlyeyRURERERCRZ2H9uP9WmV2P/uf1MrDkRvxJ+bke6xaFDMHAgNGwIL77odhpJylSEioiIiIjEsw1HNlBrZi3CbBgrmq2gXP5ybke6xcmT0KCBsxTLwIFup5Gkzs3uuCIiIiIiSd60XdOo6F+RrGmzsrn1Zp8rQDdtgmeegd27YcoUePBBtxNJUqciVEREREQkHlhr6RPUhyZzm1Ambxk2td5EgewF3I51i4UL76dcOUiXzilG69RxO5EkB5qOKyIiIiLiZddDr9N6fmum7pqKX3E/xlUfR+qUqd2O9Z/r1521QMeOfZxXX4Xp07UciyQcFaEiIiIiIl505uoZas+szfoj6/ms4mf8r+z/MMa4Hes/J0/CG284I5+NGh1h8uSH1AlXEpSKUBERERERL9lzZg9Vp1Xl+KXjzKw7k/pF6rsd6RabNjkF6MWLMHMm5Mx5gJQpH3I7liQzeiZURERERMQLAg8G8tz457gScoWgFkE+V4COG8d/z39u3gz1fSueJCMqQkVERERE4mjHyR28PvV1Hsj0AFvabKFM3jJuR/rP9evQvr3zVbEi/PgjPPmk26kkOdN0XBERERGROLh0/RL159QnR/ocBPoFcl+G+9yO9J+Iz3++/z7064ee/xTXqQgVEREREfGQtZY289tw8PxBgloE+VQBumUL1K7tPP85axbUq+d2IhGHilAREREREQ+N/nE0s3+bzYBKAyj7UFm34/zn/HmoUQMyZIBlyzT9VnyLilAREREREQ9sO7GNbsu7UaVAFbq/0N3tOLfo0QPOnlUBKr5JjYlERERERGLpwrUL1Jtdj1wZcuFfy58Uxnd+rV6zBr79Ft59F0qUcDuNyJ00EioiIiIiEgvWWlrNa8XRS0dZ22It2dNndzvSf65dc7rgPvwwfPyx22lEIqciVEREREQkFoZvGU7AngAGvTKI5x58zu04t/j8c9i715mGmz6922lEIuc78wZERERERHzc1uNb6b6iO9ULVqfbc93cjnOL335zitCmTeHVV91OI3J3KkJFRERERGLgXPA56s+uT55MeZhYayLGGLcj/ScsDNq1g0yZYPBgt9OIRE3TcUVEREREomGtpeW8lpy4fIJ1LdeRLV02tyPd4ptvYMMGmDgR7vOdpUpFIqUiVEREREQkGkM2D2H+3vkMqTyE0nlLux3nFidOOEuyVKwIzZu7nUYkepqOKyIiIiIShc3HNtNzZU9qF6pN19Jd3Y5zh65dISQExo4FH5ohLHJXGgkVEREREbmLs1fPUn92fR7M/CATak7wqedAAebPhzlzoH9/eOwxt9OIxIyKUBERERGRSITZMPx+8OPUP6fY0GoDWdJmcTvSLS5fhk6doGhReO89t9OIxJyKUBERERGRSAzaOIhF+xYx4vURlMxT0u04d/joIzh+HGbPhlSp3E4jEnMqQkVEREREIrDWMmjjIP636n/Ue6IenZ7t5HakO2zZAiNGOCOhZcq4nUYkdlSEioiIiIiE+yfkH9osaMOM3TOo90Q9vqv5nc89B3rjBrRtC3nywGefuZ1GJPZUhIqIiIiIAIcuHKLWjFrsPLWTzyt9Ts8XevpcAQrw1Vewaxf88ANkzux2GpHYUxEqIiIiIsneqgOraDCnAaFhoSxqvIjXC7zudqRI/fkn9OkDdepAzZpupxHxjNYJFREREZFky1rL0M1DqTylMrky5uLHtj/6bAFqLXToAKlTw/DhbqcR8ZxGQkVEREQkWQq+EUy7he2YsnMKtQrVwr+WP5nSZHI71l35+8OqVTB6NDzwgNtpRDynIlREREREkp0jF49Qe2Zttp/czqflP+XDlz4khfHNSYLWwtCh0LMnvPACtG/vdiKRuFERKiIiIiLJyppDa6g3ux7XQq8xv+F8qj9e3e1Id3X6NLRsCYsWQY0aMGECpPDNWlkkxmL9I2yMKWKMqXPbtgrGmFXGmG3GmHe9F09ERERExDustYzcOpKXJ79MtnTZ2Np2q08XoIGBULw4rFjhPAP6ww+QPbvbqUTizpPPUQYCbf59YYx5AJgPFAPSAQONMc29E09EREREJO5Cw0JpM78NnZd05rXHXmNLmy0UylHI7ViRCg2F3r2hUiXIlAm2bIHOncEHV4sR8YgnRejTwJoIr5sAKYES1tongCVAJy9kExERERHxig9XfciEnyfw4YsfMq/hPO5Ne6/bkSJ15AhUqAB9+4KfH2zbBiVKuJ1KxLs8KUKzAqcivH4dWGOtPR7+egFQMK7BRERERES8Yc5vcxi4cSAdnulAv4r9fLYB0Q8/OAXnzz/DlCnw3XeQMaPbqUS8z5N/gWeAvADGmAzAc8DKCPtToYZHIiIiIuIDfjv9Gy3ntaT0A6UZ+tpQt+NE6to1Z7pt7drw8MOwfTs0aeJ2KpH440mxuA540xjzG84oaCqcZ0L/VRA4HtmJIiIiIiIJ5dL1S9SeWZv0qdIzp/4c0tyTxu1Id9izBxo2hF9+gXfegc8/hzS+F1PEqzwpQj8AVgBzwl9/Ya3dB2CMSQnUxZmSKyIiIiLiCmstLX5owf5z+1nVfBV5M+d1O9Idpkxx1vxMnx4WLoSqVd1OJJIwYl2EWmsPGmMKAU8AF621hyPsTg+8CfzipXwiIiIiIrH2xYYvCNgTwFevfkW5/OXcjnOHpUuheXN46SWYNg3y5HE7kUjC8ejZTWttKLAzku2XgXlxDSUiIiIi4qkV+1fw4eoPaVCkAe+UecftOHc4eBAaN4aiRWHRIsiQwe1EIgkr2iLUGPOSJxe21q715DwREREREU8dvnCYRt83onCOwnxb41uMjy2uGRwMdeqAtRAQoAJUkqeYjIQGATbCa3Pb67tJ6UkgERERERFPBN8Ips6sOtwIu0FAgwAypvat9U2shTffdJZgWbgQHn3U7UQi7ohJEVrhttepgYFABmAcsDd8eyGgLXAF6OGtgCIiIiIi0bHW0mlxJ7af3M78hvMpkL2A25HuMGYMTJoEH3+sJkSSvEVbhFpr10R8bYwZCNwEillrr0XYtcAYMwpnCZdXuHXtUBERERGReDNu2zi++/k7er3Ui+qPV3c7zh02bYKuXaFKFejd2+00Iu5K4cE5zQD/2wpQAKy1VwF/oHlcg4mIiIiIxMTmY5vpvKQzrz32Gh+X+9jtOHf46y+oWxcefNBZliWFJ7+BiyQhnnTHzQxkj2J/jvBjRERERETi1akrp6g7qy55M+dlap2ppEzhW21JbtyABg3g/HlnNDRrVrcTibjPk89h1gNdI+uaa4wpB3QJP0ZEREREJN6EhoXSYE4DzgafZW6DuWRLl83tSHfo2RPWroVx46B4cbfTiPgGT0ZCOwNrgUBjzE7+vzHR40Ax4AxOISoiIiIiEm96rujJmsNr8K/lT4ncJdyOc4cZM2DIEOjcGZo2dTuNiO+I9UiotfYP4ElgKJAOqBn+lS5825PW2r13v4KIiIiIiOfCbBgfrf6IwZsH89azb9GseDO3I91h925o3RpeeAEGDXI7jYhv8WQkFGvtaeDd8C8RERERkQRx+fplmgU0Y97eebR+qjWDKw92O9IdLlyA2rUhc2aYPRtSp3Y7kYhv8agIFRERERFJaAfOH6DG9BrsObOH4a8N561Sb2GMcTvWLcLCoHlzOHQIAgPh/vvdTiTiezwqQo0xWYBGwCNANuD2f/3WWts6jtlERERERAAIPBhI3dl1sdaytOlSXn7kZbcjRap/f1iwAIYNg7Jl3U4j4ptiXYQaY14G5gIZgUvA+UgOs3HMJSIiIiICwOgfR9NlSRcKZi/IvIbzKJC9gNuRIrV0KfTuDU2aOM2IRCRynoyEDsbpgPuitfYXL+cREREREQEg5GYIXZd0Zcy2MVQtUJWpdaZyb9p73Y4Vqb17oXFjePJJZzkWH5slLOJTPClCCwI9VICKiIiISHw5/c9p6s2ux5rDa+j5Qk8+q/gZKVOkdDtWpP7+G6pUgXvugYAASJ/e7UQivs2TIvQgznIsIiIiIiJet/PUTmrOqMnJyyeZUnsKTYo1cTvSXQUHQ40acPIkBAXBI4+4nUjE98V6nVCgP9DBGJPD22FEREREJHkL+D2A58c/T8jNENa1XOfTBWhYGDRtClu3wtSpUKqU24lEEgdPRkIfBM4C+4wxc4AjwM3bjrHW2s/jGk5EREREkgdrLX3X9KV3UG9KPVCKgAYB5MmUx+1YUerRA+bOhSFDnHVBRSRmPClC+0X4892WYbGAilARERERiZa1lhH7RxBwPIBmxZoxrvo40t6T1u1YURo1Cr76yumC27Wr22lEEhdPitCHvZ5CRERERJIlay09VvQg4HgA75R5h69e/Qrj461lFyyALl2genVnFNTH44r4nFgXodbaw/ERRERERESSn96BvRm0aRC18tRKFAXotm3QsCE89RRMnw4pfbNhr4hP82QkFABjTFagEv8/MnoQWGmtveCNYCIiIiKStPVb249+6/rR5qk2NMrUyOcL0MOHoVo1uO8+WLgQMmRwO5FI4uRREWqM6Qb0BdICEf9vEWyM+chaO8Qb4UREREQkaRq0cRC9AnvRrFgzxlQbw7q169yOFKULF6BqVWdJlpUrIXdutxOJJF6xXqLFGOMHDAJ+BhoARcO/6gM7gEHGmObeDCkiIiIiSceILSPovqI79YvUZ0LNCaRM4dtzWkNC4I03YO9epxtukSJuJxJJ3DwZCX0HWA9UsNZGXJrlN2NMABAIdAP8vZBPRERERJKQcdvG0WVpF2oVqsWU2lO4J4XHT4clCGuhfXtYvRomToSKFd1OJJL4xXokFHgcmHVbAQpA+LZZ4ceIiIiIiPxn0s+T6LCwA1UKVGHGGzNIlTKV25Gi1a+fU3x+/DH4+bmdRiRp8KQIvQxEtXLwA+HHiIiIiIgAMGP3DFrNb0WlRyrxff3vSXNPGrcjRWvKFOjdG5o1c4pQEfEOT4rQ5UAXY8zLt+8wxlQC3gKWxTWYiIiIiCQNc3+fS9O5TSn7UFnmNZxH2nvSuh0pSmfPQqdOzshnhQrw7bdaC1TEmzyZhP8+UA5YZozZDfwevr0Q8CRwHPifd+KJiIiISGK28I+FNJzTkFIPlGJho4WkT5Xe7Uh3deMGjBnjjHpeuuQUov36QerUbicTSVpiPRJqrT0GlACGAKmBmuFfaYCvgKfCjxERERGRZGz5/uW8MesNiucuzpImS8iUJpPbke5q5UooUQK6dIFnnoFffoHhwyFzZreTiSQ9HrUjs9aeBd4L/xIRERERucWqA6uoOaMmhXMUZlnTZdyb9l63I0Vq/354912YNw8eeQR++AFq1ND0W5H45Mk6oRmMMQ9Fsf8hY4zvzrMQERERkXi19M+lVJtejceyPcaKZivIli6b25HucPkyvP8+PPGEMwr6+efw229Qs6YKUJH45kljoiHAgij2zwcGeRZHRERERBKz+Xvn/zcCGugXyH0Z7nM70i3CwmDSJChYEL74Aho1gj/+cArSNL7fsFckSfCkCH0ZCIhi/1zgVc/iiIiIiEhiNee3Obwx6w1K5C7BquaryJE+h9uRbrFlCzz3HLRoAfnyOa8nToQ8US0+KCJe50kRmgeIqvHQCaJeR1REREREkphpu6bRYE4DSj9QmhXNVpA1XVa3I91i4UJ4/nk4ehT8/WHjRihVyu1UIsmTJ42JzgEFotj/OHDZszgiIiIikth8t+M7Ws9vTbn85VjQaAEZU2d0O9Itfv0VGjeGp56CwEDI5LtNekWSBU9GQlcB7Y0xdxSixpjHgXbAyrgGExERERHfN/ansbSa34qXH3mZRY0X+VwBevas0+02fXqn860KUBH3eTIS+jFQFfjZGOMP7A7f/iTQDLgefoyIiIiIJGHDtwyn69KuVC1QlTn155D2nrRuR7rFjRtQvz4cOwZBQZA3r9uJRAQ8KEKttQeMMS8Ao4D2t+0OBDpba//0RjgRERER8U1fbviSHit7ULtQbWbUnUHqlKndjnSHbt1g9Wqn+dBzz7mdRkT+5clIKNba34GKxpjswKPhm/dba896LZmIiIiI+KS+a/rSO6g3DYo0YHLtyaRKmcrtSHcYNw5GjoR33wU/P7fTiEhEHhWh/wovOlV4ioiIiCQD1lp6Bfbis3Wf0bx4cybUmEDKFCndjnWHtWuhUyd47TVnLVAR8S2eNCbCGPOYMWayMea4MSbEGFMxfHsOY8wEY4waXouIiIgkIdZaeqzowWfrPqPNU234ruZ3PlmAHjoEb7wBjz4K06dDSt+LKJLsxboINcYUBX4CqgA7gP/+aVtrz+A0KOrgrYAiIiIi4q5/C9BBmwbR6dlOjK0+lhTGo7GMeHXlCtSs6TQkmj8fsmRxO5GIRMaT6bgDcNYKLQ1Y4O/b9i8FGsQxl4iIiIj4iC82fMGgTYPoWLIjI14fgTHG7Uh3CAuD5s1h925YvBgKFnQ7kYjcjScfYb0IfG2tPY1ThN7uCJAnTqlERERExCeM/Wks/1v1Pxo/2ZgRVXyzAAXo0wcCAmDQIKhc2e00IhIVT4rQe4ArUezPAYR6FkdEREREfMXM3TN5c9GbVC1QlYk1J/rkFFyA2bPh00+hRQt4+22304hIdDz5P8lOoGJkO4zz0VgdnGdGRURERCSRWvrnUpoGNKXsQ2WZVW+WTy7DArBjh7MEy3PPwZgx4KMDtSISgSdF6GDgDWPMp0Cu8G2pwxsWzQGeBr7yUj4RERERSWAbjmygzsw6FM1ZlAWNFpA+VXq3I0Xq1CmnEVH27DB3LqRJ43YiEYmJWDcmstbONsbkA/oDH4ZvXhT+/SbwrrV2iZfyiYiIiEgC+uWvX6g6rSp5M+dlaZOl3Jv2XrcjRerYMWjQAM6cgfXrIXdutxOJSEx50h0Xa+0gY8wMoC5QAGdE9U/ge2vtIe/FExEREZGE8ue5P6k8pTIZU2dkRbMV5MqYK/qTEpC1sG4djBjhNCGy1lkL9Omn3U4mIrHhUREKYK09Bgz1YhYRERERccnxS8d5ZfIrhIaFEugXSL4s+dyO9J+rV2HqVBg5EnbuhKxZoVs3ePNNePhht9OJSGzFugg1xqQDMllr/46wLSfQHsgCzLLWbvFeRBERERGJT2evnuXVKa9y5uoZAv0CKXxfYbcjAXDgAIweDePHw4ULUKwYfPMNNG4M6X3zMVURiQFPRkLHAUVwGhBhjEkPbAbyh+/vbIypYK3d4JWEIiIiIhJvroRcoeq0quw/t58lTZZQMk9JV/OEhcHKlc6U20WLIEUKqFMHOneGsmXV/VYkKfCkO+6LwPwIrxviFKCvA3mAPcAHcU4mIiIiIvHqeuh1as+szU8nfmJm3ZlUeLiCa1lCQw0jR8ITT0DlyrB1K3z4IRw+DLNmwYsvqgAVSSo8GQnNCRyJ8LoasNVauwzAGPMd0MML2UREREQknoSGhdJ4bmNWHljJxJoTqVmopmtZLl6E999/km3boFQpmDwZ6tXTkisiSZUnRehVIBOAMSYFUB4YFWH/FZxnQ0VERETEBx2+cJi2C9qy4sAKhlQegl8JP9eyHDkCVarAnj1ZmDgR/NyLIiIJxJPpuDuBpsaYbEBr4F4g4rqg+YG/IzlPRERERFwUZsMYtXUURb8uysajG/m66te8XeZt1/Js3w6lSztrfg4cuFMFqEgy4clIaF9gEXA6/PUaa+3GCPurAVvjGkxEREREvOePs3/QZn4b1h1ZxyuPvMK46uPInyW/a3kWLYIGDSB7dqcR0enTF1zLIiIJK9YjodbaQJzOuO8ALXEaEgEQPjq6GhgZk2sZY1IbY/oaY44YY64ZY3YaYxrFNIsxpln4OdeMMYeNMX2MMaluOyZj+PbFxpjTxhhrjPkkimtmNsaMNMb8ZYwJNsZsNsa8EtNMIiIiIr4kNCyUgRsGUnxMcXb9vYsJNSawrOkyVwvQr7+GGjXg8cdh82YoUsS1KCLiAk9GQrHW7sHpgnv79nM4xWlMjQcaA6NxpvnWAaYZY1JYa6dGdaIxpjXwLbAYGAEUB3rhdOhtG+HQHEBv4DiwHXg1imsaYAFQChiM04CpJbDYGPOytXZNLP5uIiIiIq7adWoXrea34qcTP1GrUC1GVxnN/Znudy1PWBi8/z58+SVUqwbTp0PGjK7FERGXeFSEeoMx5hmgKdDHWvtJ+LZvgbXAIGPMLGvtjbucmxYYAAQB1ay1Nnz7BeADY8xwa+2u8MNPAg9Ya08YY/ICR6OIVQd4CWhprZ0Yfs1JwG7gK8DdhbNEREREYiDkZgj91/Wn/7r+ZEmbhZl1Z1LviXoYF9c4CQ52mg7Nng0dO8KwYXCPa7+Jioibov2nb4w5CIQBhay1N8Jf22hOs9baR6PNHkapAAAgAElEQVQ5pn74df7rrGuttcaY0cA0nGJw1V3OrYAzwjnq3wI03Gjgw/Br7wq/5nXgRDRZIma6AEyJkOmaMWY80N8Y86i1dn8MryUiIiKS4H48/iOt5rdi99+7afJkE4a+NpQc6XO4munMGahZEzZuhEGDoFs3rfkpkpzF5POnNTjFYthtr+PqaeCQtfb0bdu3Rth/tyL06duOBSB8tPNYhP2eZNphrQ2NIpOKUBEREfE5wTeC6R3Ym8GbB3N/xvtZ0GgB1QpWczsW+/Y5S7AcO+aMgtat63YiEXFbtEWotbZFVK/j4H6cqbK3+3dbnmjOjXjs7edHdW50mSLr7BuTTCIiIiKuuHDtAq9NeY0tx7fQ7ul2DHxlIPemvdftWGzY4IyAGgOrV8Nzz7mdSER8gZsz8dMR+Xqi1yLsj+pce5dnRq8BmeOQ6bonmYwx7YB2ALly5SIoKMjDCDF35cqVBLmP3Ervu3v03rtD77s79L67J7G995duXKL7zu4c+OcAfZ7ow0uZXmLH5h0JnuP69RQcOZKegwczcOhQBg4ezMC2bVnJlesaAwbs4vr1YKJ6WxPb+55U6H13T3J+72PyTOhDnlzYWnskmkOCgTSRbE8bYX9U5xpjTKpICtG00ZwbL5msteOAcQAlS5a05cuX9zBCzAUFBZEQ95Fb6X13j957d+h9d4fed/ckpvf+zNUzvDL5FQ4FHyKgYUCCTL8NCXGm2O7e7Xz9+qvzff9+p/stQKpUULgwNG8OAwakJ0eO0tFeNzG970mJ3nf3JOf3PiYjoYfw7BnQlNHsPwk8Fsn2f6faRtVMKOL02MORnL8z2nR3v25kU25jkklEREQkwfz9z9+87P8y+87tY37D+VR+rHK83cta+OYbGDEC9uyB0PDuGSlSQIECUKwYNG7srPdZtCg89phTiIqIRCYmRWgrvNOI6HbbgUrGmPtua05UOsL+qM4FeJYIRagxJg+QF5gYh0yvGmPuua050b+ZEn5ui4iIiMht/rryF5X8K3Hw/EEWNlpIpUcqxdu9jh6F1q1hxQooXRree88pNIsWhccfh7Rpo7+GiEhEMWlMNDGe7j0H6AF0Aj4BZ34t0AE4hbNeKMaYewlvYmStvRh+biBwFuhkjPk+wjItHcO/z45Dpvo465dODL9/WpxCfIe19k8PrysiIiLiFccvHaeif0WOXzrOkiZLKJe/XLzcx1qYMMFZTuXmTfj6a2jfXkuriEjcudaYyFr7ozFmGtDLGJMNZwptHeBFwC/Cs561ge+AloQXhuFrd/4P5xnMBcaYH4ASOEXoBGvtLdNxjTFvAVn4/4ZFLxljPgr/82Rr7b+jqd8D64GvjTGPAUeBFkB+4BXv/e1FREREYu/oxaNUmFSBU/+cYmnTpZR9qGy83OfYMWjbFpYuhfLlnWL04Yfj5VYikgzFpDFRc08ubK31j8FhrXCeOW0OtAf+AJpaa6fG4PrfGGNCgO7AKJxOu/2AvpEc/h6QL8LrCuFf4BSdh8OvGWaMqQZ8DrTFKVp3AVWttYEx+PuIiIiIxItDFw5RcVJFzgafZUWzFZTJW8br97AW/P2ha1e4ccN5BrRjR+fZTxERb4nJSOhED65rgWiLUGvtdeDD8K+7HTPxbhmstZOASTG4T/7ojolw7EWcEdWO0R0rIiIikhD2n9tPRf+KXLp+iVXNV1EyT0mv3+PECWe67cKFULYsfPed02BIRMTbYlKEavKFiIiIiEv2nd1HhUkVCA4NZnXz1Tx1/1Nevb61MG0adO4MwcEwZAh06aLRTxGJPzFpTHT7EigiIiIikgD2nNlDxUkVuRF2g0C/QIrlKubV6586BR06wA8/wHPPwcSJULCgV28hInIH1xoTiYiIiMjd/fr3r1Tyd5ZeCfILokjOIl657smTsHmz8zV+PFy5Al9+Ce+8AymjW+VdRMQLYtKYaALOM57trLU3w19Hx1prW8c5nYiIiEgytHz/curPrk/6VOlZ7beaQjkKeXSd4GDYvt0pOLdscb4fPersS5UKXnrJaT5UuLAXw4tIwrHWWUPpnsQ1thiTtBWBMCAFcDP8tY3yjOj3i4iIiMhtrLWM3DqSt5e9TdGcRZnfcD75suSL/kSc30X//PPWgvOXXyA01NmfPz+88AKULg1lykCJEpA2bfz9XUQkHl25AlOnwqhR0Lq109I6EYnJM6H5o3otIiIiInF34+YNOi/pzNhtY6nxeA2m1plKxtQZY3TumTPQqBGsXOm8zpgRSpWC7t2dgrN0aciVKx7Di0jC2LsXRo92HuC+dMn5NOnBB91OFWtxGrc1xqQFsgLm9n3W2hNxubaIiIhIcnH26lnqza5H4KFA3n/hfT6r9BkpTMza0/7yC9Sq5Syx8sUX8Prr8MQTer5TJMkIDXXWTho1yvmkKVUqqFcPOnVyOoqZO0oxnxfrItQYkwboBbQCovpMTf/rExEREYnGnjN7qDatGkcvHcW/lj/NijeL8bkzZkCrVpA1K6xd64x4ikgS8fff8O23MGaM8zB33rzQrx+0aZPopzZ4MhI6FmgObAVmAhe8mkhEREQkmfi3AVGae9IQ6BfI8w8+H6Pzbt6EDz6AgQOd5zznzIHcueM5rIjEP2udB7pHjYLZsyEkBF5+GYYNg+rVE10Dorvx5G/xBjDFWtvc22FEREREkoO4NCA6d855/nP5cmeNz2HDIHXqeA4sIvFv3z5o2hS2boXMmaF9e+jYEQp51h3bl3lShAYDG7wdRERERCQ5iEsDol27nOc/jx2Db75xZuWJSBIwfz40a+Y87/n1104xmjFm/19IjGL2xPutAoBXvB1EREREJKk7e/UsladUZuy2sbz/wvsENAiIcQE6Z47TgyQ4GNasUQEqkiSEhcHHH0PNmvDYY7BtmzPFIQkXoODZSGg3YK4x5jvgW+AIzvqht1B3XBEREZH/t+fMHqpPr86Ri0di1YDo5k3o1Qs+/9wpQr//Hu6/P57Diki8u+fyZec5z8WLoUULZ+mVdOncjpUgPClCrwO7gbdxGhTdjbrjioiIiAAbj26k2rRqpEqZKlYNiC5cgMaNYckSaNcOhg+HNGniOayIxL+dO3mmQwc4fdopPjt0SJRLrXjKkyJ0JNAW+BHYhLrjioiIiNzVoj8WUW92PR7I/ADLmy7n4awPx+i8PXugRg04dMhZoaF9+/jNKSIJZPp0aNOGFOnSQVAQPB+zD6WSEk+K0AbANGttzBexEhEREUmG/H/xp9W8VpTIXYLFTRaTM0POGJ0XGgpvvAEXL0JgoLMMi4gkcjduQM+eMGQIlC3Ltnfe4flkWICCZ42JbgLrvR1EREREJCkZtHEQfj/4UT5/eQL9AmNcgAJMmgS//eY0yVQBKpIEnDoFr7ziFKBdusDq1YRky+Z2KteoO66IiIiIF4XZMLov7073Fd2pX6Q+ixovIlOaTDE+/+pVp1lmmTJQu3Y8BhWRhLFlCzzzjLP+5+TJzuK+qVK5ncpVnkzHHQxMMcZMAsah7rgiIiIigLMGaJsFbfD/xZ+3nn2LYa8PI4WJ3Wf+w4fD8ePOY2PJqE+JSNITGuos6Pv225AnD2zcCCVKuJ3KJ3hShP4a/v0poGkUx6k7roiIiCQb/4T8Q/059Vm8bzGflv+Uj176CBPLKvLsWRgwwFm14cUX4ymoiMSvPXvgu++cUc+TJ6FyZZg2DZLx9NvbeVKEfgpYbwcRERERSazOBZ+j6rSqbD2+lbHVxtLumXYeXad/f7h82VkTVEQSkUuXYOZMp/jctAlSpoQqVaBlS6fNdUqNz0UU6yLUWvtJPOQQERERSZSOXTpG5SmV2X9uP7PrzaZO4ToeXefQIRg50lmzvkgRr0YUkfgQFgZr1sCECfD99xAcDIULw5dfQtOmkDu32wl9licjoSIiIiIC/H76dypPqczF6xdZ2nQp5fOX9/havXpBihTQp4/38olIPDh0yGlhPXGi8+fMmaF5c2fUs1QpPcwdAypCRURERDyw+dhmqk6rSqoUqVjTYg0lcnvecOTnn2HqVOjRA/Lm9WJIEfGe3buhWzdYscJ5XakS9OvntLFOn97dbImMJ0u0iIiIiCRbITdD+CToE1787kWyps3KhlYb4lSAArz/PmTJ4nwXER9z8yZ89ZWzzMrPPzvTFQ4dgpUroUkTFaAe0EioiIiISAxtO7GNVvNbsfPUTpoWa8rQykPJnj57nK65ahUsWwaDBjmFqIj4kEOHwM8P1q6FWrVg7FjImdPtVImeilARERGRaFwLvcanaz5l4IaB5MqYiwWNFlCtYLU4XzcsDHr2hIcegk6dvBBURLzDWqfTbdeuzjOeEyc6z33qeU+vUBEqIiIiEoUtx7bQcl5Lfj/zOy1LtGRw5cFkSeudIctZs2DbNvD3h7RpvXJJEYmrU6egbVtYsAAqVHCK0Xz53E6VpOiZUBEREZFIBN8I5r3l7/H8hOe5EnKFJU2WMKHmBK8VoCEh8OGHUKwYNG7slUuKSFzNnQtFi8Ly5TBkiPPcpwpQr9NIqIiIiMht1h9ZT6t5rdh3bh/tn2nPwFcGkjlNZq/eY+xYOHAAlizROvYirrt4Ebp0caYlPPOM8/2JJ9xOlWSpCBUREREJ90/IP4z4cwQBawLIlyUfK5utpNIjlbx+n0uX4NNPnZl+lSt7/fIiEhurVjlrfJ44Ab17w0cfQapUbqdK0lSEioiIiABBh4JoNa8VBy8cpHOpzvSv1J+MqTPGy70GDYIzZ+CLL9TnRMQ15845nwYNGwYFC8LGjVCqlNupkgU9EyoiIiLJ3tc/fk0l/0qkTJGSYcWHMfz14fFWgJ486Sw5WL8+PPtsvNxCRKLy66/Qvj3kzesUoJ07w44dKkATkIpQERERSbZuht3k3WXv0nFxR6oUqMKO9jsolqVYvN7z00+dpkSffRavtxGRiMLCnG63r7ziNB7y93c6gv3yCwwfDunTu50wWdF0XBEREUmW/gn5hyZzmzBv7zy6lOrC4MqDSZkifjsE7d0L33wDb74Jjz0Wr7cSEXAewJ4wAUaOhP374YEHoH9/ZwmWHDncTpdsqQgVERGRZOfk5ZNUn16dHX/tYNhrw+hSukuC3PeDDyBdOujVK0FuJ5J87dsHI0Y4a3xeuQLPP+8Un7Vrq+mQD1ARKiIiIsnKrlO7qDqtKueCzzGv4TyqFayWIPfdvNlZgrBPH8iZM0FuKZK8WAsrVjjPeS5e7BSbDRs6S6+ULOl2OolARaiIiIgkG8v+XEa92fXIlCYT61qu46n7n0qQ+4aGwttvQ65c0K1bgtxSJHm5cgVat4ZZs5xPeT7+GDp0gNy53U4mkVARKiIiIsnC2J/G0mlxJ4rmLMrCxgvJmzlvgt17wADYsgWmTYOM8dN0VyT5+uMPqFMHfv/dmXLbrRukSeN2KomCilARERFJ0sJsGD1X9GTQpkFUKVCFGW/MIFOaTAl2/59+cqbgNmrkfImIF82fD82aOVNvly+HSpXcTiQxoCVaREREJMm6euMq9WbXY9CmQXQs2ZF5DeclaAF69So0berMCBw1KsFuK5L03bzpdPiqWRMKFIBt21SAJiIaCRUREZEk6a8rf1Fjeg1+OvETQyoPoWvprhhjEjRDjx7OsiwrV0LWrAl6a5Gk69w5aNIEli6FVq2cT3jSpnU7lcSCilARERFJchb9sYgOizpwLvgcAQ0CqFmoZoJnWLrU+d34nXc0QCPiNT//7Dz/eewYjB3rrPeZwB8uSdxpOq6IiIgkGX9d+YsGcxpQbXo1MqfJzLqW61wpQM+cgZYtoUgRp0+KiHjBlCnw3HMQEgLr1kG7dipAEymNhIqIiEiiF2bD+Hb7t/RY0YPg0GD6VuhLjxd6kDpl6gTPYi20bw9nzzqjoZolKBJHISHw3nswYgSUKwczZzrrHUmipSJUREREErXfT/9Ou4XtWH9kPeXzl2dstbEUzF7QtTz+/jB3LnzxBRQv7loMkaTh5EmoVw82bHCWXvniC7hHJUxip/+CIiIikihdC73G5+s+5/P1n5MpTSYm1JhAixItErz5UEQHD0LnzvDSS/Duu67FEEncbt50nv1cvRoGD4ZLl2DGDGjQwO1k4iUqQkVERCTRCToURPuF7fnj7B80ebIJgysPJmeGnK5munkT/PycP/v7Q8qUrsYRSTyshT17nKJz1SoICoLz5519zzwDK1ZA0aKuRhTvUhEqIiIiica54HN0X96dCT9P4OEsD7Os6TJeffRVt2MBMGiQ0ytl0iTIl8/tNCI+7sgRp+Bcvdr5OnHC2Z4vH9Su7bSUrljRWWRXkhwVoSIiIpIozNg9gy5LunAu+Bw9X+hJ73K9SZ8qvduxANixA3r1grp1oVkzt9OI+KgdO2DMGKf43L/f2ZYzp1NsVqzoFJ6PPOJuRkkQKkJFRETEp1lr+Wj1R/Rf359SD5RiRbMVFM/tOx1/goOhaVPIkcP5/VorRojc5vJl6N0bhg+HDBmgfHl46y2n6CxaVP9okiEVoSIiIuKzQsNC6bCwA+N3jKft020ZXXU096TwrV9fPvgAfvvNWY4le3a304j4EGudVtFduzrTbTt0cBbOzZLF7WTishRuBxARERGJTPCNYOrOqsv4HePp9VIvxlYb63MF6MqVMHSoM6hTubLbaUR8yKFDUL26M0c9Rw7YtAlGj1YBKoBGQkVERMQHXbh2gRrTa7D+yHpGvD6Ct0q95XakO5w7By1aQKFCztKFIgLcuOEsq9KnD6RIAV99BV26aG1PuYV+GkRERMSnnLh8gtemvMaeM3uYUXcG9YvUdzvSHUJDoU0bOHUK5s2D9L7RH0nEXRs2OFNud++GWrVg2DB46CG3U4kP0nRcERER8Rl/nP2D58c/z8ELB1nSZIlPFqAhIdCwIQQEwJdfOssYiiRr585B27ZQtixcvOh8MhMQoAJU7kojoSIiIuITfjz+I1WmVcFgCPIL4pk8vlfdBQc7j7gtXgxDhsDbb7udSMRF1sLkyfDuu3D+PLz3Hnz8MWTM6HYy8XEqQkVERMR1y/cvp87MOuTMkJNlTZdRIHsBtyPd4coVqFEDgoJg3Dhn4EckWbl0CX76CbZsga1bne8nT0KZMjB2LBQr5nZCSSRUhIqIiIirpu+ajt8Pfjxx3xMsabKE+zPd73akO1y4AFWqOL93T54MTZq4nUgknt24Abt2/X+xuXUr/P67M/oJULCgs85n5crQuLHThEgkhlSEioiIiGuGbR7G28veply+csxrOI97097rdqQ7nDkDr77q9FqZPRtq13Y7kUg82bTJ+SHfsgW2b4dr15zt990HpUo5D0OXLg0lS0K2bO5mlURNRaiIiIgkuJCbIXwc+DEDNgygTuE6TK0zlbT3pHU71h1OnoSXX4YDB2D+fHjtNbcTicSD48ehRw+YNg3SpnW6bb35plNwlioF+fODMW6nlCRERaiIiIgkmEvXLzFu2ziGbB7CicsnaPd0O0ZXHU3KFCndjnaHw4ed2YanTsHSpVCunNuJRLzs2jUemjoVpk931h3q1Qt69oQMGdxOJkmcilARERGJdycvn2TYlmF8/dPXXLp+iYoPV2RCjQm8+uirGB8cYdm3zylAL1+GFSucvisiSYa1sHAhvPMOj+zf78wx/+orePhht5NJMqEiVEREROLN3jN7GbRxEP47/QkNC+WNwm/Q44UelMxT0u1od3XwYHoaNXIGhgIDoUQJtxOJeNHevc7aQkuXQuHC/PLllxR/7z23U0kyoyJUREREvG7zsc0M3DCQH/b8QJp70tD6qdZ0e64bj2V7zO1oUdq+Hd5++ykyZIC1a6FwYbcTiXjJpUvQty8MHQrp0zsL3XbqxPkNG9xOJsmQilARERHxijAbxuJ9ixm4YSDrjqwja9qsfPjih3Qu3ZmcGXK6HS9amzbB669DunQ3WbcuFY8+6nYiES8IC3PWFerZE/7+G1q1gv79Iafv/5uUpEtFqIiIiMTZ3jN7qTu7Lrv/3s2DmR9kaOWhtH66NRlTZ3Q7WrTCwmDECOd39Icegr59d/Doo8+5HUsk7jZuhG7dnCVXypSBBQvg2WfdTiWiIlRERETi5o+zf1BhUgVu2ptMrj2ZBkUakCplKrdjxciJE9CihdN8qHp1GD8efv31utuxRDxnLSxfDgMGQFAQ5M4NkyZB06aQIoXb6UQAFaEiIiISB/vO7qPCpAqEhoUS6BdIkZxF3I4UYwEB0LYtXL0KY8ZAu3ZaClESsZs34fvvneJzxw7Ik8fpeNuuHWT0/RkJkrzo4xARERHxyP5z+6kwqQIhN0NY7bc60RSgV65A69ZQpw7kz+/8vt6+vQpQSaSuX4dvv3W6aDVoAP/847w+cMCZiqsCVHyQRkJFREQk1g6cP0CFSRW4FnqN1X6rKZqzqNuRYmTLFmjSxPn9/IMP4OOPIXVqt1OJeODyZRg3DgYPduaVP/MMzJ7trPmZMqXb6USipCJUREREYuXQhUNUmFSBf278w+rmqymWq5jbkaIVGuo0BP30U8ibF9asgRdfdDuViAfOnIHhw2HkSDh/HipWhIkT4eWXNZwviYaKUBEREYmxwxcOU35ieS5fv8yq5qsonru425GideCA05Nl0ybn+8iRcO+9bqcSiaX9+2HYMGeqbXCwM+LZsyeULu12MpFYUxEqIiIiMXLk4hHKTyrPxesXWdlsJU/d/5TbkaJkrdMUtHNnZ3bi9OnQsKHbqURiwVpYt86Zcjt/PtxzDzRu7BSfhQu7nU7EYypCRUREJFpHLx6lwqQKnA8+z8rmK3kmzzNuR4rStWvO0iszZ0K5cuDv76wBKpIohITArFkwZAhs3w7ZszsPMXfs6HS9FUnkVISKiIhIlI5dOkaFSRU4c/UMK5qtoGSekm5HitK/MxWXLXOeA+3RQ31aJJE4exbGjoVRo5xmQ4UKOa+bNoX06d1OJ+I1KkJFRETkro5fOk7FSRX5+5+/Wd5sOaUeKOV2pChdvQo1a8KqVTBhArRs6XYikRjYuxeGDnXmjwcHwyuvOM9+Vq4MKbSioiQ9KkJFREQkUicvn6Sif0VOXjnJsqbLKJO3jNuRonTlClSvDmvXOr/LN2vmdiKRKFgLQUEwaBAsXgxp0jgjnm+/DUUTx5JHIp5SESoiIiJ32HVqF/Vm1+P4peMsbbqU5x983u1IUbp8GapWhQ0bYPJkp3eLiM9aswZ693Y+McmZEz75BN580/mzSDKg8X0RERH5z5/n/qTJ3CYUH1OcU/+cYkmTJZR9qKzbsaJ06RK89hps3AgzZqgAFR+2fj1UqgTly8O+fTBiBBw+DB9/rAJUkhWNhIqIiAjHLh2j75q+jN8xntQpU9PzhZ50f6E72dJlcztalC5ccB6b277daSZap47biUQisWmTU2iuWOEUm0OGQPv2kC6d28lEXKEiVEREJBk7/c9pPl//OaN/HE2YDaPjsx354MUPyJ0xt9vRonXuHLz6KuzcCXPmOA2JRHzKjz86xeeSJZAjB3z5pTPtNkMGt5OJuEpFqIiISDJ08dpFvtr0FUM2D+Hqjav4Ffejd7ne5M+S3+1oMXL2LLz8Mvz2GwQEOM+DiviMHTuc4nPBAsiWDQYMgE6dIGNGt5OJ+AQVoSIiIsnI1RtXGbl1JAPWD+D8tfPUL1KfPuX7UChHIbejxdjp085jdX/8AfPnO9NxRXzCrl1O8RkQAFmyQL9+0LkzZM7sdjIRn6IiVEREJBm4cfMG32z/hr5r+/LXlb+oUqAK/Sr046n7n3I7WqycOuUUoAcOwMKFzmioiOvCwmDgQPjoI2eq7SefQNeuTiEqIndQESoiIpLEnb16lnqz6xF4KJCX8r3EnHpzeOGhF9yOFWsnT0LFinDkiLOsYvnybicSAf76y1mUduVKqFcPxoxxpuCKyF2pCBUREUnCfj/9O9WnV+fopaNMrDmR5sWbY4xxO1asWOtMu333Xef3/aVL4cUX3U4lgvPD2Lw5XLkC48ZBmzaQyP59ibhB64SKiIgkUUv/XEqZ8WW4HHKZIL8g/Er4JaoC1FpnxPPZZ6FWLed3+xUrVICKDwgJge7d4fXXIVcu+OknaNtWBahIDKkIFRERSWKstf/H3n1HR1WtfRz/7jRICAQIEAIk9N67NEGaBdALigW59o69Xl8uWLBfuIoKKlZUuIoV7KgQQKX3DtJCCSUEAuntvH/sCSkkQCDkpPw+a511Zs7sM+eZnckkz+zGa4teY9D0QdSvXJ+lty+lW1g3t8M6Y44Ds2dDt2521tuYGPjwQ9i40R4TcdW2bdCzJ4wfD3fdBUuWQIsWbkclUqKoO66IiEgpkpKewqgfRvHeyvcY2mwoHw/9mEC/krMsxNy5MHYs/PEHhIfDu+/CjTeCr6/bkYkA//sf3HkneHvbxWmvvNLtiERKJLWEioiIlBLRCdEM+GQA7618j9G9RvPl1V+WmAR0wQK46CI78dCOHTB5sl2C5bbblIBKMRAfD7fcAiNGQOvWsGqVElCRc6CWUBERkVJg/cH1DPnfEPYd38e0YdMY0XqE2yGdkYUL7bKKv/5qh9ZNnAh33AHly7sdmYjHqlVw7bX2W5HRo+3yKz76F1rkXOg3SEREpIT7YcsPXPfVdVTwq8C8m+bRtU5Xt0PK17FjsHy5ncfl11/tVr26HV53990QEOB2hCIeBw/CJ5/YxLNqVbsES9++bkclUiooCRURESmhHMdhwsIJPP7r47Sr2Y5Z182iTqU6bod1QkKCbURautQmnUuXwubNWY/Xrw8vvQSjRkFgyeg1LKVZcjL8+aedFWv2bFi50h6/7DL46CP7bYmIFAoloSIiIiVQUloS9/xwDx+u+pArm1/J1H9MpYJfBVdjWrMG/vorK+lcvx7S0+1jtWpBp04wcqTdd+oE1aq5Gq6UdY5jvxX55RebdEZE2J7mEQcAACAASURBVG9OfHygRw94/nkYOBA6dtTSKyKFTEmoiIhICXI06ShvL3ubiYsnsj9uP2MuHMPTfZ7Gy7g71+Arr8ATT9jbwcF2bc/LL7f7Tp1sEiriupgY+P33rMRz9257vEkTO/HQwIHQpw9UrOhqmCKlnZJQERGREmB37G5eW/QaU1ZMIS4ljgENBjB92HQuqn+R26ExaZJNQK++Gl5+GerWVcORFDNpafabkmeegZQUCAqC/v3h3/+GAQNs33ARKTJKQkVERIqxtQfWMn7heKavnY7jOFzT6hoe7fYo7UPbux0aAFOnwr33wpAh8OmnWk5FiqG1a+Hmm+2MWMOHw0MP2SZ6zXAr4hr99omIiBQzjuOw6ugqXpn2Cj/9/RMBvgGM6jyKBy94kHqV67kd3glffGF7MPbrBzNmKAGVYiY11c58NW4cVK5s37BXXeV2VCICuDqAxBjjZ4wZZ4yJNMYkGWPWGGOuK8D5//Sck2SM2WWMecYYc9KfwDO9jjHmaWOMk89WfKYbFBGRUik9I50v1n9B1/e68tDqh1i2bxnjLhpH5IORvHbJa8UqAf3hBxgxArp1g5kzta6nFDOrV0PXrjB2LFx5JWzYoARUpBhxuyX0fWAEMBlYAwwDphtjvBzHmXaqE40xtwLvAT8CbwBtgTFALeD2c7zO/cCRXMdiCvC6RERECuSbjd/w2K+Pse3INhpVbcRDjR/i+eHP4+/r73ZoJ5k71/5f36aNTUYruDspr0iWlBR48UV47jm7tudXX8GwYW5HJSK5uJaEGmM6AiOBZxzHedpz7D1gPjDeGDPDcZzUfM4tD7wERACDHcdxPMePAv9njHndcZy153CdbxzH2VOYr1dERCQvKekpPP7r40xcPJG2IW356uqvuKLpFSyYv6BYJqALF9rxnw0b2glGg4LcjkjEY9UquOkm2wo6YgS8/rqdqllEih03u+NeDTjApMwDnmRyMlATuPAU514EVAMmZSagHpMB43nuc7mOMcZUMsbl+e5FRKRUi4yN5MIPL2Ti4onc1+U+lty+hGHNh+Ht5e12aHlatQouvRRq1oTfftM6n1JMpKTAU0/ZyYYOHIBvv4Vp05SAihRjbiZZHYCdjuMcynV8SbbHT3Vu9rIAOI6zD9iT69yzuc56IBaIN8Z8a4xpdIpYRERECuzHrT/S/p32bDi0gRlXzeD1S1/Hz9vP7bDytXGjXUKxUiW7zGJoqNsRiQArVtiFaJ99Fq67DtavhyuucDsqETkNN8eEhgJReRzPPHaqZa0z//Tld36tXGXP9DpHsC2kC4F4oAvwALDQGNPRcZzIU8QkIiJyWmkZaYydO5YX/3iRtiFt+WL4FzQObux2WKe0fbtdUtHLyyagdeu6HZGUWSkptk/47Nl2W77cNs3PmmX7iYtIiWBy9mYtwgsbsw3Y5ThO31zHvYB04B3Hce7K59z3gZsdxzmpJdcYMx+o4ThOs3O9jqdcb2Au8JHjOLecotwdwB0AISEhHT/77LP8ihaauLg4AgMDz/t1JCfVu3tU9+5QvRee6ORoxm0cx5rYNQyqOYj7Gt1HOe9yeZYtLvV+6FA5HnigHfHxPrz66ioaNIh3O6TzrrjUfVmTZ707Dv5791J16VKqLFtG5ZUr8UlMxPHy4liLFsR07szeoUNJq1jRnaBLAb3f3VPa6/6iiy5a7jhOp7wec7MlNBHI6y9v+WyPn+pcY4zxzWNSofK5zj2X6+A4zjxjzBJgwGnKTQGmAHTq1Mnp06fPqYoXioiICIriOpKT6t09qnt3qN4Lx+/bf2fU16OIS4lj6j+mckPbG05ZvjjU+8GDcOGFEBcHc+ZAp06dXY2nqBSHui+LTtT70aO2yT2ztXPnTlugQQM78dDAgZiLLiIoKIggoL57IZcKer+7pyzXvZtJaBSQ11jLzK62+05zLtiutLvyOH9NIV0nUyTQ5gzKiYiI5JDhZPD8/Od5KuIpmlVrxpwb5tCyRku3wzqtdetg5EiIjLSz4HbK87tskUKSlETNH3+E0aNh0SLIyICKFaFfP3j8cTsguWFDt6MUkULiZhK6AuhnjKmea9KgrtkeP9W5AJ3JloQaY2oBdYCPCuk6mRoCuSc2EhEROaVD8YcY+c1IZm+bzfWtr+ftwW8T6Fd8u14lJ8OXX8Jbb8Gff4K/v51otFcvtyOTUmv/fvuGe+stmh06BK1a2UR04EDo2hV8fd2OUETOAzdnx/0Su5zKqMwDxhgD3AUcwK7jiTEmyBjTzBiTfSWyucBhYJTnnEz3ePZfFPQ6nuM1cgdpjBmCnUH3x4K/RBERKYvSM9KZuWkm7d9pz7yd83hn8Dt8MvSTYpuAbttmG5vq1LGtn/v3w3/+Y1tBBw50OzoplTLX9KxbF8aNgwsuYNWECbBmjZ3ptmdPJaAipZhrLaGO4yw1xkwHxhhjqmK70A4DegE3ZhvrORT4ELgZTwun4zhJxpgnsWMwvzPGfAu0wyahHziOs+YsrgOwyxgzA1gLxGFbWm8EdgPPnIdqEBGRUiQmMYYPV37I5GWT2X5kO42qNmLhrQtpH9re7dBOkpYG338Pb79tu9t6e8Pll8Pdd9sekF5aKVsKW3q6fdO99hpEREBAANx+OzzwADRuzNGICMjRtiAipZWb3XEBbgF2AjcAdwJbgJGO40w73YmO47xrjEkBHgMmAQeB54Bx53CdT4DuwD8Af2Av8DbwrOM4Bwv42kREpIxYvX81by55k2lrp5GYlkiv8F682O9FhjYbiq938WrN2bsX3nsP3n3X3q5dG55+Gm67zd4WKXTHj8NHH8HEibbZPSwMXnnFvumqVHE7OhFxgatJqOM4ycBoz5ZfmY/IOcYz+2NTgamFcR1PuTtO91wiIiIAqempfLPpG95c8iYLIhfg7+PP9a2v594u99K2Zlu3wzvJ0qXw4ot2OcX0dNvN9s03YfBg8HH7K2kpfRzHdrmdNs1+6xEbCxdcAC+8AMOG6U0nUsbpE0BERKQA9sftZ8ryKby97G2i4qKoX7k+4weM5+b2N1PVv6rb4Z1k7VoYMwZmzoSqVeHhh+HOOzXRqJwHSUl2LZ9Zs2y32717bT/vq66CBx+0SaiICEpCRUREzsiq/at45c9X+HLDl6RmpHJJo0t4t/O7XNLoEry9vN0O7yRbt8JTT8Fnn9mVLp591uYBFSu6HZmUKvv3ww8/wHffwa+/QkICVKhgm9qHDIFBg6DGSfM+ikgZpyRURETkFOJT4nkq4ileXfQqgX6B3NP5Hu7pfA9Ngpu4HVqeIiPtZKMffgjlysETT8Bjj9lWUJFz5jh2BtvvvrPbkiX2eFiYne12yBDo0wfKl3czShEp5pSEioiI5GP2ttnc9f1d7Di6g9s73M7L/V+min/xnEjlwAE73O7tt+39UaPgySehZk1345JS4vhxO4j47bftNx0AXbrYbzyGDIE2bTSzrYicMSWhIiIiuUQnRPPwLw/zyZpPaBLchIgbI+hdr7fbYeUpJsau6fn665CcDDffbMeAhoe7HZmUCnFxMGmSfZMdPmy72Y4da7vZ6hsOETlLSkJFREQ8HMdh2tppPPTLQxxNOsq/e/2b0ReOprxP8etaePy4XfFi/Hg4dgyuu84utdK4sduRSakQHw9vvQUvvwzR0XDppfYN1qWL25GJSCmgJFRERATYcWQHd/9wN79s+4Wutbvy7pB3aR3S2u2wTpKQYBumXn7ZNkxdcYXtEdm6+IUqJVFCgu1y+/LLcPCgbfl85hnNbCsihUpJqIiIlGlpGWm8vvh1xswdg5fx4vVLXueezvcUuxlvk5LgnXfsWp8HDsDFF9sZb9UwJYUiMRGmTIGXXrIz3vbvb5PP7t3djkxESiEloSIiUmat2r+K22bdxvKo5QxuMpjJl00mLCjM7bBySEmB99+H55+3yy5edBF89RX06OF2ZFIqJCXBe+/ZWa2iouwbbMYM6NXL7chEpBRTEioiImVOTGIMz89/nomLJxIcEMznV33O8BbDMcVods+0NMP779uutrt22aTzk09sjiBy1hwHtm+HpUvt8iozZthvNy68EKZPt8uriIicZ0pCRUSkzIhPiWfi4om88ucrHEs+xq3tb+XlAS9T1b/4LKKZnm5zgX/9qwv79kHnzrYb7sCBWgFDzkJUlE04M5POZcvslMpg1/Ls2RM+/th+u6E3mIgUESWhIiJS6qWmp/L+yvd5Zt4z7I/bz5AmQ3ih3wu0qtHK7dBOyMiAL7+0E5Bu3AiNGqUxaxYMHqzcQM5QYiL8+WfOpHPvXvuYtze0agXDhtlvNjp3tvd9fd2NWUTKJCWhIiJSamU4GXy54Uv+PeffbI3ZSo+wHnwx/At6hvd0O7Qc0tJgxAj44gto2dImo1WqLKdv3z4uRyYlwpEjdsrkiRPtcipg1+rp3Tsr4WzfHgIC3I1TRMRDSaiIiJRKv23/jX/99i+WRy2nZfWWzLp2FoObDC5W4z7Bdr+96SabgL70Ejz6qG20iohwOzIp9vbsgVdftbPaxsXBoEFwzz3QrRtUqeJ2dCIi+VISKiIipcryfcv51+//4rftvxEeFM5HV3zEyDYji92SK2C74N55J0ybZicnfeIJtyOSEmHTJvjPf+xMVRkZcO218Pjj0KaN25GJiJwRJaEiIlIq/B3zN6PnjGbG+hkE+wfz6sWvcnenuynnU87t0PLkOHD//Xb5lbFj4ckn3Y5Iir0lS+Dll+Gbb6BcOfsNxiOPQL16bkcmIlIgSkJFRKREi0+J57n5zzFh4QT8vP0Yc+EYHu3+KJXKVXI7tHw5Djz2mB3G99hjdjIikTw5Dvz2m+2rPWcOVK4Mo0fDffdBjRpuRyciclaUhIqISInkOA5fbviSh2c/zJ5je7ix7Y281P8lagbWdDu00xo7FiZMsHnEyy9r9lvJJSMDNmyA+fPhvfdg5UqoVQvGj4c77oCKFd2OUETknCgJFRGREmdT9Cbu++k+ftv+G+1qtuOzKz+jR3gPt8M6Iy+8AM89B7fdBq+9pgRUgJQUWL4c/vgDFiywy6xkruXZtKnts3399bYLrohIKaAkVERESoy4lDjGzRvHq4teJcA3gDcufYO7Ot2Fj1fJ+HP23//anpQjR8Lbb4OXl9sRiSuOH4eFC7OSzsWL7RqfAE2awNCh0KsX9OwJDRromwoRKXVKxl9tEREp0xzHYcb6GTwy+xH2Ht/Lze1u5qX+L1GjQskZEzd5sp1DZvhw+PBDuwyLlCH79tmlVL7/HlatsmvzeHlBu3a2i21m0hkS4nakIiLnnZJQEREp1jYc2sB9P93HnB1zaF+zPV8M/4JuYd3cDqtAPvgARo2Cyy+3y7H46K9v2eA4tpXz9dftQrDp6TbRfPJJm3R266bxnSJSJunPoIiIFEvHk4/zzLxnmLh4IoF+gUy+bDJ3dLyjWK73eSrTp9vxnxdfDDNmgK+v2xHJeZecbJPO11+HpUuhUiU7C9WoUdCwodvRiYi4TkmoiIgUK1sOb+Hd5e/y0eqPiE6I5tb2t/JivxepXqG626EV2FdfwQ03QO/e8PXXmlem1IuKsoN933kHDhyAZs3sOjw33ACBgW5HJyJSbCgJFRER1yWlJfHNxm+YsmIKETsj8PHy4YqmV/BY98foWqer2+EVmOPYbrc33wxdu8J330FAgNtRyXmTvcttWhoMGmRbPvv31+xTIiJ5UBIqIiKu2RS9iXeXv8vU1VM5nHiYBlUa8GK/F7mp3U0lYr3PvKxbB/ffD3PnQvfu8OOPagQrVZKSYOdO2LEDtm613zYsWWK73I4aZbdGjdyOUkSkWFMSKiIiRSopLYmvNnzFlBVTmL9rPj5ePgxtNpQ7Ot5B3/p98TIls+Xo6FF4+ml4800ICoK33oLbb9csuCVORgZ+hw7ZpVN27IDt27P227fbWW6za9LE/tBvuEGTDImInCEloSIiUiQ2RW/inWXvMHX1VI4kHaFR1Ua83P9lbmx7IyGBJXdZiowM+Ogj+Ne/IDoa7rwTnnsOgoPdjkwKZO5cGDMGli2je3Jy1nFjoE4dqF8fBg60+wYN7Fa/PtSsqXU8RUQKSEmoiIicV7tjd/Pvuf/mk9Wf4OPlw7Dmw7ij4x30qdenxLZ6Zlq6FO691/bG7N4dfv4ZOnRwOyopkHXr4IknbL/p8HC47z62pKXR5JJLbKIZHq4ZpURECpmSUBEROS+OJh3lpT9e4rVFrwHwWPfHeLT7oyVyltvcDh6E//s/u/5nSAh8/DGMHKkGsRJl71546in48EPbjfaVV+xkQuXLsy8igiZ9+rgdoYhIqaUkVEREClVyWjJvLXuLcfPHcSTxCCPbjGTcReOoW7mu26Gds7Q0mDwZxo6F+Hh45BHbg7NSJbcjkzN27Bj85z8wYYL9gT7wAIwerf7TIiJFSEmoiIgUCsdxmLF+Bk/+/iQ7ju6gf4P+vNL/FdqHtnc7tHPmOPD77/Dww7B2LQwYABMnQvPmbkcmZyw1Fd59184edegQXHstvPCCHdcpIiJFSkmoiIics3k75/HYr4+xdN9SWtdozc/X/8zAhgMxpaB/6rx5tuVz/nyoWxe+/hr+8Q91vS0xHAe++cbOHLV1K/TubVtCO3d2OzIRkTKrZM8IISIirtpwaAOX/+9y+kztQ1RcFB9d8REr71zJxY0uLvEJ6B9/QL9+0KePzV3eeAM2bYKhQ5WAlgiHD8Ps2dCzJ1x5Jfj4wHff2VlwlYCKiLhKLaEiIlIg6Rnp/BH5B1NXT2Xq6qkE+gXyYr8XeaDrA/j7+rsd3jlbtMjOVzN7NtSoAa++apdd8S/5L630SU2Fbdtg8+ac26ZNNgkFu4TKlClw8802ERUREdfp01hERE4rNT2VOTvm8NXGr/h207ccSjhEeZ/y3Nv5Xsb0HkO1gGpuh3jOli61yedPP0G1arbH5t13Q4UKbkcmACQk2L7Qq1ZlJZvbt0N6elaZkBBo2hSGDYNmzeztPn30QxQRKWaUhIqISJ6S0pKYvW02kzZNYsniJRxNOkqgXyCDGg/iyuZXcmnjSwn0C3Q7zHO2cqVNPr/7DqpWhZdeglGjILDkv7TSYe9emDQJ3nkHYmLsmp2NG0ObNnD11TbRbNoUmjSBypXdjlZERM6AklARETkhLiWOn7b+xFcbv+KHrT8QlxJHoE8gw1oO48rmVzKw4UDK+5R3O8w8xcfbHphpabaXZmpq1u28jiUnw7Rpds6aypXhuefsMpFabqWYWLoUXnsNZsyAjAw7G9QDD0CPHuDt7XZ0IiJyDpSEiogIaw+s5Zl5z/DD1h9ISkuiekB1rmt1HVc2vxKvSC8G9B3gdognSUyEhQvtPDNz5sCSJTbBLIhKleyKHQ8+CEFB5yVMKYi0NPutwGuvwV9/QcWK9puB++7TUioiIqWIklARkTIsOiGaMXPGMGXFFILKBXF7h9u5svmV9AzvibeXbW2K2BPhbpAeqak20cxMOv/6y7ZmennZyU4ffRQaNbJzz/j62u10txs0UMtnsXD0KLz3np2CODLS/mAmToSbbtIPSESkFFISKiJSBqWmpzJ56WSenvc0x5OPM6rzKJ7u8zRV/au6HdoJ6el2vGZm0rlgge1yC9CunR232bcv9OqlPKXEcRz7w9y1C95+Gz780N7v0wdefx0GD1aXWxGRUkxJqIhIGfPz3z/z0C8PsSl6EwMbDuTVi1+lRfUWboeVw99/wyWX2NU3AJo3t41ifftC794QHOxqeJKX2Fg7fvPAATh2zN4/dizn7ezHMjLseX5+cN11tk90u3buvgYRESkSSkJFRMqIzdGbeXj2w/y49UcaVW3Ed9d9x6DGgzDGuB1aDmvXwsCBtvvtxx9D//4QGup2VJKvhAR48007rfCRI/ZY+fJ2kG2lSln7Ro1y3g8KgipVYNAgu5aniIiUGUpCRURKuaNJR3l23rO8seQNAnwD+M+A/3B/1/vx8/ZzO7STLFliW0D9/WH+fGhRvBpoJbvUVHj/fRg3Dvbtg0svhWeftUun+BW/95aIiBQfSkJFREqp9Ix03lvxHv+e+28OJxzm1va38lzf5wgJDHE7tDxFRMCQIVCjBvz2myZDLbYyMuCzz2DsWNtfukcPe79XL7cjExGREkJJqIhIKbP9yHZmbZ7FBys/YO3BtfQK78XESybSPrS926Hl64cf4Kqr7KSov/4KtWq5HZGcxHHsD2r0aFizxrZ4fv89XHYZFLMu3SIiUrwpCRURKeEynAyW7VvGrM2zmLl5JusOrgOgVY1WfH7V5wxvMbzYjfvM7vPPYeRIaNsWfv4ZqlVzOyI5yfz58OSTdl2chg1h+nS45hq7Po6IiEgBKQkVESmBktKSmLNjDrM2z2LW5llExUXhbbzpVbcX/x34Xy5vejkNqzZ0O8zTevdduPNO25Pzu++01Eqx4TiQkmJniRozxn47UKuWXU7lllvsIqsiIiJnSUmoiEgJcTjhMD9s/YFZm2fx898/E58aT6BfIJc0uoQrml7BpY0uJTig5Kxd8t//wiOP2PlsvvwSAgLcjqgUS0+Hb7+Fb76BuDhITISkJLvP3LLfT0qyiSjYGWxfeQXuvdfOGCUiInKOlISKiBRzkbGRPBPxDFNXTyXdSadWxVr8s80/uaLZFVxU7yLK+ZRzO8QCcRx4+mk7kerw4fDpp5pM9bxJSoKpU2H8eLv4as2aduYnf3+7BQdn3S5f/uTbVavaNTyDgtx+JSIiUoooCRURKaYOxh/khQUv8NaytwC4p/M93ND2BjqGdizWYzxPJSMDHn4YJk60vTqnTAFvb7ejKoWOHIG33rIVffAgdOoEX3wBQ4eqwkVExHVKQkVEipnYpFgmLJzAq4teJSE1gZvb3czY3mMJDwp3O7Rzkp4Od9wBH3wADz4IEyZoXptCt3s3vPaaze7j4uyiq48/Dn36aAZbEREpNpSEiogUE4mpiUxaOokX/3iRmMQYhrcYzriLxtG0WlO3Qzsnycl2DdA33rArfDz1lN2UExWi9evhP/+BadNsf+drr4XHHrNTDouIiBQzSkJFRFyWmp7KBys/4Nn5z7Lv+D4ubngxz/d9no61Orod2lmLjoYff4RZs+CXX2yjXECAbaR74AG3oyslHAf++MNOGvT997aC77nH9neuW9ft6ERERPKlJFRExCUZTgafr/ucsRFj+Tvmb7rV6cb0YdPpXa+326EVmOPA5s026fzuO7ucZEaGXdVj5EgYMgT69rXz3chZOHwY1q2z29q1WbdjY+3Cqs88A6NG2YmGREREijkloSIiRSgpLYll+5bxZ+Sf/G/d/1h9YDWta7Rm1rWzGNxkcImacCgtDf78Myvx3LrVHm/f3i4tOWQIdOigbrcFEhcHGzbAunU0/OkneP55m2zu359VpnJlaN0aRoyAzp3hmmu0vo2IiJQoSkJFRM6j6IRo/tr9F39E/sGfu/9k2b5lpKSnANCqRis+Hfop17W+Di9TfGfoyciA7dth40abH2XuN2yA48ft8ip9+8JDD8HgwRAW5nbEJUxyMnz1FbzzDsyff+JwrXLlbLJ5ySXQqpW93aoVhIYqsxcRkRJNSaiISCFxHIetMVv5M/JP/tz9J39E/sHmw5sB8PXypVOtTtzf5X56hveke1h3qleo7nLEOaWm2qUkcyebGzf2Ijk5q1zNmtC8Odxwg00+BwyAihXdi7vE2rrVzmL70Ud2EG2DBrYJuUMHaN2aBTt30qdfP7ejFBERKXRKQkVEztGWw1t4Y/EbzNgwg4PxBwGo6l+V7mHduandTfQI60GnWp3w9/V3OdK8xcXZiVUnTID4+KzjdetCixbQuPE+Bg4Mo0ULm3xWqeJerCVeSgrMnGlbPX//3a7ZecUVcNdd0K9fzjVrdu92L04REZHzSEmoiMhZcByHX7f/ysTFE/lx64/4efsxrPkw+tbrS4/wHjSr1qxYd7EF28126lQYPRqiomD4cLj8cptoNmsGFSrYchER2+jTR31sz8mOHfDuu3aR1AMHbIb/3HNwyy22e62IiEgZoiRURKQAElIT+GT1J7y+5HU2HNpASIUQnu79NHd1uouQwBC3wztjc+fCI4/AypXQtasdktitm9tRlWCOY2dqSk3N2qemwqJFttXzl1/sOM7Bg+HOO+Hii20rqIiISBmkJFRE5Azsjt3NpKWTmLJ8CkeSjtAhtANT/zGVa1peQzmfcm6Hd8a2bIHHH7c9QsPD4X//s5Orap6bUzh2DL7+GqZNs4Nksyeamfv09PzPr10bxo6FW2/VrE0iIiIoCRURyZfjOPy1+y8mLp7I1xu/xsFhaLOhPHjBg/QI61GillOJiYFx4+DNN8HfH158ER54wN6WPKSk2NbLTz+1a9AkJUHDhnamWj8/8PUFHx+7z34797G6dWHgQHtbREREACWhIiI5HEs+xvJ9y1mydwlfbvySZfuWUbl8ZR7u9jCjOo+ibuW6bodYICkp8NZb8MwzEBsLt90Gzz4LISWn53DRcRzbffbTT+Hzz+HwYahWzVba9dfbfssl6IsHERGR4kpJqIiUWclpyaw5sIYle5ewdN9SluxdwqboTTg4gF3Hc/Jlk7mh7Q1U8KvgcrQFk5oK338PTzxhVwIZMMDOftu6tduRFUNbttiutp9+ahdELV8e/vEPGDnStmL6+rodoYiISKmiJFREyoQMJ4Mth7ewZO+SE0nnqv2rSElPAaBGhRp0qd2F61pdR+fanelcqzPBAcEuR33mHAfWrbOrfvz+O8ybB8eP25luf/zR9iIt8414KSl22ZNdu+y2cyf8/DMsWWIrp18/O3Zz6FCoVMntaEVEREotJaEiUqolpiYydfVUXl30KlsObwEg0C+QjqEdeaDrA3Sp3YUutbsQVimsRI3xBJtDZSadc+bYlT8AGjWyvUcHDLBLrpSZ4YhJSbBtGGHgmQAAIABJREFUW1aSmXuLirLZenbt2sH48XDttXYCIRERETnvysq/JiJSxhyMP8jkpZOZtHQS0QnRdKrViSmDp9A9rDvNqjXD26vkLY8RHW2TzczEc9s2e7xmTejf3zbk9etnZ70tM9LS4NdfYfp0+OYbiI/PeszHx85GW7euzcjr1s3a6tWDOnWgXMmZ2VhERKS0UBIqIqXK5ujN/Hfhf/l4zcckpSUxpMkQHu3+KL3Ce5W4lk7IGts5ZYqdrNVxbE/RPn3g/vtt0tmiRRnraus4sHixHcf5+edw6BBUrgzXXQcXXZSVaIaGai1OERGRYkhJqIiUeI7jsCByARMWTmDW5lmU8y7HjW1v5KFuD9GsWjO3wzsrO3bAe+/BBx/A/v22p+jo0TBoEHTqVIa62Ga3aZNNPKdPtxMIlSsHQ4bYvseXXqpWTRERkRKiLP4bIyKlRFpGGl9v/Jrxf41n6b6lBPsHM/bCsYzqMooaFWq4HV6BpabaJSmnTLE9TI2xSecdd9iJhcpk4rlvH3z2mU0+V6wALy/o2xfGjLETCAUFuR2hiIiIFFBZ/JdGREoox3HYdXQXK6JWsGzfMqatncau2F00rtqYtwa9xQ1tbyDAN8DtMAts2zbb6vnhh3ZyobAwePppuOUWO2yxVHMcOHIEIiPtzLWRkVnb9u2wdKkt06kTvPoqXHON7WYrIiIiJZaSUBEplhzHYfuR7SyPWs6KqBWsiFrB4sjFHJt/DABv402P8B5MvGQiQ5oOwct4uRxxwRw7Zsd4TpkCv/1mhy4OHmxbPS++uBQOZTx82L7QrVtzJpqRkTknEwLw87OZeHi4bfEcMQKaNnUnbhERESl0SkJFpFiIjI3kj8g/WBG1guVRy1kZtZLY5FgAfL18aR3Sml7VejGowyA61upI6xqt8ff1dznqM5ORAZs3w8KFsGiR3a9fbxv4wsNh3Di4+eZStkJI5sKl338PP/xgX3RGhn0sJMQmmc2b24w7PDznVr267XYrIiIipZKSUBFxTdTxKL7Y8AWfrfuMhXsWAlDOuxxta7ZlROsRdAjtQIfQDrSq0Qo/bz8iIiLo07mPu0GfgaNH7eStmQnn4sX2GNhJXC+4AIYPh549oXfvUtTqmZho15D54QebfO7ebY936JA1q1LbtlC+vLtxioiIiKuUhIpIkYpOiObrjV/z2brPiNgZgYND25C2vNjvRS5rfBnNqzXH19vX7TAL5NAhmD3b5l8LF8LGjfa4MdCqFVx9tU08u3WDJk1KWSPf7t1ZSeecOTYRrVDBrss5dixcdhnUquV2lCIiIlKMKAkVkfMuNimWbzd9y2frP+PXbb+S7qTTNLgpY3uP5ZqW19C8enO3QyyQ9HRYsgR+/hl++gmWLbO9T6tUsYnmiBF237mzXdOzxMrIgOhoArduhbg42Ls357Zzp+1nDNCgAdx+u23t7N1by6WIiIhIvpSEish5EZcSx/dbvuezdZ/x098/kZKeQr3K9Xis+2Nc2+pa2oS0wRjjdphnbP9+O5HQzz/bVs+YGNui2bWrncn20kuhY8cS2MoZF2cHqK5bBxs22JbNzCRz3z5ITaVT9vLGQM2adgBrs2Zw2212RqWmTe1jIiIiIqehJFREzlnmTLYL9yxk0Z5FLNyzkNX7V5PupFOrYi3u6XQP17a6li61u5SYxDM11Y7l/Oknu61caY+HhMCQITbp7N8fgoPdjfOMpaTAli022Vy7Nmu/Y0dWGX9/OzFQ7dpw4YV2X6sW644codXFF9v7NWuW0QVLRUREpLDoPwkRKbC4lDiW7l16IulctGcRhxIOARDoF0iX2l14oscTDGw4kF51e5WI5VMcxzYI/v67XUlk3jw4ftxOGtS9O7zwAlxyiZ1Xp1i3dmZkwK5dORPNdetst9nUVFvG29u2XHbpYhcjbd3aDl6tXz/PFxcdEWGbfEVEREQKgZJQETmtmMQYfv77ZxbsWsDCPQtZe3AtGY5dbqNpcFMua3wZ3ep0o1tYN1pWb4m3V8mY7jUy0iacv/9utwMH7PHGjeH6621LZ79+dkbb01qzBubOtQldx44QFHReY8dx4ODBrCQzM+Fcvz7nupt169oEc/Bgu2/d2iagGrMpIiIiLlESKiJ52nl0JzM3zWTm5pnM3zWfdCedin4V6VqnK6N7jaZbnW50qd2F4ICS0h8VDh+2eWJma+fff9vjISE22cxMOsPDC/Ck0dEwZgxMmZK1DibY8ZKdO9utS5ezX5okPt6O09y9G7Zvzxq/uXatvXamatVsgnnrrTbZbNUKWrYs4TMjiYiISGmkJFREADuuc3nUcmZumsmsLbNYc2ANAC2qt+DxHo9zRdMr6FSrU4lp5QSbdM6fb7vWzpsHq1fbBsSKFe0Ervfea5POli3PYk6d1FR4+227DMnx4zBqFDz4oM1slyyx2+zZ8MkntryvL7Rpk5WUdu5sm1wPHLAJZmRk1j777ZiYnNcNDLQB/+MfWclm69ZQo0ah1JmIiIjI+aYkVKQMS0lPYe6OuczcPJNZm2ex9/hevIwXPcN7MmHgBC5vejmNqjZyO8wzdvBgzqRz7Vp7vHx5O67zmWds0tm5s80Jz9pvv8EDD9jZZPv3h9des4kh2KVKBg60tx0H9uyBpUvttmQJTJ9uk9f8VK5sm2LDwuw6L2Fh9n7mFhZWzAelioiIiJyaklCRMsJxHHYe3cmaA2tYe3AtK6JW8Nv23ziecpwA3wAubngxVzS9gkFNBlEtoJrb4Z6RqKishHPePNi40R4PCIAePeCaa2yLZ+fOhTQEcts2eOQRmDnTJpvffguXX55/M6oxNmkMC4Nhw+yxjAw7S+3SpbZ7ba1aWYlmWJhtphUREREpxZSEipRCsUmxrDu4jjUH1tjt4BrWHljL8ZTjJ8o0qNKAa1tdy+VNL6df/X74+/q7GHH+HMf2WN20CWbOrMU339hkc9Mm22MVbN7WsyfceKNNOjt2PMeWztzi4uz0uBMm2Cd+4QV46KGzG+Pp5WXHizZrVogBioiIiJQcSkJFSrjjycf5a/df/Ln7T1btX8WaA2vYFbvrxOOVy1emTUgbbmx7I61DWtMmpA2tarQi0C/QxahPlpZmGwY3bbJbZqK5aRMcPZpZqgmBgTZ/69PHzvXTuze0a3eelq7MyIBp0+CJJ2yz6z//CS+9ZFsvRUREROSsKAkVKWEOxh/kj8g/mL9rPgsiF7Bq/yoynAy8jTdNqzWlW1g37ux4J21C2tAmpA11KtXBFHjWncKXmmpbLnfutNuuXVm3d+6EvXshPT2rfGgoNG8OI0bYpLN5czhyZCFXXdWt4JMIZec4kJhoWzdzb/HxOe9/9RUsXmz78379NVxwwblUgYiIiIigJFSkWHMch12xu2zCuWsBCyIXsPnwZgDK+5TngjoXMLrXaC6seyEX1LnA9dZNx7GJ5qpVdtu6NSvh3Ls35womXl5QuzbUq2dbM+vWhYYNbbLZrFney2xGRCSfeQJ67JidDnfFCrutXGmDiYuzgZ6J0FD48EO44QZNBiQiIiJSSJSEirjIcRyOpxwn6ngUUXFROfaRxyL5a/df7Dm2B7DdanuG9+SW9rfQK7wXHWt1xM/bz7XYU1NtV9mVK7OSzlWr4MgR+7gxdq6devWgb1+7r1vX7uvVgzp1CnHcZnS0DSQz2VyxwmbAmUJDoX17G0ilSlChgl3qJPeW+3hAgJJPERERkUKmJFTkPHIch6i4KFbtX8W6g+vYe2yvTTKzJZwJqQknnVfOuxy1K9WmR1gPeoX3olfdXrSq0Qov405CFBsLa9bkTDbXrYOUFPu4v79dAvPqq+34zHbt7NKVFSqc5QXT0uxFY2PtgFDP7ZqLFtnWzcxj27fbhDNzhiKwGW6HDnaWovbt7RYaeq5VICIiIiKFREmoSCFJz0hna8xWVu1fxcqolaw6sIpV+1dxMP7giTKVylUiNDCU0IqhdKndhZqBNU/cz76vXL6yK+M4Hcd2nV292iaamfsdO7LKVK9u87oHH8xKOBs3PouJgVJS7Dqby5fbLTOZjI21YzPzkGM+2QoV7JImvXrZgDp0sMFUrVrQly0iIiIiRUhJqEgBOY5DTGIMf8f8nSPhXHNgzYlWTV8vX1rVaMWgxoNoX7M97Wq2o01IG4LK5zHQ0SWJiXYG2uwJZ2YjI9jutI0b2zl5br/dzkTbrp1tVCxwfpySYptOMxPO5ctt02pmU2rFijaJvOQSOxi0cuWce8/tRRs3csHFF9v752U6XBERERE53/RfnEgeElIT2Hl0JzuO7GDH0R1Z+6M72HpoK/Hzs1rqgsoF0a5mO27vcPuJhLN59ebnfbxmcjIcPmyHQx4+DDExOXqunrQdO5bzfnJy1nMFBNjutNdeaxPNtm3z6U7rODZxTEiwrZXZt7yObd5sE861a+0gUrAJZIcOcP/9dkHPDh2gUaMzGnuZFBsLwcGFV4kiIiIiUuSUhEqZdCz5GJGxkTm2XbG72HFkB9uPbOdA/IEc5f19/KlXuR4NqjSgvld9erbqSYMqDWgb0pZ6leudc9dZx4Hjx2H/frsdOGD3mQlm9mQzc8unx+oJFStmNSIGBdlutI0a2Xl5Mo81aWITzoYNwdsbu0bKnj12rOVn2+0++3bkSM51VE6nShWbaD70kN137AgNGpxFU6qIiIiIlBZKQqVUSE1PJSE1gYTUBBLTEklITeBo0tGTEs3MLTY5Nsf5Pl4+1KlUhwZVGjC4yWDqV65P/Sr1T+xDKoScSDQjIiLo063PGcWVng4HD9rlSfbty0oy89oSE/N+jipVbONftWpQq5ZtoQwOzjqWeTs4OKv3asWKuRoWHcdmrTExWc2m0dGwMxLmZEsyd+60kwKdqBgfO6VtgwYwbJi9YIUKtum0QoWcW17HKlZUwikiIiIiOSgJlUKRmJpIakYqlcpVKpTny3Ay2Hl0J+sPrmf9ofWsO7iOyNjIHElmQmoCian2drpz6ta5IL+qhPqHU9O/Ps1De1OjXLjd/OpSzTecSt4heOGNjw/4+dmlQ3wzwC8O4pIh2TfreFycNwmeCW2jomzD4d69WVv2+1FROXO6TMHBULOm3bp3z7qduYWE2C042NNCmclxbLfXmJic298xsCRbgpl9n3k7c/xlXsE0aGBbKYcPt7cztzp1NPZSRERERAqV/ruUAslccmT1/tWsPuDZ9q9m8+HNZDgZBJULIjwonLCgMMIrhRMelHOrVbEWvt6+OZ5v97HdOZLN9YfWs+HQhhxLl4RVCqNBlQaEBIYQ4BuAv48/Ab4BBPgG4IM/x6IDiN4fwP7d/uzdGcCenf6kxVWC2HA4FkZsSiCxwKZCqYVe+T4SGAh1ajvUDk7kouax1Gl7kNoZe6idtI3aiX8T6neYGuWP4evj2KZKLy9I8IJd3rDbK+tYZjNmbKxNII8cyUo480smAcqVs0ll1ap236RJVjNp5rHMfXCwTTKDis9kSSIiIiJS+rmahBpj/IAxwI1ADWAL8KLjOP87w/P/CTwGNAEOAB8BzzmOk3q21zHG1ATGA5cC5YAlwGOO4yw/i5dYoqWkp7ApehOr969m1f5VJ5LO6IToE2XqBtWlbc22XNXiKgL9Atkdu5vIY5Hsjt3N4j2LOZx4OMdzehkvQgNDCQ8Kx8Fhw6ENHEs+duLx0MBQWtZoyR0d7qBljZa0qtGKFtVbnGhhPXLEzuS6cqVd0WPBSti0CTIy7PlVqth5bq4aAE2b2tZLb++cm4/Pyce8vW2v0bQ0O39OSordp6ZCSlIGqXHJpMankBqfwraN26gZXBMnMYmaThR1UrZR+9gmakevptLejbBln22xzC40FGrXhgxvSMiwAWff0tNPPuY4NkGsWhVatLAvrmrV/LcqVWyXWHV/FREREZFizO2W0PeBEcBkYA0wDJhujPFyHGfaqU40xtwKvAf8CLwBtMUmmrWA28/mOsaYCsBcIASYAMQCo4C5xpgujuMUTkOaC2Zvm01MYgxxKXFntB1POc7u2N2kZth8vpx3OVrVaMVlDS8nzLctVVPaUe5oG6L3VGb3OlgUaRO3qlWhRjA08+RFgaHxpAfuJqX8buJ8IoklkujUSKLid5PupDOi5T+pV6EVoV4tCU5vQWpUOWK2HeHw3Di27U1kycE0YmI2cTjWl52JNdiZUvvEa6oddJz29WO5akQy7Tt40b5nBcLbVcX45vG2TkmBQ4fsOMhDh/K+ffgwxMVlzeyaeTsp6dSV6+tr16usWxf697f77FtYmG2hFBERERER95JQY0xHYCTwjOM4T3uOvQfMB8YbY2bkbtHMdm554CUgAhjsOLbZyRhzFPg/Y8zrjuOsPYvr3AU0A/o6jjPXU/ZzbMvpc8BVhVoJRei6/91OTHpkjmM++OFnAilvAilnAinnZfflvapRzVQg3Gs4fkfbkrq3LUe2NmZXpA/Lo09uZQutnEBY0HHKeaeydXN5FiWU53B8eVLSfYAK2CptluOc8j5p+HilE5GSV3IWCIAvKVQlhmDfYwT7J9C16t/c6f017ZMX0/7oXGrE7oNV2O1Tz6nG2G6mISF2YpzoaLsdO5bHdbKVr149q5tqeLg9NzAwa4KdbLfX7dxJq65d7TSzYWF2EGeOgZsiIiIiIpIfN1tCrwYcYFLmAcdxHGPMZGA6cCHwez7nXgRUAyZlJqAek4HRnudeexbXuRpYn5mAesoeMsbMAG40xgQ4jpM1ULEE8X1/GsQFQ0qg3VIrkJbuRxpwqhcUZI4RZvYQnvErXYkknEjC2E2453Zt9uJ3NBWO5jzPARLx5zDBxFCVGKrmvJ0WTBq+BAcm22GKIb4E1/Gnat2KBDeqQtWm1QlsVgdTMwS8a2Z75t7AfbaramysXcvk4MGc+8zb8fF2TZJq1WySWb16ztvVq9surAVMIKMjIqBPnwKdIyIiIiIilptJaAdgp+M4h3IdX5Lt8fyS0A65ygLgOM4+Y8yebI+f8XWMMV7YLr3T87jeEuAOoCWwNJ+YirXN4a+QceAQjpe33bx9sm577md45TxWqaJDULCPXWajUiXPFgaVWtrbOY5XytHl1AABni0sv6D8/e2gzbNhjF2PpHJlO/hTRERERERKBDeT0FAgKo/jmcdqnebc7GVzn18rV9kzuU5V7EREZxtTsRY0b5bbIYiIiIiIiLiahPoDB/M4npTt8VOd6+QzZjQJqJSr7JlcJ3OffDYxGWPuwLaWEhISQkRERH5FC01cXFyRXEdyUr27R3XvDtW7O1Tv7lHdu0P17g7Vu3vKct27mYQmYlsecyuf7fFTnWuMMb55JKLlc517ptfJ3J9VTI7jTAGmAHTq1MnpUwRjBiMiIiiK60hOqnf3qO7doXp3h+rdPap7d6je3aF6d09ZrnsvF6+du9tspsyutvtOcy6nOH9frrJncp0YbCvo2cYkIiIiIiIip+FmEroCqGuMqZ7reNdsj5/qXIDO2Q8aY2oBdXKde0bXcRwnA1id+zmzlU0GNpwiJhERERERETkNN5PQL7GTqI7KPGCMMdi1Og9g1/HEGBNkjGlmjAnKdu5c4DAwynNOpns8+y8Kep1sZVsaY/pkK1sdGA786DhO/Fm9UhEREREREQFcHBPqOM5SY8x0YIwxpiqwBhgG9AJuzDbWcyjwIXAz8JHn3CRjzJPYMZjfGWO+Bdphk9APHMdZcxbXAXgLuA342hgzHojFJq8+wL/PQzWIiIiIiIiUKW5OTARwC7ATuAG4E9gCjHQcZ9rpTnQc511jTArwGDAJOwPuc8C4s72O4zhxxpiLgPHAo9hJipYANziOo664IiIiIiIi58jVJNRxnGRgtGfLr8xHeFpA83hsKjC1MK6Trew+YMTpyomIiIiIiEjBuTkmVERERERERMoYJaEiIiIiIiJSZJSEioiIiIiISJFREioiIiIiIiJFRkmoiIiIiIiIFBkloSIiIiIiIlJklISKiIiIiIhIkVESKiIiIiIiIkVGSaiIiIiIiIgUGSWhIiIiIiIiUmSUhIqIiIiIiEiRURIqIiIiIiIiRUZJqIiIiIiIiBQZJaEiIiIiIiJSZJSEioiIiIiISJExjuO4HUOpY4w5BOwqgktVA6KL4DqSk+rdPap7d6je3aF6d4/q3h2qd3eo3t1T2uu+ruM41fN6QEloCWaMWeY4Tie34yhrVO/uUd27Q/XuDtW7e1T37lC9u0P17p6yXPfqjisiIiIiIiJFRkmoiIiIiIiIFBkloSXbFLcDKKNU7+5R3btD9e4O1bt7VPfuUL27Q/XunjJb9xoTKiIiIiIiIkVGLaEiIiIiIiJSZJSEioiIiIiISJFRElrCGGP8jDHjjDGRxpgkY8waY8x1bsdVnBljOhtjXjfGrDXGxBlj9hljvjfGnDQltjGmkjHmTWPMfmNMojFmkTFmQD7P28QYM8sYc8yzzTTGNMyn7KXGmMWe59zviSewsF9rcWeM6WWMcTxbnVyPqe4LkTGmpTHmS2PMIc9nxVZjzCu5ytQ0xnxqjDns+d2YY4zpmM/zdTHGzPWUO2yM+dgYUyOfsv/0fDYlGWN2GWOeMcb4no/XWdwYY2oZY6YYY7Z73nPbjTHvGGPCcpVT3Z8lY0yg53X96Hl/O8aYp/Mp6+rnirEe8vz+JRtjthhj7jfGmHOqBBecab0bY/oaY94zxmwyxiR43oefG2Oa5PO8+l04hYK833Od909P2bR8Hle9n0ZB694Y08MY85Mx5ogxJt4Ys84Y80ge5fRZA+A4jrYStAGfAOnAG8DtwE+AA1zvdmzFdQO+BA4Akzx19jiwzVOPl2UrZ4B5QCLwPHAnsAhIBXrnes5anueMBB4GHgH2AHuB6rnKDvBc6y/Pc74IJAGz3a6bIv45+ABrgDjPe7aO6v681XUfIAFYBjwK3AY8C0zLVqYCsBGIAUYD93ruHwOa5Xq+1kA8sB4YBfwbOOL5eZbPVfZWz8/3B8/v25tABvCu2/VSBPUeBOzGLjw+zlPvEzx1FwlUVN0XSj3X87zOPcAvnttP51HO9c8Vz/vAwf7tvg2Y5rk/2u16PI/1vgzYAYz3vOaxnrpNANrnKqvfhUKq91znBAFR2L+3aXk8rnov5LoHrvN8LswB7gfuAF4CXstVTp81mTG7HYC2AvywoGPuXwDsH9kFng8bX7djLI4b0B3wy3Us2PMhsCLbsSs99XtTtmPlgb+BZbnOfwNIAZpkO9YMSAPG5yq7FtgMlMt27DbPtQa7XT9F+HN4CDgIvMrJSajqvvDqOdDzx2wW4H2Kco946uGibMeqY/+5+DJX2e+Aw0C1bMf6e86/N9fP7BAwF8/Ed57jz2H/EWntdv2c57q/xVMnQ3Idv8dzfKjqvlDquRxQy3O7DvknQ65+rmD/2UwGPsp1/qfYhKz6mb7m4rAVoN4vBLxyHWuE/TLg61zH9btQSPWe65yJ2KTxU/JOQlXvhVj3nsfigEln8Jz6rMmMz+0AtBXghwUve36Rc39Tcp3nDdnP7RhL0gZ8DiTlun8E8MlV7klP/TbMdmw/8H0ez/kLsDvb/eaecx/NVc4POA584nY9FFFdhwKxng/Ppzk5CVXdF15d3+553S099yuQRzIKLAbW5XH8Hew3rQGe+5U8fzDfzKPsZmBBtvuXeq59Va5ytTzHx7ldP+e57h/0vM5OuY4P9Ry/WHVf6HV+qn8MXf1cAe7O5/3QzXP8Vrfr73zU+ynOWQxsyuOYfhcKsd6BNtiEpj/wEXknoar3Qqx7bE+LFKCy534g2RLxXGX1WePZNCa0ZOkA7HQc51Cu40uyPS5nrhb2271MHYCVjuPkHj+Ro36NMbWBkGzHc5etY4ypnv2c3GUdx0kBVlF2fmbjga3AB/k8rrovPAOxXaqqG2M2YL+djTPGTDfGBAMYY7yAtuRfj+WAlp77rQHfU5Rtl23MSX51vg/b3ai01nmmedg/+G8YY7obY2obY/pju1AtAn5X3Rcptz9XOmC7/q7M9ZzLsV8ol5mfied9WpNsf3P1u1D4PHUwCfjOcZzf8imjei98A4FNwABjzE5skhhrjJlkjPHPLKTPmpyUhJYsodhut7llHqtVhLGUaMaYXkAP4LNsh8+0fkNzHT+XsqX+Z2aM6Y1trb/fcZyMfIqp7gtPY+z42x+ACGAYdlzicOAnY4w3UBX7j0Zh1GMg9tvyMylbWuscAMdxVmK/kW4G/In9x+tXYAu2p0oaqvui5PbnSihwyHGc9OyFPP9EHqZs/UyuB8LJ+TdXvwuF7wagE3asYX5U74WvMVAb2/11Gvbv7ifYoRifZiunz5psfNwOQArEHzumLrekbI/LaRhjQoH/YQeFP5vtIX9sn/rcctdv5r4wypbqn5kxxgf7rew0x3H+OkVR1X3hCQQCsBNB3OM59o0x5hi2S/8gsr4tLcw6j/XsHcdxUvMpWymP46VNFPAHMBv7GdMF+w/hx8aY4RTuezizjOo+b25/ruR3/bzKllrGmJbAZOyERW9le0i/C4XIGBMEvIIdV7jjFEVV74UvEPDGTgL0gufYN55W4ruNMW0cx1mDPmtyUEtoyZKI/fYqt/LZHpdT8HxI/4j9wBjiOE5stofPtH4z94VRtrT/zB4A6gJPnKac6r7wZL6uT3Mdn+bZ96Rw6zF3WZPPdPyluc4BMMZcAcwAHnYc5w3HcWY6jjMauA87Sc7lqO6LktufK/ldP6+ypZKxSxP9BBwF/pGra7R+FwrXc9hxiS+eppzqvfCdyd/d7OX0WYOS0JImv+4MmU32+4owlhLHGBMAfA80xc4qtjZXkTOt31N1fy5o2VL7M/Mk/E9hx4H6GWPqGWPqAZU9ReqYrLVCVfeFJ/N1Hch1PPN+Fey0/MkUTj3GY8egnknZ0lrnmR4ENjiOszXX8a//v717C7WiCgM4/l8pUqZEFBYaKKEIQqkpLvL9AAAF0klEQVRRKVTkU1SQGCXRPQiKKLoYPVRWFhl2iArJLqAgYeFDKEgFSRR0ISg6Emb0Enaxi2YKhskxYfWw1s454+yjwt4zOv5/sDjM7HX2WeebmTXzzW3ln5dh7OvUdL/yOzAh3wL/vxDCGNIb2lu9TPKzbRtJV2GuiDH+WqrittAjIYRppEcBlpPWuc7+dlz+fEoI4exc3bj33pHsd8G+ZhiT0OPLIDC58NByx5zC56qQN8R1wFxgYYzxs4pqg6SH7Mu3qXfiuwkg70h3ABdVfMccYFvh5VGdZTKsbm7PLNq9zE4HxpPGy9paKA/kz78g3bYIxr6Xvs4/zynN70z/mZ/N/YbucRwCvsvTm0lvWqyqezHpxS8xT3eL+cT899sa846JpFuyyjrr9WhjX6um+5VB0rKfXfrOC0nHX61dJvkk5Aek5+SuijF+X67jttBTk0h9zwDD97fX5flbyc/jGve+OOx+F+xrDtH063ktR15IK+Kw10OTxgn9hPTKZ8cJrY7bKOAd0oC/N45QbyHdx5QbLNVdQbrtZVphXmecpxdLdbfQfZyn+U3Hp49xHwssqChr8/9+J+nsuLHvbdxnkt6Gt7Y0f2n+vy/P04/k6XmFOp1x4spj+b0H7ATOKMzrjBN3f2mZ7aR6nLgInN90fPoc+w15PZxdmr8o//+3Gvuex3ykYRMa7VdIicF+qsfu2wdMaDp+fYr7WNKLufYV1/Eu3+O20IO4A2dSvb/9iHTsswC41Lj3bZ2/Jn/2fGn+Wzn+5xbm2dd02td0AyxHucAOrtDL84r4fl4Zb2u6bcdqAV7KMdoI3FJRTs31TgI+zRvss8DdpKt1BygM6JzrTiKdzfoZeIh0kLmNdMvDWaW6V+Zl9jlwF/Ac6UHxD4sd9YlSqB4n1Nj3Nsav5xivI92itbIzXagzLu/cdgGPAfeSzn7/Dcwofd9M0oDXW3K9x0kHK98Cp5TqdsYpfTf3Ua+QkuJVTcelhrhfQnpN/u7Cerwqr4NbgJONfc9ifR+wmHTlJ5IOthfnMjnXabxf4eDJnzdJJ97W5Oknmo5hH+O+Pn/2NhX73NL3uS30KO5dfm811eOEGvcex5707HMk9fn3kC5+RA5NLO1rOm1uugGWo1xg6cHjpcAvpFsmNgM3N92uY7mQhqmII5Qphbqnkd7it5104PIleYD5iu+dnjvaPblsAKZ2qXs18FXuPLbnjnl807FpaHksoZSEGvuex3g08CjwA+ns6E+kg/AxpXoTSQeKu0jP9nxMabDrQt25eVvam+uvKe8wC3VvJx2gDOW+6hlOkDs1SLdJrc8HGPvzwcVrFK4iGPuexPnHEfr0eYV6jfYrpET4YdLV1yHSeMkPcpyeBDuSuB+mTqz4TreFHq3vFb+3mook1Lj3PvakOwAGSH3+ftLQXIuqtnX7mlRCbrgkSZIkSX3ni4kkSZIkSbUxCZUkSZIk1cYkVJIkSZJUG5NQSZIkSVJtTEIlSZIkSbUxCZUkSZIk1cYkVJIkSZJUG5NQSZIkSVJtTEIlSTrOhRDuCCHEEMKBEMLUis9XhhBiE22TJKnMJFSSpPYYBTzZdCMkSRqJSagkSe2xCbgphDC96YZIktSNSagkSe2xDPgXeKrphkiS1I1JqCRJ7fEb8AZwQwhhRtONkSSpikmoJEntsgwYApY03A5JkiqZhEqS1CIxxj+AV4HrQwjnNd0eSZLKTEIlSWqfAeAfvBoqSToGmYRKktQyMcYdwArg2hDCrKbbI0lSkUmoJEntNADsBZ5uuiGSJBWZhEqS1EIxxr+A5cB84IKGmyNJ0v9MQiVJaq8XgD3A7KYbIklSh0moJEktFWPcDbzcdDskSSoKMcam2yBJkiRJOkF4JVSSJEmSVBuTUEmSJElSbUxCJUmSJEm1MQmVJEmSJNXGJFSSJEmSVBuTUEmSJElSbUxCJUmSJEm1MQmVJEmSJNXGJFSSJEmSVBuTUEmSJElSbf4DSET4hxwdp54AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}